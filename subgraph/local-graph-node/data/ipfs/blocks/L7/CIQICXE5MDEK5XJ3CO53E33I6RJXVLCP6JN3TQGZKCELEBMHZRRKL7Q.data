{\n        if (hour === 0) {\n            return 12;\n        }\n        else if (hour > 12) {\n            return hour - 12;\n        }\n        return hour;\n    }\n\n    // firstWeekday: 'sunday' or 'monday', default is 'sunday'\n    //\n    // Pilfered & ported from Ruby's strftime implementation.\n    function weekNumber(date, firstWeekday) {\n        firstWeekday = firstWeekday || 'sunday';\n\n        // This works by shifting the weekday back by one day if we\n        // are treating Monday as the first day of the week.\n        var weekday = date.getDay();\n        if (firstWeekday === 'monday') {\n            if (weekday === 0) // Sunday\n                weekday = 6;\n            else\n                weekday--;\n        }\n\n        var firstDayOfYearUtc = Date.UTC(date.getFullYear(), 0, 1),\n            dateUtc = Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()),\n            yday = Math.floor((dateUtc - firstDayOfYearUtc) / 86400000),\n            weekNum = (yday + 7 - weekday) / 7;\n\n        return Math.floor(weekNum);\n    }\n\n    // Get the ordinal suffix for a number: st, nd, rd, or th\n    function ordinal(number) {\n        var i = number % 10;\n        var ii = number % 100;\n\n        if ((ii >= 11 && ii <= 13) || i === 0 || i >= 4) {\n            return 'th';\n        }\n        switch (i) {\n            case 1: return 'st';\n            case 2: return 'nd';\n            case 3: return 'rd';\n        }\n    }\n\n    function getTimestampToUtcOffsetFor(date) {\n        return (date.getTimezoneOffset() || 0) * 60000;\n    }\n\n    function warn(message) {\n        if (typeof console !== 'undefined' && typeof console.warn == 'function') {\n            console.warn(message)\n        }\n    }\n\n}());\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n'use strict';\n\n/*<replacement>*/\n\nvar Buffer = require('safe-buffer').Buffer;\n/*</replacement>*/\n\nvar isEncoding = Buffer.isEncoding || function (encoding) {\n  encoding = '' + encoding;\n  switch (encoding && encoding.toLowerCase()) {\n    case 'hex':case 'utf8':case 'utf-8':case 'ascii':case 'binary':case 'base64':case 'ucs2':case 'ucs-2':case 'utf16le':case 'utf-16le':case 'raw':\n      return true;\n    default:\n      return false;\n  }\n};\n\nfunction _normalizeEncoding(enc) {\n  if (!enc) return 'utf8';\n  var retried;\n  while (true) {\n    switch (enc) {\n      case 'utf8':\n      case 'utf-8':\n        return 'utf8';\n      case 'ucs2':\n      case 'ucs-2':\n      case 'utf16le':\n      case 'utf-16le':\n        return 'utf16le';\n      case 'latin1':\n      case 'binary':\n        return 'latin1';\n      case 'base64':\n      case 'ascii':\n      case 'hex':\n        return enc;\n      default:\n        if (retried) return; // undefined\n        enc = ('' + enc).toLowerCase();\n        retried = true;\n    }\n  }\n};\n\n// Do not cache `Buffer.isEncoding` when checking encoding names as some\n// modules monkey-patch it to support additional encodings\nfunction normalizeEncoding(enc) {\n  var nenc = _normalizeEncoding(enc);\n  if (typeof nenc !== 'string' && (Buffer.isEncoding === isEncoding || !isEncoding(enc))) throw new Error('Unknown encoding: ' + enc);\n  return nenc || enc;\n}\n\n// StringDecoder provides an interface for efficiently splitting a series of\n// buffers into a series of JS strings without breaking apart multi-byte\n// characters.\nexports.StringDecoder = StringDecoder;\nfunction StringDecoder(encoding) {\n  this.encoding = normalizeEncoding(encoding);\n  var nb;\n  switch (this.encoding) {\n    case 'utf16le':\n      this.text = utf16Text;\n      this.end = utf16End;\n      nb = 4;\n      break;\n    case 'utf8':\n      this.fillLast = utf8FillLast;\n      nb = 4;\n      break;\n    case 'base64':\n      this.text = base64Text;\n      this.end = base64End;\n      nb = 3;\n      break;\n    default:\n      this.write = simpleWrite;\n      this.end = simpleEnd;\n      return;\n  }\n  this.lastNeed = 0;\n  this.lastTotal = 0;\n  this.lastChar = Buffer.allocUnsafe(nb);\n}\n\nStringDecoder.prototype.write = function (buf) {\n  if (buf.length === 0) return '';\n  var r;\n  var i;\n  if (this.lastNeed) {\n    r = this.fillLast(buf);\n    if (r === undefined) return '';\n    i = this.lastNeed;\n    this.lastNeed = 0;\n  } else {\n    i = 0;\n  }\n  if (i < buf.length) return r ? r + this.text(buf, i) : this.text(buf, i);\n  return r || '';\n};\n\nStringDecoder.prototype.end = utf8End;\n\n// Returns only complete characters in a Buffer\nStringDecoder.prototype.text = utf8Text;\n\n// Attempts to complete a partial non-UTF-8 character using bytes from a Buffer\nStringDecoder.prototype.fillLast = function (buf) {\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, this.lastTotal - this.lastNeed, 0, buf.length);\n  this.lastNeed -= buf.length;\n};\n\n// Checks the type of a UTF-8 byte, whether it's ASCII, a leading byte, or a\n// continuation byte. If an invalid byte is detected, -2 is returned.\nfunction utf8CheckByte(byte) {\n  if (byte <= 0x7F) return 0;else if (byte >> 5 === 0x06) return 2;else if (byte >> 4 === 0x0E) return 3;else if (byte >> 3 === 0x1E) return 4;\n  return byte >> 6 === 0x02 ? -1 : -2;\n}\n\n// Checks at most 3 bytes at the end of a Buffer in order to detect an\n// incomplete multi-byte UTF-8 character. The total number of bytes (2, 3, or 4)\n// needed to complete the UTF-8 character (if applicable) are returned.\nfunction utf8CheckIncomplete(self, buf, i) {\n  var j = buf.length - 1;\n  if (j < i) return 0;\n  var nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 1;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) self.lastNeed = nb - 2;\n    return nb;\n  }\n  if (--j < i || nb === -2) return 0;\n  nb = utf8CheckByte(buf[j]);\n  if (nb >= 0) {\n    if (nb > 0) {\n      if (nb === 2) nb = 0;else self.lastNeed = nb - 3;\n    }\n    return nb;\n  }\n  return 0;\n}\n\n// Validates as many continuation bytes for a multi-byte UTF-8 character as\n// needed or are available. If we see a non-continuation byte where we expect\n// one, we \"replace\" the validated continuation bytes we've seen so far with\n// a single UTF-8 replacement character ('\\ufffd'), to match v8's UTF-8 decoding\n// behavior. The continuation byte check is included three times in the case\n// where all of the continuation bytes for a character exist in the same buffer.\n// It is also done this way as a slight performance increase instead of using a\n// loop.\nfunction utf8CheckExtraBytes(self, buf, p) {\n  if ((buf[0] & 0xC0) !== 0x80) {\n    self.lastNeed = 0;\n    return '\\ufffd';\n  }\n  if (self.lastNeed > 1 && buf.length > 1) {\n    if ((buf[1] & 0xC0) !== 0x80) {\n      self.lastNeed = 1;\n      return '\\ufffd';\n    }\n    if (self.lastNeed > 2 && buf.length > 2) {\n      if ((buf[2] & 0xC0) !== 0x80) {\n        self.lastNeed = 2;\n        return '\\ufffd';\n      }\n    }\n  }\n}\n\n// Attempts to complete a multi-byte UTF-8 character using bytes from a Buffer.\nfunction utf8FillLast(buf) {\n  var p = this.lastTotal - this.lastNeed;\n  var r = utf8CheckExtraBytes(this, buf, p);\n  if (r !== undefined) return r;\n  if (this.lastNeed <= buf.length) {\n    buf.copy(this.lastChar, p, 0, this.lastNeed);\n    return this.lastChar.toString(this.encoding, 0, this.lastTotal);\n  }\n  buf.copy(this.lastChar, p, 0, buf.length);\n  this.lastNeed -= buf.length;\n}\n\n// Returns all complete UTF-8 characters in a Buffer. If the Buffer ended on a\n// partial character, the character's bytes are buffered until the required\n// number of bytes are available.\nfunction utf8Text(buf, i) {\n  var total = utf8CheckIncomplete(this, buf, i);\n  if (!this.lastNeed) return buf.toString('utf8', i);\n  this.lastTotal = total;\n  var end = buf.length - (total - this.lastNeed);\n  buf.copy(this.lastChar, 0, end);\n  return buf.toString('utf8', i, end);\n}\n\n// For UTF-8, a replacement character is added when ending on a partial\n// character.\nfunction utf8End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + '\\ufffd';\n  return r;\n}\n\n// UTF-16LE typically needs two bytes per character, but even if we have an even\n// number of bytes available, we need to check if we end on a leading/high\n// surrogate. In that case, we need to wait for the next two bytes in order to\n// decode the last character properly.\nfunction utf16Text(buf, i) {\n  if ((buf.length - i) % 2 === 0) {\n    var r = buf.toString('utf16le', i);\n    if (r) {\n      var c = r.charCodeAt(r.length - 1);\n      if (c >= 0xD800 && c <= 0xDBFF) {\n        this.lastNeed = 2;\n        this.lastTotal = 4;\n        this.lastChar[0] = buf[buf.length - 2];\n        this.lastChar[1] = buf[buf.length - 1];\n        return r.slice(0, -1);\n      }\n    }\n    return r;\n  }\n  this.lastNeed = 1;\n  this.lastTotal = 2;\n  this.lastChar[0] = buf[buf.length - 1];\n  return buf.toString('utf16le', i, buf.length - 1);\n}\n\n// For UTF-16LE we do not explicitly append special replacement characters if we\n// end on a partial character, we simply let v8 handle that.\nfunction utf16End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) {\n    var end = this.lastTotal - this.lastNeed;\n    return r + this.lastChar.toString('utf16le', 0, end);\n  }\n  return r;\n}\n\nfunction base64Text(buf, i) {\n  var n = (buf.length - i) % 3;\n  if (n === 0) return buf.toString('base64', i);\n  this.lastNeed = 3 - n;\n  this.lastTotal = 3;\n  if (n === 1) {\n    this.lastChar[0] = buf[buf.length - 1];\n  } else {\n    this.lastChar[0] = buf[buf.length - 2];\n    this.lastChar[1] = buf[buf.length - 1];\n  }\n  return buf.toString('base64', i, buf.length - n);\n}\n\nfunction base64End(buf) {\n  var r = buf && buf.length ? this.write(buf) : '';\n  if (this.lastNeed) return r + this.lastChar.toString('base64', 0, 3 - this.lastNeed);\n  return r;\n}\n\n// Pass bytes on through for single-byte encodings (e.g. ascii, latin1, hex)\nfunction simpleWrite(buf) {\n  return buf.toString(this.encoding);\n}\n\nfunction simpleEnd(buf) {\n  return buf && buf.length ? this.write(buf) : '';\n}","var isHexPrefixed = require('is-hex-prefixed');\n\n/**\n * Removes '0x' from a given `String` is present\n * @param {String} str the string value\n * @return {String|Optional} a string by pass if necessary\n */\nmodule.exports = function stripHexPrefix(str) {\n  if (typeof str !== 'string') {\n    return str;\n  }\n\n  return isHexPrefixed(str) ? str.slice(2) : str;\n}\n","\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!global.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = global.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n","import getPrototypeOf from \"./getPrototypeOf.js\";\nexport default function _superPropBase(object, property) {\n  while (!Object.prototype.hasOwnProperty.call(object, property)) {\n    object = getPrototypeOf(object);\n    if (object === null) break;\n  }\n\n  return object;\n}","import superPropBase from \"./superPropBase.js\";\nexport default function _get() {\n  if (typeof Reflect !== \"undefined\" && Reflect.get) {\n    _get = Reflect.get.bind();\n  } else {\n    _get = function _get(target, property, receiver) {\n      var base = superPropBase(target, property);\n      if (!base) return;\n      var desc = Object.getOwnPropertyDescriptor(base, property);\n\n      if (desc.get) {\n        return desc.get.call(arguments.length < 3 ? target : receiver);\n      }\n\n      return desc.value;\n    };\n  }\n\n  return _get.apply(this, arguments);\n}","const typeofs = [\n  'string',\n  'number',\n  'bigint',\n  'symbol'\n];\nconst objectTypeNames = [\n  'Function',\n  'Generator',\n  'AsyncGenerator',\n  'GeneratorFunction',\n  'AsyncGeneratorFunction',\n  'AsyncFunction',\n  'Observable',\n  'Array',\n  'Buffer',\n  'Object',\n  'RegExp',\n  'Date',\n  'Error',\n  'Map',\n  'Set',\n  'WeakMap',\n  'WeakSet',\n  'ArrayBuffer',\n  'SharedArrayBuffer',\n  'DataView',\n  'Promise',\n  'URL',\n  'HTMLElement',\n  'Int8Array',\n  'Uint8Array',\n  'Uint8ClampedArray',\n  'Int16Array',\n  'Uint16Array',\n  'Int32Array',\n  'Uint32Array',\n  'Float32Array',\n  'Float64Array',\n  'BigInt64Array',\n  'BigUint64Array'\n];\nexport function is(value) {\n  if (value === null) {\n    return 'null';\n  }\n  if (value === undefined) {\n    return 'undefined';\n  }\n  if (value === true || value === false) {\n    return 'boolean';\n  }\n  const typeOf = typeof value;\n  if (typeofs.includes(typeOf)) {\n    return typeOf;\n  }\n  if (typeOf === 'function') {\n    return 'Function';\n  }\n  if (Array.isArray(value)) {\n    return 'Array';\n  }\n  if (isBuffer(value)) {\n    return 'Buffer';\n  }\n  const objectType = getObjectType(value);\n  if (objectType) {\n    return objectType;\n  }\n  return 'Object';\n}\nfunction isBuffer(value) {\n  return value && value.constructor && value.constructor.isBuffer && value.constructor.isBuffer.call(null, value);\n}\nfunction getObjectType(value) {\n  const objectTypeName = Object.prototype.toString.call(value).slice(8, -1);\n  if (objectTypeNames.includes(objectTypeName)) {\n    return objectTypeName;\n  }\n  return undefined;\n}","class Type {\n  constructor(major, name, terminal) {\n    this.major = major;\n    this.majorEncoded = major << 5;\n    this.name = name;\n    this.terminal = terminal;\n  }\n  toString() {\n    return `Type[${ this.major }].${ this.name }`;\n  }\n  compare(typ) {\n    return this.major < typ.major ? -1 : this.major > typ.major ? 1 : 0;\n  }\n}\nType.uint = new Type(0, 'uint', true);\nType.negint = new Type(1, 'negint', true);\nType.bytes = new Type(2, 'bytes', true);\nType.string = new Type(3, 'string', true);\nType.array = new Type(4, 'array', false);\nType.map = new Type(5, 'map', false);\nType.tag = new Type(6, 'tag', false);\nType.float = new Type(7, 'float', true);\nType.false = new Type(7, 'false', true);\nType.true = new Type(7, 'true', true);\nType.null = new Type(7, 'null', true);\nType.undefined = new Type(7, 'undefined', true);\nType.break = new Type(7, 'break', true);\nclass Token {\n  constructor(type, value, encodedLength) {\n    this.type = type;\n    this.value = value;\n    this.encodedLength = encodedLength;\n    this.encodedBytes = undefined;\n    this.byteValue = undefined;\n  }\n  toString() {\n    return `Token[${ this.type }].${ this.value }`;\n  }\n}\nexport {\n  Type,\n  Token\n};","export const useBuffer = globalThis.process && !globalThis.process.browser && globalThis.Buffer && typeof globalThis.Buffer.isBuffer === 'function';\nconst textDecoder = new TextDecoder();\nconst textEncoder = new TextEncoder();\nfunction isBuffer(buf) {\n  return useBuffer && globalThis.Buffer.isBuffer(buf);\n}\nexport function asU8A(buf) {\n  if (!(buf instanceof Uint8Array)) {\n    return Uint8Array.from(buf);\n  }\n  return isBuffer(buf) ? new Uint8Array(buf.buffer, buf.byteOffset, buf.byteLength) : buf;\n}\nexport const toString = useBuffer ? (bytes, start, end) => {\n  return end - start > 64 ? globalThis.Buffer.from(bytes.subarray(start, end)).toString('utf8') : utf8Slice(bytes, start, end);\n} : (bytes, start, end) => {\n  return end - start > 64 ? textDecoder.decode(bytes.subarray(start, end)) : utf8Slice(bytes, start, end);\n};\nexport const fromString = useBuffer ? string => {\n  return string.length > 64 ? globalThis.Buffer.from(string) : utf8ToBytes(string);\n} : string => {\n  return string.length > 64 ? textEncoder.encode(string) : utf8ToBytes(string);\n};\nexport const fromArray = arr => {\n  return Uint8Array.from(arr);\n};\nexport const slice = useBuffer ? (bytes, start, end) => {\n  if (isBuffer(bytes)) {\n    return new Uint8Array(bytes.subarray(start, end));\n  }\n  return bytes.slice(start, end);\n} : (bytes, start, end) => {\n  return bytes.slice(start, end);\n};\nexport const concat = useBuffer ? (chunks, length) => {\n  chunks = chunks.map(c => c instanceof Uint8Array ? c : globalThis.Buffer.from(c));\n  return asU8A(globalThis.Buffer.concat(chunks, length));\n} : (chunks, length) => {\n  const out = new Uint8Array(length);\n  let off = 0;\n  for (let b of chunks) {\n    if (off + b.length > out.length) {\n      b = b.subarray(0, out.length - off);\n    }\n    out.set(b, off);\n    off += b.length;\n  }\n  return out;\n};\nexport const alloc = useBuffer ? size => {\n  return globalThis.Buffer.allocUnsafe(size);\n} : size => {\n  return new Uint8Array(size);\n};\nexport const toHex = useBuffer ? d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n  return globalThis.Buffer.from(toBytes(d)).toString('hex');\n} : d => {\n  if (typeof d === 'string') {\n    return d;\n  }\n  return Array.prototype.reduce.call(toBytes(d), (p, c) => `${ p }${ c.toString(16).padStart(2, '0') }`, '');\n};\nexport const fromHex = useBuffer ? hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n  return globalThis.Buffer.from(hex, 'hex');\n} : hex => {\n  if (hex instanceof Uint8Array) {\n    return hex;\n  }\n  if (!hex.length) {\n    return new Uint8Array(0);\n  }\n  return new Uint8Array(hex.split('').map((c, i, d) => i % 2 === 0 ? `0x${ c }${ d[i + 1] }` : '').filter(Boolean).map(e => parseInt(e, 16)));\n};\nfunction toBytes(obj) {\n  if (obj instanceof Uint8Array && obj.constructor.name === 'Uint8Array') {\n    return obj;\n  }\n  if (obj instanceof ArrayBuffer) {\n    return new Uint8Array(obj);\n  }\n  if (ArrayBuffer.isView(obj)) {\n    return new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength);\n  }\n  throw new Error('Unknown type, must be binary type');\n}\nexport function compare(b1, b2) {\n  if (isBuffer(b1) && isBuffer(b2)) {\n    return b1.compare(b2);\n  }\n  for (let i = 0; i < b1.length; i++) {\n    if (b1[i] === b2[i]) {\n      continue;\n    }\n    return b1[i] < b2[i] ? -1 : 1;\n  }\n  return 0;\n}\nfunction utf8ToBytes(string, units = Infinity) {\n  let codePoint;\n  const length = string.length;\n  let leadSurrogate = null;\n  const bytes = [];\n  for (let i = 0; i < length; ++i) {\n    codePoint = string.charCodeAt(i);\n    if (codePoint > 55295 && codePoint < 57344) {\n      if (!leadSurrogate) {\n        if (codePoint > 56319) {\n          if ((units -= 3) > -1)\n            bytes.push(239, 191, 189);\n          continue;\n        } else if (i + 1 === length) {\n          if ((units -= 3) > -1)\n            bytes.push(239, 191, 189);\n          continue;\n        }\n        leadSurrogate = codePoint;\n        continue;\n      }\n      if (codePoint < 56320) {\n        if ((units -= 3) > -1)\n          bytes.push(239, 191, 189);\n        leadSurrogate = codePoint;\n        continue;\n      }\n      codePoint = (leadSurrogate - 55296 << 10 | codePoint - 56320) + 65536;\n    } else if (leadSurrogate) {\n      if ((units -= 3) > -1)\n        bytes.push(239, 191, 189);\n    }\n    leadSurrogate = null;\n    if (codePoint < 128) {\n      if ((units -= 1) < 0)\n        break;\n      bytes.push(codePoint);\n    } else if (codePoint < 2048) {\n      if ((units -= 2) < 0)\n        break;\n      bytes.push(codePoint >> 6 | 192, codePoint & 63 | 128);\n    } else if (codePoint < 65536) {\n      if ((units -= 3) < 0)\n        break;\n      bytes.push(codePoint >> 12 | 224, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else if (codePoint < 1114112) {\n      if ((units -= 4) < 0)\n        break;\n      bytes.push(codePoint >> 18 | 240, codePoint >> 12 & 63 | 128, codePoint >> 6 & 63 | 128, codePoint & 63 | 128);\n    } else {\n      throw new Error('Invalid code point');\n    }\n  }\n  return bytes;\n}\nfunction utf8Slice(buf, offset, end) {\n  const res = [];\n  while (offset < end) {\n    const firstByte = buf[offset];\n    let codePoint = null;\n    let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;\n    if (offset + bytesPerSequence <= end) {\n      let secondByte, thirdByte, fourthByte, tempCodePoint;\n      switch (bytesPerSequence) {\n      case 1:\n        if (firstByte < 128) {\n          codePoint = firstByte;\n        }\n        break;\n      case 2:\n        secondByte = buf[offset + 1];\n        if ((secondByte & 192) === 128) {\n          tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;\n          if (tempCodePoint > 127) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 3:\n        secondByte = buf[offset + 1];\n        thirdByte = buf[offset + 2];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;\n          if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 4:\n        secondByte = buf[offset + 1];\n        thirdByte = buf[offset + 2];\n        fourthByte = buf[offset + 3];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;\n          if (tempCodePoint > 65535 && tempCodePoint < 1114112) {\n            codePoint = tempCodePoint;\n          }\n        }\n      }\n    }\n    if (codePoint === null) {\n      codePoint = 65533;\n      bytesPerSequence = 1;\n    } else if (codePoint > 65535) {\n      codePoint -= 65536;\n      res.push(codePoint >>> 10 & 1023 | 55296);\n      codePoint = 56320 | codePoint & 1023;\n    }\n    res.push(codePoint);\n    offset += bytesPerSequence;\n  }\n  return decodeCodePointsArray(res);\n}\nconst MAX_ARGUMENTS_LENGTH = 4096;\nexport function decodeCodePointsArray(codePoints) {\n  const len = codePoints.length;\n  if (len <= MAX_ARGUMENTS_LENGTH) {\n    return String.fromCharCode.apply(String, codePoints);\n  }\n  let res = '';\n  let i = 0;\n  while (i < len) {\n    res += String.fromCharCode.apply(String, codePoints.slice(i, i += MAX_ARGUMENTS_LENGTH));\n  }\n  return res;\n}","import {\n  alloc,\n  concat,\n  slice\n} from './byte-utils.js';\nconst defaultChunkSize = 256;\nexport class Bl {\n  constructor(chunkSize = defaultChunkSize) {\n    this.chunkSize = chunkSize;\n    this.cursor = 0;\n    this.maxCursor = -1;\n    this.chunks = [];\n    this._initReuseChunk = null;\n  }\n  reset() {\n    this.cursor = 0;\n    this.maxCursor = -1;\n    if (this.chunks.length) {\n      this.chunks = [];\n    }\n    if (this._initReuseChunk !== null) {\n      this.chunks.push(this._initReuseChunk);\n      this.maxCursor = this._initReuseChunk.length - 1;\n    }\n  }\n  push(bytes) {\n    let topChunk = this.chunks[this.chunks.length - 1];\n    const newMax = this.cursor + bytes.length;\n    if (newMax <= this.maxCursor + 1) {\n      const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n      topChunk.set(bytes, chunkPos);\n    } else {\n      if (topChunk) {\n        const chunkPos = topChunk.length - (this.maxCursor - this.cursor) - 1;\n        if (chunkPos < topChunk.length) {\n          this.chunks[this.chunks.length - 1] = topChunk.subarray(0, chunkPos);\n          this.maxCursor = this.cursor - 1;\n        }\n      }\n      if (bytes.length < 64 && bytes.length < this.chunkSize) {\n        topChunk = alloc(this.chunkSize);\n        this.chunks.push(topChunk);\n        this.maxCursor += topChunk.length;\n        if (this._initReuseChunk === null) {\n          this._initReuseChunk = topChunk;\n        }\n        topChunk.set(bytes, 0);\n      } else {\n        this.chunks.push(bytes);\n        this.maxCursor += bytes.length;\n      }\n    }\n    this.cursor += bytes.length;\n  }\n  toBytes(reset = false) {\n    let byts;\n    if (this.chunks.length === 1) {\n      const chunk = this.chunks[0];\n      if (reset && this.cursor > chunk.length / 2) {\n        byts = this.cursor === chunk.length ? chunk : chunk.subarray(0, this.cursor);\n        this._initReuseChunk = null;\n        this.chunks = [];\n      } else {\n        byts = slice(chunk, 0, this.cursor);\n      }\n    } else {\n      byts = concat(this.chunks, this.cursor);\n    }\n    if (reset) {\n      this.reset();\n    }\n    return byts;\n  }\n}","const decodeErrPrefix = 'CBOR decode error:';\nconst encodeErrPrefix = 'CBOR encode error:';\nconst uintMinorPrefixBytes = [];\nuintMinorPrefixBytes[23] = 1;\nuintMinorPrefixBytes[24] = 2;\nuintMinorPrefixBytes[25] = 3;\nuintMinorPrefixBytes[26] = 5;\nuintMinorPrefixBytes[27] = 9;\nfunction assertEnoughData(data, pos, need) {\n  if (data.length - pos < need) {\n    throw new Error(`${ decodeErrPrefix } not enough data for type`);\n  }\n}\nexport {\n  decodeErrPrefix,\n  encodeErrPrefix,\n  uintMinorPrefixBytes,\n  assertEnoughData\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport {\n  decodeErrPrefix,\n  assertEnoughData\n} from './common.js';\nexport const uintBoundaries = [\n  24,\n  256,\n  65536,\n  4294967296,\n  BigInt('18446744073709551616')\n];\nexport function readUint8(data, offset, options) {\n  assertEnoughData(data, offset, 1);\n  const value = data[offset];\n  if (options.strict === true && value < uintBoundaries[0]) {\n    throw new Error(`${ decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nexport function readUint16(data, offset, options) {\n  assertEnoughData(data, offset, 2);\n  const value = data[offset] << 8 | data[offset + 1];\n  if (options.strict === true && value < uintBoundaries[1]) {\n    throw new Error(`${ decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nexport function readUint32(data, offset, options) {\n  assertEnoughData(data, offset, 4);\n  const value = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  if (options.strict === true && value < uintBoundaries[2]) {\n    throw new Error(`${ decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  return value;\n}\nexport function readUint64(data, offset, options) {\n  assertEnoughData(data, offset, 8);\n  const hi = data[offset] * 16777216 + (data[offset + 1] << 16) + (data[offset + 2] << 8) + data[offset + 3];\n  const lo = data[offset + 4] * 16777216 + (data[offset + 5] << 16) + (data[offset + 6] << 8) + data[offset + 7];\n  const value = (BigInt(hi) << BigInt(32)) + BigInt(lo);\n  if (options.strict === true && value < uintBoundaries[3]) {\n    throw new Error(`${ decodeErrPrefix } integer encoded in more bytes than necessary (strict decode)`);\n  }\n  if (value <= Number.MAX_SAFE_INTEGER) {\n    return Number(value);\n  }\n  if (options.allowBigInt === true) {\n    return value;\n  }\n  throw new Error(`${ decodeErrPrefix } integers outside of the safe integer range are not supported`);\n}\nexport function decodeUint8(data, pos, _minor, options) {\n  return new Token(Type.uint, readUint8(data, pos + 1, options), 2);\n}\nexport function decodeUint16(data, pos, _minor, options) {\n  return new Token(Type.uint, readUint16(data, pos + 1, options), 3);\n}\nexport function decodeUint32(data, pos, _minor, options) {\n  return new Token(Type.uint, readUint32(data, pos + 1, options), 5);\n}\nexport function decodeUint64(data, pos, _minor, options) {\n  return new Token(Type.uint, readUint64(data, pos + 1, options), 9);\n}\nexport function encodeUint(buf, token) {\n  return encodeUintValue(buf, 0, token.value);\n}\nexport function encodeUintValue(buf, major, uint) {\n  if (uint < uintBoundaries[0]) {\n    const nuint = Number(uint);\n    buf.push([major | nuint]);\n  } else if (uint < uintBoundaries[1]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 24,\n      nuint\n    ]);\n  } else if (uint < uintBoundaries[2]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 25,\n      nuint >>> 8,\n      nuint & 255\n    ]);\n  } else if (uint < uintBoundaries[3]) {\n    const nuint = Number(uint);\n    buf.push([\n      major | 26,\n      nuint >>> 24 & 255,\n      nuint >>> 16 & 255,\n      nuint >>> 8 & 255,\n      nuint & 255\n    ]);\n  } else {\n    const buint = BigInt(uint);\n    if (buint < uintBoundaries[4]) {\n      const set = [\n        major | 27,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0,\n        0\n      ];\n      let lo = Number(buint & BigInt(4294967295));\n      let hi = Number(buint >> BigInt(32) & BigInt(4294967295));\n      set[8] = lo & 255;\n      lo = lo >> 8;\n      set[7] = lo & 255;\n      lo = lo >> 8;\n      set[6] = lo & 255;\n      lo = lo >> 8;\n      set[5] = lo & 255;\n      set[4] = hi & 255;\n      hi = hi >> 8;\n      set[3] = hi & 255;\n      hi = hi >> 8;\n      set[2] = hi & 255;\n      hi = hi >> 8;\n      set[1] = hi & 255;\n      buf.push(set);\n    } else {\n      throw new Error(`${ decodeErrPrefix } encountered BigInt larger than allowable range`);\n    }\n  }\n}\nencodeUint.encodedSize = function encodedSize(token) {\n  return encodeUintValue.encodedSize(token.value);\n};\nencodeUintValue.encodedSize = function encodedSize(uint) {\n  if (uint < uintBoundaries[0]) {\n    return 1;\n  }\n  if (uint < uintBoundaries[1]) {\n    return 2;\n  }\n  if (uint < uintBoundaries[2]) {\n    return 3;\n  }\n  if (uint < uintBoundaries[3]) {\n    return 5;\n  }\n  return 9;\n};\nencodeUint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? -1 : tok1.value > tok2.value ? 1 : 0;\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport * as uint from './0uint.js';\nimport { decodeErrPrefix } from './common.js';\nexport function decodeNegint8(data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint8(data, pos + 1, options), 2);\n}\nexport function decodeNegint16(data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint16(data, pos + 1, options), 3);\n}\nexport function decodeNegint32(data, pos, _minor, options) {\n  return new Token(Type.negint, -1 - uint.readUint32(data, pos + 1, options), 5);\n}\nconst neg1b = BigInt(-1);\nconst pos1b = BigInt(1);\nexport function decodeNegint64(data, pos, _minor, options) {\n  const int = uint.readUint64(data, pos + 1, options);\n  if (typeof int !== 'bigint') {\n    const value = -1 - int;\n    if (value >= Number.MIN_SAFE_INTEGER) {\n      return new Token(Type.negint, value, 9);\n    }\n  }\n  if (options.allowBigInt !== true) {\n    throw new Error(`${ decodeErrPrefix } integers outside of the safe integer range are not supported`);\n  }\n  return new Token(Type.negint, neg1b - BigInt(int), 9);\n}\nexport function encodeNegint(buf, token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n  uint.encodeUintValue(buf, token.type.majorEncoded, unsigned);\n}\nencodeNegint.encodedSize = function encodedSize(token) {\n  const negint = token.value;\n  const unsigned = typeof negint === 'bigint' ? negint * neg1b - pos1b : negint * -1 - 1;\n  if (unsigned < uint.uintBoundaries[0]) {\n    return 1;\n  }\n  if (unsigned < uint.uintBoundaries[1]) {\n    return 2;\n  }\n  if (unsigned < uint.uintBoundaries[2]) {\n    return 3;\n  }\n  if (unsigned < uint.uintBoundaries[3]) {\n    return 5;\n  }\n  return 9;\n};\nencodeNegint.compareTokens = function compareTokens(tok1, tok2) {\n  return tok1.value < tok2.value ? 1 : tok1.value > tok2.value ? -1 : 0;\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport {\n  assertEnoughData,\n  decodeErrPrefix\n} from './common.js';\nimport * as uint from './0uint.js';\nimport {\n  compare,\n  fromString,\n  slice\n} from './byte-utils.js';\nfunction toToken(data, pos, prefix, length) {\n  assertEnoughData(data, pos, prefix + length);\n  const buf = slice(data, pos + prefix, pos + prefix + length);\n  return new Token(Type.bytes, buf, prefix + length);\n}\nexport function decodeBytesCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nexport function decodeBytes8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options));\n}\nexport function decodeBytes16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options));\n}\nexport function decodeBytes32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options));\n}\nexport function decodeBytes64(data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ decodeErrPrefix } 64-bit integer bytes lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nfunction tokenBytes(token) {\n  if (token.encodedBytes === undefined) {\n    token.encodedBytes = token.type === Type.string ? fromString(token.value) : token.value;\n  }\n  return token.encodedBytes;\n}\nexport function encodeBytes(buf, token) {\n  const bytes = tokenBytes(token);\n  uint.encodeUintValue(buf, token.type.majorEncoded, bytes.length);\n  buf.push(bytes);\n}\nencodeBytes.encodedSize = function encodedSize(token) {\n  const bytes = tokenBytes(token);\n  return uint.encodeUintValue.encodedSize(bytes.length) + bytes.length;\n};\nencodeBytes.compareTokens = function compareTokens(tok1, tok2) {\n  return compareBytes(tokenBytes(tok1), tokenBytes(tok2));\n};\nexport function compareBytes(b1, b2) {\n  return b1.length < b2.length ? -1 : b1.length > b2.length ? 1 : compare(b1, b2);\n}","import {\n  Token,\n  Type\n} from './token.js';\nimport {\n  assertEnoughData,\n  decodeErrPrefix\n} from './common.js';\nimport * as uint from './0uint.js';\nimport { encodeBytes } from './2bytes.js';\nimport {\n  toString,\n  slice\n} from './byte-utils.js';\nfunction toToken(data, pos, prefix, length, options) {\n  const totLength = prefix + length;\n  assertEnoughData(data, pos, totLength);\n  const tok = new Token(Type.string, toString(data, pos + prefix, pos + totLength), totLength);\n  if (options.retainStringBytes === true) {\n    tok.byteValue = slice(data, pos + prefix, pos + totLength);\n  }\n  return tok;\n}\nexport function decodeStringCompact(data, pos, minor, options) {\n  return toToken(data, pos, 1, minor, options);\n}\nexport function decodeString8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options), options);\n}\nexport function decodeString16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options), options);\n}\nexport function decodeString32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options), options);\n}\nexport function decodeString64(data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ decodeErrPrefix } 64-bit integer string lengths not supported`);\n  }\n  return toToken(data, pos, 9, l, options);\n}\nexport const encodeString = encodeBytes;","import {\n  Token,\n  Type\n} from './token.js';\nimport * as uint from './0uint.js';\nimport { decodeErrPrefix } from './common.js';\nfunction toToken(_data, _pos, prefix, length) {\n  return new Token(Type.array, length, prefix);\n}\nexport function decodeArrayCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nexport function decodeArray8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options));\n}\nexport function decodeArray16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options));\n}\nexport function decodeArray32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options));\n}\nexport function decodeArray64(data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ decodeErrPrefix } 64-bit integer array lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nexport function decodeArrayIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return toToken(data, pos, 1, Infinity);\n}\nexport function encodeArray(buf, token) {\n  uint.encodeUintValue(buf, Type.array.majorEncoded, token.value);\n}\nencodeArray.compareTokens = uint.encodeUint.compareTokens;\nencodeArray.encodedSize = function encodedSize(token) {\n  return uint.encodeUintValue.encodedSize(token.value);\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport * as uint from './0uint.js';\nimport { decodeErrPrefix } from './common.js';\nfunction toToken(_data, _pos, prefix, length) {\n  return new Token(Type.map, length, prefix);\n}\nexport function decodeMapCompact(data, pos, minor, _options) {\n  return toToken(data, pos, 1, minor);\n}\nexport function decodeMap8(data, pos, _minor, options) {\n  return toToken(data, pos, 2, uint.readUint8(data, pos + 1, options));\n}\nexport function decodeMap16(data, pos, _minor, options) {\n  return toToken(data, pos, 3, uint.readUint16(data, pos + 1, options));\n}\nexport function decodeMap32(data, pos, _minor, options) {\n  return toToken(data, pos, 5, uint.readUint32(data, pos + 1, options));\n}\nexport function decodeMap64(data, pos, _minor, options) {\n  const l = uint.readUint64(data, pos + 1, options);\n  if (typeof l === 'bigint') {\n    throw new Error(`${ decodeErrPrefix } 64-bit integer map lengths not supported`);\n  }\n  return toToken(data, pos, 9, l);\n}\nexport function decodeMapIndefinite(data, pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return toToken(data, pos, 1, Infinity);\n}\nexport function encodeMap(buf, token) {\n  uint.encodeUintValue(buf, Type.map.majorEncoded, token.value);\n}\nencodeMap.compareTokens = uint.encodeUint.compareTokens;\nencodeMap.encodedSize = function encodedSize(token) {\n  return uint.encodeUintValue.encodedSize(token.value);\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport * as uint from './0uint.js';\nexport function decodeTagCompact(_data, _pos, minor, _options) {\n  return new Token(Type.tag, minor, 1);\n}\nexport function decodeTag8(data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint8(data, pos + 1, options), 2);\n}\nexport function decodeTag16(data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint16(data, pos + 1, options), 3);\n}\nexport function decodeTag32(data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint32(data, pos + 1, options), 5);\n}\nexport function decodeTag64(data, pos, _minor, options) {\n  return new Token(Type.tag, uint.readUint64(data, pos + 1, options), 9);\n}\nexport function encodeTag(buf, token) {\n  uint.encodeUintValue(buf, Type.tag.majorEncoded, token.value);\n}\nencodeTag.compareTokens = uint.encodeUint.compareTokens;\nencodeTag.encodedSize = function encodedSize(token) {\n  return uint.encodeUintValue.encodedSize(token.value);\n};","import {\n  Token,\n  Type\n} from './token.js';\nimport { decodeErrPrefix } from './common.js';\nimport { encodeUint } from './0uint.js';\nconst MINOR_FALSE = 20;\nconst MINOR_TRUE = 21;\nconst MINOR_NULL = 22;\nconst MINOR_UNDEFINED = 23;\nexport function decodeUndefined(_data, _pos, _minor, options) {\n  if (options.allowUndefined === false) {\n    throw new Error(`${ decodeErrPrefix } undefined values are not supported`);\n  } else if (options.coerceUndefinedToNull === true) {\n    return new Token(Type.null, null, 1);\n  }\n  return new Token(Type.undefined, undefined, 1);\n}\nexport function decodeBreak(_data, _pos, _minor, options) {\n  if (options.allowIndefinite === false) {\n    throw new Error(`${ decodeErrPrefix } indefinite length items not allowed`);\n  }\n  return new Token(Type.break, undefined, 1);\n}\nfunction createToken(value, bytes, options) {\n  if (options) {\n    if (options.allowNaN === false && Number.isNaN(value)) {\n      throw new Error(`${ decodeErrPrefix } NaN values are not supported`);\n    }\n    if (options.allowInfinity === false && (value === Infinity || value === -Infinity)) {\n      throw new Error(`${ decodeErrPrefix } Infinity values are not supported`);\n    }\n  }\n  return new Token(Type.float, value, bytes);\n}\nexport function decodeFloat16(data, pos, _minor, options) {\n  return createToken(readFloat16(data, pos + 1), 3, options);\n}\nexport function decodeFloat32(data, pos, _minor, options) {\n  return createToken(readFloat32(data, pos + 1), 5, options);\n}\nexport function decodeFloat64(data, pos, _minor, options) {\n  return createToken(readFloat64(data, pos + 1), 9, options);\n}\nexport function encodeFloat(buf, token, options) {\n  const float = token.value;\n  if (float === false) {\n    buf.push([Type.float.majorEncoded | MINOR_FALSE]);\n  } else if (float === true) {\n    buf.push([Type.float.majorEncoded | MINOR_TRUE]);\n  } else if (float === null) {\n    buf.push([Type.float.majorEncoded | MINOR_NULL]);\n  } else if (float === undefined) {\n    buf.push([Type.float.majorEncoded | MINOR_UNDEFINED]);\n  } else {\n    let decoded;\n    let success = false;\n    if (!options || options.float64 !== true) {\n      encodeFloat16(float);\n      decoded = readFloat16(ui8a, 1);\n      if (float === decoded || Number.isNaN(float)) {\n        ui8a[0] = 249;\n        buf.push(ui8a.slice(0, 3));\n        success = true;\n      } else {\n        encodeFloat32(float);\n        decoded = readFloat32(ui8a, 1);\n        if (float === decoded) {\n          ui8a[0] = 250;\n          buf.push(ui8a.slice(0, 5));\n          success = true;\n        }\n      }\n    }\n    if (!success) {\n      encodeFloat64(float);\n      decoded = readFloat64(ui8a, 1);\n      ui8a[0] = 251;\n      buf.push(ui8a.slice(0, 9));\n    }\n  }\n}\nencodeFloat.encodedSize = function encodedSize(token, options) {\n  const float = token.value;\n  if (float === false || float === true || float === null || float === undefined) {\n    return 1;\n  }\n  if (!options || options.float64 !== true) {\n    encodeFloat16(float);\n    let decoded = readFloat16(ui8a, 1);\n    if (float === decoded || Number.isNaN(float)) {\n      return 3;\n    }\n    encodeFloat32(float);\n    decoded = readFloat32(ui8a, 1);\n    if (float === decoded) {\n      return 5;\n    }\n  }\n  return 9;\n};\nconst buffer = new ArrayBuffer(9);\nconst dataView = new DataView(buffer, 1);\nconst ui8a = new Uint8Array(buffer, 0);\nfunction encodeFloat16(inp) {\n  if (inp === Infinity) {\n    dataView.setUint16(0, 31744, false);\n  } else if (inp === -Infinity) {\n    dataView.setUint16(0, 64512, false);\n  } else if (Number.isNaN(inp)) {\n    dataView.setUint16(0, 32256, false);\n  } else {\n    dataView.setFloat32(0, inp);\n    const valu32 = dataView.getUint32(0);\n    const exponent = (valu32 & 2139095040) >> 23;\n    const mantissa = valu32 & 8388607;\n    if (exponent === 255) {\n      dataView.setUint16(0, 31744, false);\n    } else if (exponent === 0) {\n      dataView.setUint16(0, (inp & 2147483648) >> 16 | mantissa >> 13, false);\n    } else {\n      const logicalExponent = exponent - 127;\n      if (logicalExponent < -24) {\n        dataView.setUint16(0, 0);\n      } else if (logicalExponent < -14) {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | 1 << 24 + logicalExponent, false);\n      } else {\n        dataView.setUint16(0, (valu32 & 2147483648) >> 16 | logicalExponent + 15 << 10 | mantissa >> 13, false);\n      }\n    }\n  }\n}\nfunction readFloat16(ui8a, pos) {\n  if (ui8a.length - pos < 2) {\n    throw new Error(`${ decodeErrPrefix } not enough data for float16`);\n  }\n  const half = (ui8a[pos] << 8) + ui8a[pos + 1];\n  if (half === 31744) {\n    return Infinity;\n  }\n  if (half === 64512) {\n    return -Infinity;\n  }\n  if (half === 32256) {\n    return NaN;\n  }\n  const exp = half >> 10 & 31;\n  const mant = half & 1023;\n  let val;\n  if (exp === 0) {\n    val = mant * 2 ** -24;\n  } else if (exp !== 31) {\n    val = (mant + 1024) * 2 ** (exp - 25);\n  } else {\n    val = mant === 0 ? Infinity : NaN;\n  }\n  return half & 32768 ? -val : val;\n}\nfunction encodeFloat32(inp) {\n  dataView.setFloat32(0, inp, false);\n}\nfunction readFloat32(ui8a, pos) {\n  if (ui8a.length - pos < 4) {\n    throw new Error(`${ decodeErrPrefix } not enough data for float32`);\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 4).getFloat32(0, false);\n}\nfunction encodeFloat64(inp) {\n  dataView.setFloat64(0, inp, false);\n}\nfunction readFloat64(ui8a, pos) {\n  if (ui8a.length - pos < 8) {\n    throw new Error(`${ decodeErrPrefix } not enough data for float64`);\n  }\n  const offset = (ui8a.byteOffset || 0) + pos;\n  return new DataView(ui8a.buffer, offset, 8).getFloat64(0, false);\n}\nencodeFloat.compareTokens = encodeUint.compareTokens;","import {\n  Token,\n  Type\n} from './token.js';\nimport * as uint from './0uint.js';\nimport * as negint from './1negint.js';\nimport * as bytes from './2bytes.js';\nimport * as string from './3string.js';\nimport * as array from './4array.js';\nimport * as map from './5map.js';\nimport * as tag from './6tag.js';\nimport * as float from './7float.js';\nimport { decodeErrPrefix } from './common.js';\nimport { fromArray } from './byte-utils.js';\nfunction invalidMinor(data, pos, minor) {\n  throw new Error(`${ decodeErrPrefix } encountered invalid minor (${ minor }) for major ${ data[pos] >>> 5 }`);\n}\nfunction errorer(msg) {\n  return () => {\n    throw new Error(`${ decodeErrPrefix } ${ msg }`);\n  };\n}\nexport const jump = [];\nfor (let i = 0; i <= 23; i++) {\n  jump[i] = invalidMinor;\n}\njump[24] = uint.decodeUint8;\njump[25] = uint.decodeUint16;\njump[26] = uint.decodeUint32;\njump[27] = uint.decodeUint64;\njump[28] = invalidMinor;\njump[29] = invalidMinor;\njump[30] = invalidMinor;\njump[31] = invalidMinor;\nfor (let i = 32; i <= 55; i++) {\n  jump[i] = invalidMinor;\n}\njump[56] = negint.decodeNegint8;\njump[57] = negint.decodeNegint16;\njump[58] = negint.decodeNegint32;\njump[59] = negint.decodeNegint64;\njump[60] = invalidMinor;\njump[61] = invalidMinor;\njump[62] = invalidMinor;\njump[63] = invalidMinor;\nfor (let i = 64; i <= 87; i++) {\n  jump[i] = bytes.decodeBytesCompact;\n}\njump[88] = bytes.decodeBytes8;\njump[89] = bytes.decodeBytes16;\njump[90] = bytes.decodeBytes32;\njump[91] = bytes.decodeBytes64;\njump[92] = invalidMinor;\njump[93] = invalidMinor;\njump[94] = invalidMinor;\njump[95] = errorer('indefinite length bytes/strings are not supported');\nfor (let i = 96; i <= 119; i++) {\n  jump[i] = string.decodeStringCompact;\n}\njump[120] = string.decodeString8;\njump[121] = string.decodeString16;\njump[122] = string.decodeString32;\njump[123] = string.decodeString64;\njump[124] = invalidMinor;\njump[125] = invalidMinor;\njump[126] = invalidMinor;\njump[127] = errorer('indefinite length bytes/strings are not supported');\nfor (let i = 128; i <= 151; i++) {\n  jump[i] = array.decodeArrayCompact;\n}\njump[152] = array.decodeArray8;\njump[153] = array.decodeArray16;\njump[154] = array.decodeArray32;\njump[155] = array.decodeArray64;\njump[156] = invalidMinor;\njump[157] = invalidMinor;\njump[158] = invalidMinor;\njump[159] = array.decodeArrayIndefinite;\nfor (let i = 160; i <= 183; i++) {\n  jump[i] = map.decodeMapCompact;\n}\njump[184] = map.decodeMap8;\njump[185] = map.decodeMap16;\njump[186] = map.decodeMap32;\njump[187] = map.decodeMap64;\njump[188] = invalidMinor;\njump[189] = invalidMinor;\njump[190] = invalidMinor;\njump[191] = map.decodeMapIndefinite;\nfor (let i = 192; i <= 215; i++) {\n  jump[i] = tag.decodeTagCompact;\n}\njump[216] = tag.decodeTag8;\njump[217] = tag.decodeTag16;\njump[218] = tag.decodeTag32;\njump[219] = tag.decodeTag64;\njump[220] = invalidMinor;\njump[221] = invalidMinor;\njump[222] = invalidMinor;\njump[223] = invalidMinor;\nfor (let i = 224; i <= 243; i++) {\n  jump[i] = errorer('simple values are not supported');\n}\njump[244] = invalidMinor;\njump[245] = invalidMinor;\njump[246] = invalidMinor;\njump[247] = float.decodeUndefined;\njump[248] = errorer('simple values are not supported');\njump[249] = float.decodeFloat16;\njump[250] = float.decodeFloat32;\njump[251] = float.decodeFloat64;\njump[252] = invalidMinor;\njump[253] = invalidMinor;\njump[254] = invalidMinor;\njump[255] = float.decodeBreak;\nexport const quick = [];\nfor (let i = 0; i < 24; i++) {\n  quick[i] = new Token(Type.uint, i, 1);\n}\nfor (let i = -1; i >= -24; i--) {\n  quick[31 - i] = new Token(Type.negint, i, 1);\n}\nquick[64] = new Token(Type.bytes, new Uint8Array(0), 1);\nquick[96] = new Token(Type.string, '', 1);\nquick[128] = new Token(Type.array, 0, 1);\nquick[160] = new Token(Type.map, 0, 1);\nquick[244] = new Token(Type.false, false, 1);\nquick[245] = new Token(Type.true, true, 1);\nquick[246] = new Token(Type.null, null, 1);\nexport function quickEncodeToken(token) {\n  switch (token.type) {\n  case Type.false:\n    return fromArray([244]);\n  case Type.true:\n    return fromArray([245]);\n  case Type.null:\n    return fromArray([246]);\n  case Type.bytes:\n    if (!token.value.length) {\n      return fromArray([64]);\n    }\n    return;\n  case Type.string:\n    if (token.value === '') {\n      return fromArray([96]);\n    }\n    return;\n  case Type.array:\n    if (token.value === 0) {\n      return fromArray([128]);\n    }\n    return;\n  case Type.map:\n    if (token.value === 0) {\n      return fromArray([160]);\n    }\n    return;\n  case Type.uint:\n    if (token.value < 24) {\n      return fromArray([Number(token.value)]);\n    }\n    return;\n  case Type.negint:\n    if (token.value >= -24) {\n      return fromArray([31 - Number(token.value)]);\n    }\n  }\n}","import { is } from './is.js';\nimport {\n  Token,\n  Type\n} from './token.js';\nimport { Bl } from './bl.js';\nimport { encodeErrPrefix } from './common.js';\nimport { quickEncodeToken } from './jump.js';\nimport { asU8A } from './byte-utils.js';\nimport { encodeUint } from './0uint.js';\nimport { encodeNegint } from './1negint.js';\nimport { encodeBytes } from './2bytes.js';\nimport { encodeString } from './3string.js';\nimport { encodeArray } from './4array.js';\nimport { encodeMap } from './5map.js';\nimport { encodeTag } from './6tag.js';\nimport { encodeFloat } from './7float.js';\nconst defaultEncodeOptions = {\n  float64: false,\n  mapSorter,\n  quickEncodeToken\n};\nexport function makeCborEncoders() {\n  const encoders = [];\n  encoders[Type.uint.major] = encodeUint;\n  encoders[Type.negint.major] = encodeNegint;\n  encoders[Type.bytes.major] = encodeBytes;\n  encoders[Type.string.major] = encodeString;\n  encoders[Type.array.major] = encodeArray;\n  encoders[Type.map.major] = encodeMap;\n  encoders[Type.tag.major] = encodeTag;\n  encoders[Type.float.major] = encodeFloat;\n  return encoders;\n}\nconst cborEncoders = makeCborEncoders();\nconst buf = new Bl();\nclass Ref {\n  constructor(obj, parent) {\n    this.obj = obj;\n    this.parent = parent;\n  }\n  includes(obj) {\n    let p = this;\n    do {\n      if (p.obj === obj) {\n        return true;\n      }\n    } while (p = p.parent);\n    return false;\n  }\n  static createCheck(stack, obj) {\n    if (stack && stack.includes(obj)) {\n      throw new Error(`${ encodeErrPrefix } object contains circular references`);\n    }\n    return new Ref(obj, stack);\n  }\n}\nconst simpleTokens = {\n  null: new Token(Type.null, null),\n  undefined: new Token(Type.undefined, undefined),\n  true: new Token(Type.true, true),\n  false: new Token(Type.false, false),\n  emptyArray: new Token(Type.array, 0),\n  emptyMap: new Token(Type.map, 0)\n};\nconst typeEncoders = {\n  number(obj, _typ, _options, _refStack) {\n    if (!Number.isInteger(obj) || !Number.isSafeInteger(obj)) {\n      return new Token(Type.float, obj);\n    } else if (obj >= 0) {\n      return new Token(Type.uint, obj);\n    } else {\n      return new Token(Type.negint, obj);\n    }\n  },\n  bigint(obj, _typ, _options, _refStack) {\n    if (obj >= BigInt(0)) {\n      return new Token(Type.uint, obj);\n    } else {\n      return new Token(Type.negint, obj);\n    }\n  },\n  Uint8Array(obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, obj);\n  },\n  string(obj, _typ, _options, _refStack) {\n    return new Token(Type.string, obj);\n  },\n  boolean(obj, _typ, _options, _refStack) {\n    return obj ? simpleTokens.true : simpleTokens.false;\n  },\n  null(_obj, _typ, _options, _refStack) {\n    return simpleTokens.null;\n  },\n  undefined(_obj, _typ, _options, _refStack) {\n    return simpleTokens.undefined;\n  },\n  ArrayBuffer(obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj));\n  },\n  DataView(obj, _typ, _options, _refStack) {\n    return new Token(Type.bytes, new Uint8Array(obj.buffer, obj.byteOffset, obj.byteLength));\n  },\n  Array(obj, _typ, options, refStack) {\n    if (!obj.length) {\n      if (options.addBreakTokens === true) {\n        return [\n          simpleTokens.emptyArray,\n          new Token(Type.break)\n        ];\n      }\n      return simpleTokens.emptyArray;\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n    for (const e of obj) {\n      entries[i++] = objectToTokens(e, options, refStack);\n    }\n    if (options.addBreakTokens) {\n      return [\n        new Token(Type.array, obj.length),\n        entries,\n        new Token(Type.break)\n      ];\n    }\n    return [\n      new Token(Type.array, obj.length),\n      entries\n    ];\n  },\n  Object(obj, typ, options, refStack) {\n    const isMap = typ !== 'Object';\n    const keys = isMap ? obj.keys() : Object.keys(obj);\n    const length = isMap ? obj.size : keys.length;\n    if (!length) {\n      if (options.addBreakTokens === true) {\n        return [\n          simpleTokens.emptyMap,\n          new Token(Type.break)\n        ];\n      }\n      return simpleTokens.emptyMap;\n    }\n    refStack = Ref.createCheck(refStack, obj);\n    const entries = [];\n    let i = 0;\n    for (const key of keys) {\n      entries[i++] = [\n        objectToTokens(key, options, refStack),\n        objectToTokens(isMap ? obj.get(key) : obj[key], options, refStack)\n      ];\n    }\n    sortMapEntries(entries, options);\n    if (options.addBreakTokens) {\n      return [\n        new Token(Type.map, length),\n        entries,\n        new Token(Type.break)\n      ];\n    }\n    return [\n      new Token(Type.map, length),\n      entries\n    ];\n  }\n};\ntypeEncoders.Map = typeEncoders.Object;\ntypeEncoders.Buffer = typeEncoders.Uint8Array;\nfor (const typ of 'Uint8Clamped Uint16 Uint32 Int8 Int16 Int32 BigUint64 BigInt64 Float32 Float64'.split(' ')) {\n  typeEncoders[`${ typ }Array`] = typeEncoders.DataView;\n}\nfunction objectToTokens(obj, options = {}, refStack) {\n  const typ = is(obj);\n  const customTypeEncoder = options && options.typeEncoders && options.typeEncoders[typ] || typeEncoders[typ];\n  if (typeof customTypeEncoder === 'function') {\n    const tokens = customTypeEncoder(obj, typ, options, refStack);\n    if (tokens != null) {\n      return tokens;\n    }\n  }\n  const typeEncoder = typeEncoders[typ];\n  if (!typeEncoder) {\n    throw new Error(`${ encodeErrPrefix } unsupported type: ${ typ }`);\n  }\n  return typeEncoder(obj, typ, options, refStack);\n}\nfunction sortMapEntries(entries, options) {\n  if (options.mapSorter) {\n    entries.sort(options.mapSorter);\n  }\n}\nfunction mapSorter(e1, e2) {\n  const keyToken1 = Array.isArray(e1[0]) ? e1[0][0] : e1[0];\n  const keyToken2 = Array.isArray(e2[0]) ? e2[0][0] : e2[0];\n  if (keyToken1.type !== keyToken2.type) {\n    return keyToken1.type.compare(keyToken2.type);\n  }\n  const major = keyToken1.type.major;\n  const tcmp = cborEncoders[major].compareTokens(keyToken1, keyToken2);\n  if (tcmp === 0) {\n    console.warn('WARNING: complex key types used, CBOR key sorting guarantees are gone');\n  }\n  return tcmp;\n}\nfunction tokensToEncoded(buf, tokens, encoders, options) {\n  if (Array.isArray(tokens)) {\n    for (const token of tokens) {\n      tokensToEncoded(buf, token, encoders, options);\n    }\n  } else {\n    encoders[tokens.type.major](buf, tokens, options);\n  }\n}\nfunction encodeCustom(data, encoders, options) {\n  const tokens = objectToTokens(data, options);\n  if (!Array.isArray(tokens) && options.quickEncodeToken) {\n    const quickBytes = options.quickEncodeToken(tokens);\n    if (quickBytes) {\n      return quickBytes;\n    }\n    const encoder = encoders[tokens.type.major];\n    if (encoder.encodedSize) {\n      const size = encoder.encodedSize(tokens, options);\n      const buf = new Bl(size);\n      encoder(buf, tokens, options);\n      if (buf.chunks.length !== 1) {\n        throw new Error(`Unexpected error: pre-calculated length for ${ tokens } was wrong`);\n      }\n      return asU8A(buf.chunks[0]);\n    }\n  }\n  buf.reset();\n  tokensToEncoded(buf, tokens, encoders, options);\n  return buf.toBytes(true);\n}\nfunction encode(data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options);\n  return encodeCustom(data, cborEncoders, options);\n}\nexport {\n  objectToTokens,\n  encode,\n  encodeCustom,\n  Ref\n};","import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport {\n  jump,\n  quick\n} from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${ decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${ decodeErrPrefix } tag not supported (${ token.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport {\n  Tokeniser,\n  tokensToObject,\n  decode\n};","import setPrototypeOf from \"./setPrototypeOf.js\";\nimport isNativeReflectConstruct from \"./isNativeReflectConstruct.js\";\nexport default function _construct(Parent, args, Class) {\n  if (isNativeReflectConstruct()) {\n    _construct = Reflect.construct.bind();\n  } else {\n    _construct = function _construct(Parent, args, Class) {\n      var a = [null];\n      a.push.apply(a, args);\n      var Constructor = Function.bind.apply(Parent, a);\n      var instance = new Constructor();\n      if (Class) setPrototypeOf(instance, Class.prototype);\n      return instance;\n    };\n  }\n\n  return _construct.apply(null, arguments);\n}","import getPrototypeOf from \"./getPrototypeOf.js\";\nimport setPrototypeOf from \"./setPrototypeOf.js\";\nimport isNativeFunction from \"./isNativeFunction.js\";\nimport construct from \"./construct.js\";\nexport default function _wrapNativeSuper(Class) {\n  var _cache = typeof Map === \"function\" ? new Map() : undefined;\n\n  _wrapNativeSuper = function _wrapNativeSuper(Class) {\n    if (Class === null || !isNativeFunction(Class)) return Class;\n\n    if (typeof Class !== \"function\") {\n      throw new TypeError(\"Super expression must either be null or a function\");\n    }\n\n    if (typeof _cache !== \"undefined\") {\n      if (_cache.has(Class)) return _cache.get(Class);\n\n      _cache.set(Class, Wrapper);\n    }\n\n    function Wrapper() {\n      return construct(Class, arguments, getPrototypeOf(this).constructor);\n    }\n\n    Wrapper.prototype = Object.create(Class.prototype, {\n      constructor: {\n        value: Wrapper,\n        enumerable: false,\n        writable: true,\n        configurable: true\n      }\n    });\n    return setPrototypeOf(Wrapper, Class);\n  };\n\n  return _wrapNativeSuper(Class);\n}","export default function _isNativeFunction(fn) {\n  return Function.toString.call(fn).indexOf(\"[native code]\") !== -1;\n}","import { Type } from '../token.js';\nimport { encodeCustom } from '../encode.js';\nimport { encodeErrPrefix } from '../common.js';\nimport {\n  asU8A,\n  fromString\n} from '../byte-utils.js';\nclass JSONEncoder extends Array {\n  constructor() {\n    super();\n    this.inRecursive = [];\n  }\n  prefix(buf) {\n    const recurs = this.inRecursive[this.inRecursive.length - 1];\n    if (recurs) {\n      if (recurs.type === Type.array) {\n        recurs.elements++;\n        if (recurs.elements !== 1) {\n          buf.push([44]);\n        }\n      }\n      if (recurs.type === Type.map) {\n        recurs.elements++;\n        if (recurs.elements !== 1) {\n          if (recurs.elements % 2 === 1) {\n            buf.push([44]);\n          } else {\n            buf.push([58]);\n          }\n        }\n      }\n    }\n  }\n  [Type.uint.major](buf, token) {\n    this.prefix(buf);\n    const is = String(token.value);\n    const isa = [];\n    for (let i = 0; i < is.length; i++) {\n      isa[i] = is.charCodeAt(i);\n    }\n    buf.push(isa);\n  }\n  [Type.negint.major](buf, token) {\n    this[Type.uint.major](buf, token);\n  }\n  [Type.bytes.major](_buf, _token) {\n    throw new Error(`${ encodeErrPrefix } unsupported type: Uint8Array`);\n  }\n  [Type.string.major](buf, token) {\n    this.prefix(buf);\n    const byts = fromString(JSON.stringify(token.value));\n    buf.push(byts.length > 32 ? asU8A(byts) : byts);\n  }\n  [Type.array.major](buf, _token) {\n    this.prefix(buf);\n    this.inRecursive.push({\n      type: Type.array,\n      elements: 0\n    });\n    buf.push([91]);\n  }\n  [Type.map.major](buf, _token) {\n    this.prefix(buf);\n    this.inRecursive.push({\n      type: Type.map,\n      elements: 0\n    });\n    buf.push([123]);\n  }\n  [Type.tag.major](_buf, _token) {\n  }\n  [Type.float.major](buf, token) {\n    if (token.type.name === 'break') {\n      const recurs = this.inRecursive.pop();\n      if (recurs) {\n        if (recurs.type === Type.array) {\n          buf.push([93]);\n        } else if (recurs.type === Type.map) {\n          buf.push([125]);\n        } else {\n          throw new Error('Unexpected recursive type; this should not happen!');\n        }\n        return;\n      }\n      throw new Error('Unexpected break; this should not happen!');\n    }\n    if (token.value === undefined) {\n      throw new Error(`${ encodeErrPrefix } unsupported type: undefined`);\n    }\n    this.prefix(buf);\n    if (token.type.name === 'true') {\n      buf.push([\n        116,\n        114,\n        117,\n        101\n      ]);\n      return;\n    } else if (token.type.name === 'false') {\n      buf.push([\n        102,\n        97,\n        108,\n        115,\n        101\n      ]);\n      return;\n    } else if (token.type.name === 'null') {\n      buf.push([\n        110,\n        117,\n        108,\n        108\n      ]);\n      return;\n    }\n    const is = String(token.value);\n    const isa = [];\n    let dp = false;\n    for (let i = 0; i < is.length; i++) {\n      isa[i] = is.charCodeAt(i);\n      if (!dp && (isa[i] === 46 || isa[i] === 101 || isa[i] === 69)) {\n        dp = true;\n      }\n    }\n    if (!dp) {\n      isa.push(46);\n      isa.push(48);\n    }\n    buf.push(isa);\n  }\n}\nfunction mapSorter(e1, e2) {\n  if (Array.isArray(e1[0]) || Array.isArray(e2[0])) {\n    throw new Error(`${ encodeErrPrefix } complex map keys are not supported`);\n  }\n  const keyToken1 = e1[0];\n  const keyToken2 = e2[0];\n  if (keyToken1.type !== Type.string || keyToken2.type !== Type.string) {\n    throw new Error(`${ encodeErrPrefix } non-string map keys are not supported`);\n  }\n  if (keyToken1 < keyToken2) {\n    return -1;\n  }\n  if (keyToken1 > keyToken2) {\n    return 1;\n  }\n  throw new Error(`${ encodeErrPrefix } unexpected duplicate map keys, this is not supported`);\n}\nconst defaultEncodeOptions = {\n  addBreakTokens: true,\n  mapSorter\n};\nfunction encode(data, options) {\n  options = Object.assign({}, defaultEncodeOptions, options);\n  return encodeCustom(data, new JSONEncoder(), options);\n}\nexport {\n  encode\n};","import { decode as _decode } from '../decode.js';\nimport {\n  Token,\n  Type\n} from '../token.js';\nimport { decodeCodePointsArray } from '../byte-utils.js';\nimport { decodeErrPrefix } from '../common.js';\nclass Tokenizer {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n    this.modeStack = ['value'];\n    this.lastToken = '';\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  ch() {\n    return this.data[this.pos];\n  }\n  currentMode() {\n    return this.modeStack[this.modeStack.length - 1];\n  }\n  skipWhitespace() {\n    let c = this.ch();\n    while (c === 32 || c === 9 || c === 13 || c === 10) {\n      c = this.data[++this.pos];\n    }\n  }\n  expect(str) {\n    if (this.data.length - this.pos < str.length) {\n      throw new Error(`${ decodeErrPrefix } unexpected end of input at position ${ this.pos }`);\n    }\n    for (let i = 0; i < str.length; i++) {\n      if (this.data[this.pos++] !== str[i]) {\n        throw new Error(`${ decodeErrPrefix } unexpected token at position ${ this.pos }, expected to find '${ String.fromCharCode(...str) }'`);\n      }\n    }\n  }\n  parseNumber() {\n    const startPos = this.pos;\n    let negative = false;\n    let float = false;\n    const swallow = chars => {\n      while (!this.done()) {\n        const ch = this.ch();\n        if (chars.includes(ch)) {\n          this.pos++;\n        } else {\n          break;\n        }\n      }\n    };\n    if (this.ch() === 45) {\n      negative = true;\n      this.pos++;\n    }\n    if (this.ch() === 48) {\n      this.pos++;\n      if (this.ch() === 46) {\n        this.pos++;\n        float = true;\n      } else {\n        return new Token(Type.uint, 0, this.pos - startPos);\n      }\n    }\n    swallow([\n      48,\n      49,\n      50,\n      51,\n      52,\n      53,\n      54,\n      55,\n      56,\n      57\n    ]);\n    if (negative && this.pos === startPos + 1) {\n      throw new Error(`${ decodeErrPrefix } unexpected token at position ${ this.pos }`);\n    }\n    if (!this.done() && this.ch() === 46) {\n      if (float) {\n        throw new Error(`${ decodeErrPrefix } unexpected token at position ${ this.pos }`);\n      }\n      float = true;\n      this.pos++;\n      swallow([\n        48,\n        49,\n        50,\n        51,\n        52,\n        53,\n        54,\n        55,\n        56,\n        57\n      ]);\n    }\n    if (!this.done() && (this.ch() === 101 || this.ch() === 69)) {\n      float = true;\n      this.pos++;\n      if (!this.done() && (this.ch() === 43 || this.ch() === 45)) {\n        this.pos++;\n      }\n      swallow([\n        48,\n        49,\n        50,\n        51,\n        52,\n        53,\n        54,\n        55,\n        56,\n        57\n      ]);\n    }\n    const numStr = String.fromCharCode.apply(null, this.data.subarray(startPos, this.pos));\n    const num = parseFloat(numStr);\n    if (float) {\n      return new Token(Type.float, num, this.pos - startPos);\n    }\n    if (this.options.allowBigInt !== true || Number.isSafeInteger(num)) {\n      return new Token(num >= 0 ? Type.uint : Type.negint, num, this.pos - startPos);\n    }\n    return new Token(num >= 0 ? Type.uint : Type.negint, BigInt(numStr), this.pos - startPos);\n  }\n  parseString() {\n    if (this.ch() !== 34) {\n      throw new Error(`${ decodeErrPrefix } unexpected character at position ${ this.pos }; this shouldn't happen`);\n    }\n    this.pos++;\n    for (let i = this.pos, l = 0; i < this.data.length && l < 65536; i++, l++) {\n      const ch = this.data[i];\n      if (ch === 92 || ch < 32 || ch >= 128) {\n        break;\n      }\n      if (ch === 34) {\n        const str = String.fromCharCode.apply(null, this.data.subarray(this.pos, i));\n        this.pos = i + 1;\n        return new Token(Type.string, str, l);\n      }\n    }\n    const startPos = this.pos;\n    const chars = [];\n    const readu4 = () => {\n      if (this.pos + 4 >= this.data.length) {\n        throw new Error(`${ decodeErrPrefix } unexpected end of unicode escape sequence at position ${ this.pos }`);\n      }\n      let u4 = 0;\n      for (let i = 0; i < 4; i++) {\n        let ch = this.ch();\n        if (ch >= 48 && ch <= 57) {\n          ch -= 48;\n        } else if (ch >= 97 && ch <= 102) {\n          ch = ch - 97 + 10;\n        } else if (ch >= 65 && ch <= 70) {\n          ch = ch - 65 + 10;\n        } else {\n          throw new Error(`${ decodeErrPrefix } unexpected unicode escape character at position ${ this.pos }`);\n        }\n        u4 = u4 * 16 + ch;\n        this.pos++;\n      }\n      return u4;\n    };\n    const readUtf8Char = () => {\n      const firstByte = this.ch();\n      let codePoint = null;\n      let bytesPerSequence = firstByte > 239 ? 4 : firstByte > 223 ? 3 : firstByte > 191 ? 2 : 1;\n      if (this.pos + bytesPerSequence > this.data.length) {\n        throw new Error(`${ decodeErrPrefix } unexpected unicode sequence at position ${ this.pos }`);\n      }\n      let secondByte, thirdByte, fourthByte, tempCodePoint;\n      switch (bytesPerSequence) {\n      case 1:\n        if (firstByte < 128) {\n          codePoint = firstByte;\n        }\n        break;\n      case 2:\n        secondByte = this.data[this.pos + 1];\n        if ((secondByte & 192) === 128) {\n          tempCodePoint = (firstByte & 31) << 6 | secondByte & 63;\n          if (tempCodePoint > 127) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 3:\n        secondByte = this.data[this.pos + 1];\n        thirdByte = this.data[this.pos + 2];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 12 | (secondByte & 63) << 6 | thirdByte & 63;\n          if (tempCodePoint > 2047 && (tempCodePoint < 55296 || tempCodePoint > 57343)) {\n            codePoint = tempCodePoint;\n          }\n        }\n        break;\n      case 4:\n        secondByte = this.data[this.pos + 1];\n        thirdByte = this.data[this.pos + 2];\n        fourthByte = this.data[this.pos + 3];\n        if ((secondByte & 192) === 128 && (thirdByte & 192) === 128 && (fourthByte & 192) === 128) {\n          tempCodePoint = (firstByte & 15) << 18 | (secondByte & 63) << 12 | (thirdByte & 63) << 6 | fourthByte & 63;\n          if (tempCodePoint > 65535 && tempCodePoint < 1114112) {\n            codePoint = tempCodePoint;\n          }\n        }\n      }\n      if (codePoint === null) {\n        codePoint = 65533;\n        bytesPerSequence = 1;\n      } else if (codePoint > 65535) {\n        codePoint -= 65536;\n        chars.push(codePoint >>> 10 & 1023 | 55296);\n        codePoint = 56320 | codePoint & 1023;\n      }\n      chars.push(codePoint);\n      this.pos += bytesPerSequence;\n    };\n    while (!this.done()) {\n      const ch = this.ch();\n      let ch1;\n      switch (ch) {\n      case 92:\n        this.pos++;\n        if (this.done()) {\n          throw new Error(`${ decodeErrPrefix } unexpected string termination at position ${ this.pos }`);\n        }\n        ch1 = this.ch();\n        this.pos++;\n        switch (ch1) {\n        case 34:\n        case 39:\n        case 92:\n        case 47:\n          chars.push(ch1);\n          break;\n        case 98:\n          chars.push(8);\n          break;\n        case 116:\n          chars.push(9);\n          break;\n        case 110:\n          chars.push(10);\n          break;\n        case 102:\n          chars.push(12);\n          break;\n        case 114:\n          chars.push(13);\n          break;\n        case 117:\n          chars.push(readu4());\n          break;\n        default:\n          throw new Error(`${ decodeErrPrefix } unexpected string escape character at position ${ this.pos }`);\n        }\n        break;\n      case 34:\n        this.pos++;\n        return new Token(Type.string, decodeCodePointsArray(chars), this.pos - startPos);\n      default:\n        if (ch < 32) {\n          throw new Error(`${ decodeErrPrefix } invalid control character at position ${ this.pos }`);\n        } else if (ch < 128) {\n          chars.push(ch);\n          this.pos++;\n        } else {\n          readUtf8Char();\n        }\n      }\n    }\n    throw new Error(`${ decodeErrPrefix } unexpected end of string at position ${ this.pos }`);\n  }\n  parseValue() {\n    switch (this.ch()) {\n    case 123:\n      this.modeStack.push('obj-start');\n      this.pos++;\n      return new Token(Type.map, Infinity, 1);\n    case 91:\n      this.modeStack.push('array-start');\n      this.pos++;\n      return new Token(Type.array, Infinity, 1);\n    case 34: {\n        return this.parseString();\n      }\n    case 110:\n      this.expect([\n        110,\n        117,\n        108,\n        108\n      ]);\n      return new Token(Type.null, null, 4);\n    case 102:\n      this.expect([\n        102,\n        97,\n        108,\n        115,\n        101\n      ]);\n      return new Token(Type.false, false, 5);\n    case 116:\n      this.expect([\n        116,\n        114,\n        117,\n        101\n      ]);\n      return new Token(Type.true, true, 4);\n    case 45:\n    case 48:\n    case 49:\n    case 50:\n    case 51:\n    case 52:\n    case 53:\n    case 54:\n    case 55:\n    case 56:\n    case 57:\n      return this.parseNumber();\n    default:\n      throw new Error(`${ decodeErrPrefix } unexpected character at position ${ this.pos }`);\n    }\n  }\n  next() {\n    this.skipWhitespace();\n    switch (this.currentMode()) {\n    case 'value':\n      this.modeStack.pop();\n      return this.parseValue();\n    case 'array-value': {\n        this.modeStack.pop();\n        if (this.ch() === 93) {\n          this.pos++;\n          this.skipWhitespace();\n          return new Token(Type.break, undefined, 1);\n        }\n        if (this.ch() !== 44) {\n          throw new Error(`${ decodeErrPrefix } unexpected character at position ${ this.pos }, was expecting array delimiter but found '${ String.fromCharCode(this.ch()) }'`);\n        }\n        this.pos++;\n        this.modeStack.push('array-value');\n        this.skipWhitespace();\n        return this.parseValue();\n      }\n    case 'array-start': {\n        this.modeStack.pop();\n        if (this.ch() === 93) {\n          this.pos++;\n          this.skipWhitespace();\n          return new Token(Type.break, undefined, 1);\n        }\n        this.modeStack.push('array-value');\n        this.skipWhitespace();\n        return this.parseValue();\n      }\n    case 'obj-key':\n      if (this.ch() === 125) {\n        this.modeStack.pop();\n        this.pos++;\n        this.skipWhitespace();\n        return new Token(Type.break, undefined, 1);\n      }\n      if (this.ch() !== 44) {\n        throw new Error(`${ decodeErrPrefix } unexpected character at position ${ this.pos }, was expecting object delimiter but found '${ String.fromCharCode(this.ch()) }'`);\n      }\n      this.pos++;\n      this.skipWhitespace();\n    case 'obj-start': {\n        this.modeStack.pop();\n        if (this.ch() === 125) {\n          this.pos++;\n          this.skipWhitespace();\n          return new Token(Type.break, undefined, 1);\n        }\n        const token = this.parseString();\n        this.skipWhitespace();\n        if (this.ch() !== 58) {\n          throw new Error(`${ decodeErrPrefix } unexpected character at position ${ this.pos }, was expecting key/value delimiter ':' but found '${ String.fromCharCode(this.ch()) }'`);\n        }\n        this.pos++;\n        this.modeStack.push('obj-value');\n        return token;\n      }\n    case 'obj-value': {\n        this.modeStack.pop();\n        this.modeStack.push('obj-key');\n        this.skipWhitespace();\n        return this.parseValue();\n      }\n    default:\n      throw new Error(`${ decodeErrPrefix } unexpected parse state at position ${ this.pos }; this shouldn't happen`);\n    }\n  }\n}\nfunction decode(data, options) {\n  options = Object.assign({ tokenizer: new Tokenizer(data, options) }, options);\n  return _decode(data, options);\n}\nexport {\n  decode,\n  Tokenizer\n};","import { CID } from 'multiformats';\nimport { base64 } from 'multiformats/bases/base64';\nimport {\n  Token,\n  Type\n} from 'cborg';\nimport * as cborgJson from 'cborg/json';\nfunction cidEncoder(obj) {\n  if (obj.asCID !== obj) {\n    return null;\n  }\n  const cid = CID.asCID(obj);\n  if (!cid) {\n    return null;\n  }\n  const cidString = cid.toString();\n  return [\n    new Token(Type.map, Infinity, 1),\n    new Token(Type.string, '/', 1),\n    new Token(Type.string, cidString, cidString.length),\n    new Token(Type.break, undefined, 1)\n  ];\n}\nfunction bytesEncoder(bytes) {\n  const bytesString = base64.encode(bytes).slice(1);\n  return [\n    new Token(Type.map, Infinity, 1),\n    new Token(Type.string, '/', 1),\n    new Token(Type.map, Infinity, 1),\n    new Token(Type.string, 'bytes', 5),\n    new Token(Type.string, bytesString, bytesString.length),\n    new Token(Type.break, undefined, 1),\n    new Token(Type.break, undefined, 1)\n  ];\n}\nfunction undefinedEncoder() {\n  throw new Error('`undefined` is not supported by the IPLD Data Model and cannot be encoded');\n}\nfunction numberEncoder(num) {\n  if (Number.isNaN(num)) {\n    throw new Error('`NaN` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n  if (num === Infinity || num === -Infinity) {\n    throw new Error('`Infinity` and `-Infinity` is not supported by the IPLD Data Model and cannot be encoded');\n  }\n  return null;\n}\nconst encodeOptions = {\n  typeEncoders: {\n    Object: cidEncoder,\n    Uint8Array: bytesEncoder,\n    Buffer: bytesEncoder,\n    undefined: undefinedEncoder,\n    number: numberEncoder\n  }\n};\nclass DagJsonTokenizer extends cborgJson.Tokenizer {\n  constructor(data, options) {\n    super(data, options);\n    this.tokenBuffer = [];\n  }\n  done() {\n    return this.tokenBuffer.length === 0 && super.done();\n  }\n  _next() {\n    if (this.tokenBuffer.length > 0) {\n      return this.tokenBuffer.pop();\n    }\n    return super.next();\n  }\n  next() {\n    const token = this._next();\n    if (token.type === Type.map) {\n      const keyToken = this._next();\n      if (keyToken.type === Type.string && keyToken.value === '/') {\n        const valueToken = this._next();\n        if (valueToken.type === Type.string) {\n          const breakToken = this._next();\n          if (breakToken.type !== Type.break) {\n            throw new Error('Invalid encoded CID form');\n          }\n          this.tokenBuffer.push(valueToken);\n          return new Token(Type.tag, 42, 0);\n        }\n        if (valueToken.type === Type.map) {\n          const innerKeyToken = this._next();\n          if (innerKeyToken.type === Type.string && innerKeyToken.value === 'bytes') {\n            const innerValueToken = this._next();\n            if (innerValueToken.type === Type.string) {\n              for (let i = 0; i < 2; i++) {\n                const breakToken = this._next();\n                if (breakToken.type !== Type.break) {\n                  throw new Error('Invalid encoded Bytes form');\n                }\n              }\n              const bytes = base64.decode(`m${ innerValueToken.value }`);\n              return new Token(Type.bytes, bytes, innerValueToken.value.length);\n            }\n            this.tokenBuffer.push(innerValueToken);\n          }\n          this.tokenBuffer.push(innerKeyToken);\n        }\n        this.tokenBuffer.push(valueToken);\n      }\n      this.tokenBuffer.push(keyToken);\n    }\n    return token;\n  }\n}\nconst decodeOptions = {\n  allowIndefinite: false,\n  allowUndefined: false,\n  allowNaN: false,\n  allowInfinity: false,\n  allowBigInt: true,\n  strict: true,\n  useMaps: false,\n  tags: []\n};\ndecodeOptions.tags[42] = CID.parse;\nexport const name = 'dag-json';\nexport const code = 297;\nexport const encode = node => cborgJson.encode(node, encodeOptions);\nexport const decode = data => {\n  const options = Object.assign(decodeOptions, { tokenizer: new DagJsonTokenizer(data, decodeOptions) });\n  return cborgJson.decode(data, options);\n};","/**\n * Isomorphic, functional type-checking for Javascript.\n * @module typical\n * @typicalname t\n * @example\n * const t = require('typical')\n * const allDefined = array.every(t.isDefined)\n */\n\n/**\n * Returns true if input is a number. It is a more reasonable alternative to `typeof n` which returns `number` for `NaN` and `Infinity`.\n *\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n * @example\n * > t.isNumber(0)\n * true\n * > t.isNumber(1)\n * true\n * > t.isNumber(1.1)\n * true\n * > t.isNumber(0xff)\n * true\n * > t.isNumber(0644)\n * true\n * > t.isNumber(6.2e5)\n * true\n * > t.isNumber(NaN)\n * false\n * > t.isNumber(Infinity)\n * false\n */\nexport function isNumber (n) {\n  return !isNaN(parseFloat(n)) && isFinite(n)\n}\n\n/**\n * A plain object is a simple object literal, it is not an instance of a class. Returns true if the input `typeof` is `object` and directly decends from `Object`.\n *\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n * @example\n * > t.isPlainObject({ something: 'one' })\n * true\n * > t.isPlainObject(new Date())\n * false\n * > t.isPlainObject([ 0, 1 ])\n * false\n * > t.isPlainObject(/test/)\n * false\n * > t.isPlainObject(1)\n * false\n * > t.isPlainObject('one')\n * false\n * > t.isPlainObject(null)\n * false\n * > t.isPlainObject((function * () {})())\n * false\n * > t.isPlainObject(function * () {})\n * false\n */\nexport function isPlainObject (input) {\n  return input !== null && typeof input === 'object' && input.constructor === Object\n}\n\n/**\n * An array-like value has all the properties of an array yet is not an array instance. An example is the `arguments` object. Returns `true`` if the input value is an object, not `null`` and has a `length` property set with a numeric value.\n *\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n * @example\n * function sum(x, y){\n *   console.log(t.isArrayLike(arguments))\n *   // prints `true`\n * }\n */\nexport function isArrayLike (input) {\n  return isObject(input) && typeof input.length === 'number'\n}\n\n/**\n * Returns true if the typeof input is `'object'` but not null.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isObject (input) {\n  return typeof input === 'object' && input !== null\n}\n\n/**\n * Returns true if the input value is defined.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isDefined (input) {\n  return typeof input !== 'undefined'\n}\n\n/**\n * Returns true if the input value is undefined.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isUndefined (input) {\n  return !isDefined(input)\n}\n\n/**\n * Returns true if the input value is null.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isNull (input) {\n return input === null\n}\n\n/**\n * Returns true if the input value is not one of `undefined`, `null`, or `NaN`.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isDefinedValue (input) {\n return isDefined(input) && !isNull(input) && !Number.isNaN(input)\n}\n\n/**\n * Returns true if the input value is an ES2015 `class`.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isClass (input) {\n  if (typeof input === 'function') {\n    return /^class /.test(Function.prototype.toString.call(input))\n  } else {\n    return false\n  }\n}\n\n/**\n * Returns true if the input is a string, number, symbol, boolean, null or undefined value.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isPrimitive (input) {\n  if (input === null) return true\n  switch (typeof input) {\n    case 'string':\n    case 'number':\n    case 'symbol':\n    case 'undefined':\n    case 'boolean':\n      return true\n    default:\n      return false\n  }\n}\n\n/**\n * Returns true if the input is a Promise.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isPromise (input) {\n  if (input) {\n    const isPromise = isDefined(Promise) && input instanceof Promise\n    const isThenable = input.then && typeof input.then === 'function'\n    return !!(isPromise || isThenable)\n  } else {\n    return false\n  }\n}\n\n/**\n * Returns true if the input is an iterable (`Map`, `Set`, `Array`, Generator etc.).\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n * @example\n * > t.isIterable('string')\n * true\n * > t.isIterable(new Map())\n * true\n * > t.isIterable([])\n * true\n * > t.isIterable((function * () {})())\n * true\n * > t.isIterable(Promise.resolve())\n * false\n * > t.isIterable(Promise)\n * false\n * > t.isIterable(true)\n * false\n * > t.isIterable({})\n * false\n * > t.isIterable(0)\n * false\n * > t.isIterable(1.1)\n * false\n * > t.isIterable(NaN)\n * false\n * > t.isIterable(Infinity)\n * false\n * > t.isIterable(function () {})\n * false\n * > t.isIterable(Date)\n * false\n * > t.isIterable()\n * false\n * > t.isIterable({ then: function () {} })\n * false\n */\nexport function isIterable (input) {\n  if (input === null || !isDefined(input)) {\n    return false\n  } else {\n    return (\n      typeof input[Symbol.iterator] === 'function' ||\n      typeof input[Symbol.asyncIterator] === 'function'\n    )\n  }\n}\n\n/**\n * Returns true if the input value is a string. The equivalent of `typeof input === 'string'` for use in funcitonal contexts.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isString (input) {\n  return typeof input === 'string'\n}\n\n/**\n * Returns true if the input value is a function. The equivalent of `typeof input === 'function'` for use in funcitonal contexts.\n * @param {*} - the input to test\n * @returns {boolean}\n * @static\n */\nexport function isFunction (input) {\n  return typeof input === 'function'\n}\n\nexport default {\n  isNumber,\n  isPlainObject,\n  isArrayLike,\n  isObject,\n  isDefined,\n  isUndefined,\n  isNull,\n  isDefinedValue,\n  isClass,\n  isPrimitive,\n  isPromise,\n  isIterable,\n  isString,\n  isFunction\n}\n"],"names":["_typeof","obj","Symbol","iterator","constructor","prototype","isDeepEqual","isDeepStrictEqual","_require$codes","require","codes","ERR_AMBIGUOUS_ARGUMENT","ERR_INVALID_ARG_TYPE","ERR_INVALID_ARG_VALUE","ERR_INVALID_RETURN_VALUE","ERR_MISSING_ARGS","AssertionError","inspect","_require$types","isPromise","isRegExp","objectAssign","Object","assign","objectIs","is","Map","lazyLoadComparison","comparison","warned","assert","module","exports","ok","NO_EXCEPTION_SENTINEL","innerFail","message","Error","innerOk","fn","argLen","value","generatedMessage","err","actual","expected","operator","stackStartFn","_len","arguments","length","args","Array","_key","apply","concat","fail","internalMessage","argsLen","undefined","warn","process","emitWarning","console","bind","errArgs","equal","notEqual","deepEqual","notDeepEqual","deepStrictEqual","notDeepStrictEqual","strictEqual","notStrictEqual","Comparison","keys","_this","this","instance","Constructor","TypeError","_classCallCheck","forEach","key","test","compareExceptionKey","a","b","name","expectedException","msg","push","isPrototypeOf","call","getActual","e","checkIsPromise","then","catch","waitForActual","promiseFn","Promise","resolve","resultPromise","expectsError","error","details","fnType","expectsNoError","strict","_len6","_key6","throws","_len2","_key2","rejects","_len3","_key3","result","doesNotThrow","_len4","_key4","doesNotReject","_len5","_key5","ifError","newErr","origStack","stack","tmp2","split","shift","tmp1","i","pos","indexOf","slice","join","_defineProperty","defineProperty","enumerable","configurable","writable","_defineProperties","target","props","descriptor","_possibleConstructorReturn","self","_assertThisInitialized","ReferenceError","_wrapNativeSuper","Class","_cache","Function","toString","has","get","set","Wrapper","_construct","_getPrototypeOf","create","_setPrototypeOf","isNativeReflectConstruct","Reflect","construct","sham","Proxy","Date","Parent","o","p","setPrototypeOf","__proto__","getPrototypeOf","endsWith","str","search","this_len","substring","blue","green","red","white","kReadableOperator","strictEqualObject","notStrictEqualObject","notIdentical","copyError","source","inspectValue","val","compact","customInspect","depth","maxArrayLength","Infinity","showHidden","breakLength","showProxy","sorted","getters","createErrDiff","other","res","lastPos","end","skipped","actualInspected","actualLines","expectedLines","indicator","inputLength","stderr","isTTY","columns","count","Math","floor","maxCount","log","repeat","pop","maxLines","max","_actualLines","printedLines","skippedMsg","cur","expectedLine","actualLine","divergingLines","_Error","options","limit","stackTraceLimit","String","getColorDepth","base","_res","knownOperators","code","captureStackTrace","protoProps","staticProps","subClass","superClass","_inherits","custom","recurseTimes","ctx","ownKeys","getOwnPropertySymbols","filter","sym","getOwnPropertyDescriptor","_objectSpread","util","createErrorType","Base","NodeError","_Base","arg1","arg2","arg3","getMessage","oneOf","thing","isArray","len","map","determiner","substr","replace","type","start","includes","reason","inspected","RangeError","input","_slicedToArray","arr","_arrayWithHoles","_arr","_n","_d","_e","_s","_i","next","done","_iterableToArrayLimit","_nonIterableRest","regexFlagsSupported","flags","arrayFromSet","array","arrayFromMap","objectGetOwnPropertySymbols","numberIsNaN","Number","isNaN","uncurryThis","f","hasOwnProperty","propertyIsEnumerable","objectToString","isAnyArrayBuffer","isArrayBufferView","isDate","isMap","isSet","isNativeError","isBoxedPrimitive","isNumberObject","isStringObject","isBooleanObject","isBigIntObject","isSymbolObject","isFloat32Array","isFloat64Array","isNonIndex","charCodeAt","pow","getOwnNonIndexProperties","compare","x","y","min","innerDeepEqual","val1","val2","memos","buf1","buf2","val1Tag","keys1","keys2","keyCheck","getTime","RegExp","byteLength","Uint8Array","buffer","byteOffset","areSimilarTypedArrays","offset","areSimilarFloatArrays","_keys","_keys2","size","valueOf","Boolean","BigInt","isEqualBoxedPrimitive","getEnumerables","k","iterationType","aKeys","bKeys","symbolKeysA","symbolKeysB","_symbolKeysB","position","val2MemoA","val2MemoB","areEq","objEquiv","delete","setHasEqualElement","memo","setValues","findLooseMatchingPrimitives","prim","setMightHaveLoosePrim","altValue","mapMightHaveLoosePrim","item","curB","mapHasEqualEntry","key1","item1","key2","aValues","Set","add","bValues","_val","setEquiv","aEntries","_aEntries$i","item2","bEntries","_i2","_bEntries$_i","mapEquiv","keysA","inherits","ctor","superCtor","super_","TempCtor","BN","number","endian","isBN","negative","words","_init","Buffer","wordSize","parseHex","r","c","parseBase","mul","num","left","right","cmp","_initNumber","_initArray","_parseHex","_parseBase","strip","toArray","ceil","j","w","off","limbLen","limbPow","total","mod","word","imuln","_iaddn","copy","dest","clone","_expand","_normSign","zeros","groupSizes","groupBases","smallMulTo","out","lo","carry","ncarry","rword","maxJ","padding","groupSize","groupBase","isZero","modn","idivn","toNumber","ret","toJSON","toBuffer","toArrayLike","ArrayType","reqLength","littleEndian","q","andln","iushrn","clz32","_countBits","t","_zeroBits","bitLength","hi","zeroBits","toTwos","width","abs","inotn","iaddn","fromTwos","testn","notn","ineg","isNeg","neg","iuor","ior","or","uor","iuand","iand","and","uand","iuxor","ixor","xor","uxor","bytesNeeded","bitsLeft","setn","bit","wbit","iadd","isub","sub","comb10MulTo","mid","a0","al0","ah0","a1","al1","ah1","a2","al2","ah2","a3","al3","ah3","a4","al4","ah4","a5","al5","ah5","a6","al6","ah6","a7","al7","ah7","a8","al8","ah8","a9","al9","ah9","b0","bl0","bh0","b1","bl1","bh1","b2","bl2","bh2","b3","bl3","bh3","b4","bl4","bh4","b5","bl5","bh5","b6","bl6","bh6","b7","bl7","bh7","b8","bl8","bh8","b9","bl9","bh9","w0","imul","w1","w2","w3","w4","w5","w6","w7","w8","w9","w10","w11","w12","w13","w14","w15","w16","w17","w18","jumboMulTo","FFTM","mulp","mulTo","hncarry","bigMulTo","makeRBT","N","l","revBin","rb","permute","rbt","rws","iws","rtws","itws","transform","s","rtwdf","cos","PI","itwdf","sin","rtwdf_","itwdf_","re","ie","ro","io","rx","guessLen13b","n","m","odd","conjugate","normalize13b","ws","round","convert13b","stub","ph","_","rwst","iwst","nrws","nrwst","niwst","rmws","mulf","muln","sqr","isqr","toBitArray","iushln","bits","carryMask","newCarry","ishln","hint","extended","h","mask","maskedWords","ishrn","shln","ushln","shrn","ushrn","imaskn","maskn","isubn","addn","subn","iabs","_ishlnsubmul","_wordDiv","mode","bhi","diff","qj","div","divmod","positive","divn","umod","divRound","dm","half","r2","acc","egcd","A","B","C","D","g","isEven","yp","xp","im","isOdd","jm","gcd","_invmp","x1","x2","delta","cmpn","invm","bincn","ucmp","gtn","gt","gten","gte","ltn","lt","lten","lte","eqn","eq","Red","toRed","convertTo","_forceRed","fromRed","convertFrom","forceRed","redAdd","redIAdd","redSub","redISub","redShl","shl","redMul","_verify2","redIMul","redSqr","_verify1","redISqr","redSqrt","sqrt","redInvm","redNeg","redPow","primes","k256","p224","p192","p25519","MPrime","tmp","_tmp","K256","P224","P192","P25519","prime","_prime","Mont","imod","rinv","minv","ireduce","rlen","imulK","_strip","output","outLen","prev","mod3","one","nOne","lpow","z","inv","wnd","current","currentLen","mont","u","Rand","rand","generate","_rand","getBytes","getByte","crypto","getRandomValues","msCrypto","window","randomBytes","Transform","StringDecoder","CipherBase","hashMode","_finalOrDigest","final","_final","__final","_decoder","_encoding","update","data","inputEnc","outputEnc","from","outData","_update","_toString","setAutoPadding","getAuthTag","setAuthTag","setAAD","_transform","_flush","alloc","enc","fin","write","MD5","RIPEMD160","sha","Hash","hash","_hash","digest","alg","toLowerCase","elliptic","version","utils","curve","curves","ec","eddsa","getNAF","getJSF","BaseCurve","conf","zero","two","pointFromJSON","gRed","_wnafT1","_wnafT2","_wnafT3","_wnafT4","_bitLength","adjustCount","redN","_maxwellTrick","BasePoint","precomputed","point","validate","_fixedNafMul","doubles","_getDoubles","naf","I","step","nafW","repr","jpoint","mixedAdd","points","toP","_wnafMul","nafPoints","_getNAFPoints","dblp","_wnafMulAdd","defW","coeffs","jacobianResult","wndWidth","comb","toJ","index","jsf","ja","jb","decodePoint","bytes","pointFromX","encodeCompressed","encode","_encode","getX","getY","precompute","power","beta","_getBeta","_hasDoubles","dbl","EdwardsCurve","twisted","mOneA","c2","d","dd","oneC","Point","zOne","_mulA","_mulC","rhs","lhs","y2","pointFromY","isInfinity","normalize","fromJSON","_extDbl","nx","ny","nt","nz","_projDbl","_extAdd","_projAdd","mulAdd","k1","k2","jmulAdd","zi","eqXToP","xc","short","edwards","MontCurve","i4","a24","aa","bb","diffAdd","da","cb","jumlAdd","ShortCurve","tinv","zeroA","threeA","endo","_getEndomorphism","_endoWnafT1","_endoWnafT2","isRed","inf","JPoint","lambda","betas","_getEndoRoots","lambdas","basis","vec","_getEndoBasis","ntinv","prevR","aprxSqrt","v","y1","len1","_endoSplit","v1","v2","c1","p1","p2","q1","q2","ax","_endoWnafMulAdd","npoints","ncoeffs","pre","endoMul","JSON","parse","obj2point","ys1","dyinv","_precompute","negate","zinv","zinv2","ay","pz2","z2","u1","u2","s1","s2","h2","h3","jx","jy","jz","jz4","jyd","jx2","jyd2","jyd4","t1","t2","dny","_zeroDbl","_threeDbl","_dbl","xx","yy","yyyy","yyyy8","c8","gamma","alpha","beta4","beta8","ggamma8","jy2","jxd4","jyd8","trpl","zz","mm","ee","yyu4","kbase","z3","pz3","zs","PresetCurve","defineCurve","sha256","sha384","sha512","HmacDRBG","KeyPair","Signature","EC","nh","keyPair","keyFromPrivate","priv","fromPrivate","keyFromPublic","pub","fromPublic","genKeyPair","drbg","pers","persEnc","entropy","hmacStrength","entropyEnc","nonce","ns2","_truncateToN","truncOnly","sign","bkey","getPrivate","ns1","iter","kp","kpX","recoveryParam","canonical","verify","signature","sinv","getPublic","recoverPubKey","isYOdd","isSecondKey","rInv","getKeyRecoveryParam","Q","Qprime","_importPrivate","privEnc","_importPublic","pubEnc","derive","_importDER","Position","place","getLength","buf","initial","octetLen","rmPadding","constructLength","octets","LN2","slen","toDER","backHalf","parseBytes","EDDSA","pointClass","encodingLength","secret","keyFromSecret","hashInt","messagePrefix","R","Rencoded","encodePoint","s_","pubBytes","S","makeSignature","sig","SG","intFromLE","fromSecret","lastIx","normed","xIsOdd","encodeInt","decodeInt","isPoint","cachedProperty","params","_secret","_pub","_pubBytes","privBytes","getSecret","_R","_S","_Rencoded","_Sencoded","Sencoded","toBytes","toHex","toUpperCase","minAssert","minUtils","zero2","fill","m8","d1","d2","m14","m24","computer","firstSource","to","nextSource","keysArray","nextIndex","nextKey","desc","polyfill","hashConstructor","createKeccakHash","hash_utils_1","randombytes","reject","resp","random_1","pk","_a","secp256k1_1","__export","ethUtil","fields","default","KECCAK256_RLP","KECCAK256_NULL","defineProperties","Account","rlp","balance","stateRoot","codeHash","KECCAK256_NULL_S","trie","isContract","getRaw","keccak256","putRaw","root","put","KECCAK256_RLP_S","Common","BlockHeader","opts","common","chain","_common","hardfork","SHA3_RLP_ARRAY","SHA3_RLP","intToBuffer","empty","allowZero","canonicalDifficulty","parentBlock","cutoff","dif","activeHardfork","bufferToInt","blockTs","timestamp","parentTs","header","parentDif","difficulty","minimumDifficulty","param","hardforkGteHardfork","uncleAddend","uncleHash","equals","exp","validateDifficulty","validateGasLimit","pGasLimit","gasLimit","maxGasLimit","minGasLimit","blockchain","height","isGenesis","getBlock","parentHash","extraData","rlphash","raw","setGenesisParams","genesis","_require","keccak224","keccak384","keccak512","secp256k1","createHash","MAX_INTEGER","TWO_POW256","SHA3_NULL_S","SHA3_NULL","KECCAK256_RLP_ARRAY_S","SHA3_RLP_ARRAY_S","KECCAK256_RLP_ARRAY","SHA3_RLP_S","allocUnsafe","zeroAddress","bufferToHex","setLengthLeft","setLength","setLengthRight","unpad","stripZeros","first","stripHexPrefix","isBuffer","isHexString","padToEven","fromSigned","toUnsigned","keccak","sha3","ripemd160","padded","isValidPrivate","privateKey","privateKeyVerify","isValidPublic","publicKey","sanitize","publicKeyVerify","pubToAddress","publicToAddress","pubKey","publicKeyConvert","privateToPublic","publicKeyCreate","importPublic","ecsign","msgHash","recovery","hashPersonalMessage","prefix","ecrecover","senderPubKey","recover","toRpcSig","fromRpcSig","privateToAddress","isValidAddress","address","isZeroAddress","addHexPrefix","toChecksumAddress","parseInt","isValidChecksumAddress","generateAddress","isPrecompiled","isHexPrefixed","isValidSignature","homestead","SECP256K1_N_DIV_2","SECP256K1_N","baToJSON","ba","_fields","label","field","serialize","getter","setter","allowLess","alias","decode","secp256k1v3","der","privateKeyExport","compressed","privateKeyImport","privateKeyNegate","privateKeyModInverse","privateKeyTweakAdd","tweak","privateKeyTweakMul","publicKeyTweakAdd","publicKeyTweakMul","publicKeyCombine","publicKeys","signatureNormalize","signatureExport","signatureImport","signatureImportLax","sigObj","signOptions","noncefn","algo","attempt","bufferAlgo","bufferData","ecdsaSign","recid","ecdsaVerify","ecdsaRecover","ecdh","ecdhUnsafe","EC_PRIVKEY_EXPORT_DER_COMPRESSED","EC_PRIVKEY_EXPORT_DER_UNCOMPRESSED","lenb","lenbyte","rindex","sindex","rvalue","svalue","ecparams","toPublicKey","bn","scalar","shared","names","mainnet","ropsten","rinkeby","kovan","goerli","supportedHardforks","_chainParams","setChain","_hardfork","_supportedHardforks","setHardfork","baseChain","customChainParams","standardChainParams","_getChainParams","__assign","chains_1","_isSupportedHardfork","changed","onlySupported","hardforks","hf","chainName","topic","_chooseHardfork","hfChanges","blockNumber","activeHfs","activeHardforks","hfBlock","hardforkBlock","hardforkIsActiveOnBlock","hardfork1","hardfork2","onlyActive","posHf1","posHf2","_getHardfork","chainId","_super","getSenderAddress","_from","ethereumjs_util_1","txData","__extends","FakeTransaction","includeSignature","fakeKey","buffer_1","transaction_1","N_DIV_2","ethereumjs_common_1","_validateV","_overrideVSetterWithValidation","Transaction","items","_implementsEIP155","getChainId","pubkey","getSenderPublicKey","verifySignature","_senderPubKey","gteHardfork","useChainIdWhileRecoveringPubKey","cost","fee","getDataFee","toCreationAddress","gasPrice","stringError","errors","getBaseFee","labels","vInt","vDescriptor","onEIP155BlockOrLater","_isSigned","ethjsUtil","addr","bytes_1","eip1191ChainId","hash_1","nonceBN","salt","initCode","fromBuf","saltBuf","initCodeBuf","__exportStar","obj_1","keys_1","calculateSigRecovery","isValidSigRecovery","homesteadOrLater","rBN","sBN","intToHex","arrayContainsArray","superset","subset","some","hex","getBinarySize","fromAscii","stringValue","fromUtf8","toAscii","fromCharCode","toUtf8","getKeys","allowEmpty","match","ReflectOwnKeys","ReflectApply","receiver","getOwnPropertyNames","NumberIsNaN","EventEmitter","init","once","emitter","errorListener","removeListener","resolver","eventTargetAgnosticAddListener","handler","on","addErrorHandlerIfEventEmitter","_events","_eventsCount","_maxListeners","defaultMaxListeners","checkListener","listener","_getMaxListeners","that","_addListener","prepend","events","existing","warning","newListener","emit","unshift","onceWrapper","fired","wrapFn","_onceWrap","state","wrapped","_listeners","unwrap","evlistener","unwrapListeners","arrayClone","listenerCount","addEventListener","wrapListener","arg","removeEventListener","setMaxListeners","getMaxListeners","doError","er","context","listeners","addListener","prependListener","prependOnceListener","list","originalListener","spliceOne","removeAllListeners","rawListeners","eventNames","HashBase","blockSize","_block","_blockSize","_blockOffset","_length","_finalized","chunk","encoding","callback","throwIfNotStringOrBuffer","block","_digest","ripemd","hmac","sha1","sha224","BlockHash","pending","pendingTotal","outSize","padLength","_delta8","_delta32","join32","_pad","Hmac","inner","outer","rotl32","sum32","sum32_3","sum32_4","K","Kh","E","Ah","Bh","Ch","Dh","Eh","T","rh","sh","toHex32","split32","shaCommon","sum32_5","ft_1","sha1_K","SHA1","W","SHA256","SHA224","ch32","maj32","s0_256","s1_256","g0_256","g1_256","sha256_K","T1","T2","SHA512","SHA384","rotr64_hi","rotr64_lo","shr64_hi","shr64_lo","sum64","sum64_hi","sum64_lo","sum64_4_hi","sum64_4_lo","sum64_5_hi","sum64_5_lo","sha512_K","ch64_hi","xh","xl","yh","yl","zh","ch64_lo","zl","maj64_hi","maj64_lo","s0_512_hi","s0_512_lo","s1_512_hi","s1_512_lo","g0_512_hi","g0_512_lo","g1_512_hi","g1_512_lo","_prepareBlock","c0_hi","c0_lo","c1_hi","c1_lo","c2_hi","c2_lo","c3_hi","c3_lo","ah","al","bh","bl","ch","cl","dh","dl","eh","el","fh","fl","gh","gl","hh","hl","c4_hi","c4_lo","T1_hi","T1_lo","T2_hi","T2_lo","rotr32","p32","isSurrogatePair","htonl","zero8","predResist","minEntropy","_reseed","reseedInterval","V","nonceEnc","seed","_hmac","kmac","reseed","addEnc","temp","ErrClass","codec","defaultHashAlg","CID","binaryBlob","path","node","deserialize","parts","isCID","remainderPath","traverse","nextpath","tree","cbor","multicodec","multihashing","multihash","isCircular","uint8ArrayConcat","uint8ArrayFromString","replaceCIDbyTAG","dagNode","circular","cid","Tagged","tagCID","decoder","DAG_CBOR","defaultTags","currentSize","defaultMaxSize","maxSize","configureDecoder","tags","decoderOptions","Decoder","userOptions","cidVersion","hashAlg","hashName","codecName","getNameFromCode","nodeTagged","all","decodeAll","EthAccount","cidFromHash","createResolver","emptyCodeHash","ETH_ACCOUNT_SNAPSHOT","serialized","ethObj","deserialized","RAW","isEmpty","storage","ETH_STORAGE_TRIE","_ethObj","RLP","ipldEthBlock","ethBlockListResolver","ETH_BLOCK_LIST","rawBlock","ethBlockList","rawOmmers","ethBlock","EthBlockHeader","ETH_BLOCK","authorAddress","coinbase","bloom","gasUsed","mixHash","ommerHash","ommers","parent","ETH_STATE_TRIE","transactions","ETH_TX_TRIE","transactionsTrie","transactionReceipts","ETH_TX_RECEIPT_TRIE","receiptTrie","transactionReceiptTrieRoot","transactionTrieRoot","ethAccountSnapshotResolver","ethStateTrieResolver","createTrieResolver","ethStorageTrieResolver","ethTxResolver","ethTxTrieResolver","EthTx","ETH_TX","fromAddress","isContractPublish","toAddress","ethAccountSnapshot","ethStateTrie","ethStorageTrie","ethTx","ethTxTrie","multihashes","rawhash","createUtil","_traverse","KECCAK_256","EthTrieNode","addNibbleToObject","nibble","entries","ii","getLeafValue","trieNode","leafResolver","getValue","createCustomEthTrieNode","rawNode","finalNode","getChildren","valueToAdd","isRawNode","childNode","getKey","mapFromBaseTrie","customEthTrieNode","DEFAULT_HASH_ALG","defaultOptions","blake","blake2b","blake2bInit","blake2bUpdate","blake2bFinal","blake2s","blake2sInit","blake2sUpdate","blake2sFinal","makeB2Hash","table","mur","factory","fromNumberTo32BitBuf","algorithm","sha3_224","arrayBuffer","sha3_256","sha3_384","sha3_512","shake128","shake256","x64","hash128","x86","hash32","identity","sha2256","sha2512","dblSha2256","sha3224","sha3256","sha3384","sha3512","murmur3128","murmur332","addBlake","errcode","Multihashing","coerceCode","functions","newHash","subtle","encodeText","alphabet","codeBuf","string","char","baseX","rfc4648","decodeText","constants","reduce","tupple","nameOrCode","validEncode","isEncoded","encodingFromData","freeze","bitsPerChar","pad","written","SyntaxError","TextEncoder","textDecoder","TextDecoder","textEncoder","text","arrs","baseTable","varint","nameToVarint","constantToCode","nameToCode","codeToName","getNameFromData","prefixedData","getCodeFromName","getCodeFromData","getVarintFromName","getVarintFromCode","varintEncode","addPrefix","multicodecStrOrCode","varintUint8ArrayEncode","rmPrefix","getCodec","getName","getNumber","getCode","getCodeVarint","getVarint","uint8ArrayToString","uint8ArrayToNumber","numberToUint8Array","hexString","multibase","isValidCode","isAppCode","toHexString","fromHexString","toB58String","fromB58String","encoded","hashfn","subarray","arrays","curr","utf8Encoder","asciiStringToUint8Array","utf8Decoder","uint8ArrayToAsciiString","gitUtil","commit","tag","GIT_RAW","gitType","headLen","find","typeLen","SmartBuffer","lines","cidToSha","parents","serializePersonLine","author","committer","mergetag","object","outBuf","writeString","writeUInt8","line","shaToCid","parsePersonLine","startLine","mt","tagger","sort","entry","writeStringNT","writeBuffer","fromBuffer","modeName","readStringNT","readBuffer","SHA1_LENGTH","modNameMatched","strftime","byte","matched","email","date","timezone","isoString","isoStrictToTimestampWithOffset","mh","DAGLink","Name","Tsize","_nameBuf","toBaseEncodedString","_json","createDagLinkFromB58EncodedHash","link","Size","sortLinks","dagLink","asDAGLink","Links","serializeDAGNode","toDAGLink","addLink","rmLink","DAGNode","links","serializedSize","sortedLinks","Data","_serializedSize","_size","_invalidateCached","sum","uint8ArrayEquals","nameOrCid","predicate","splice","uint8ArrayCompare","linkSort","nameAsBuffer","inplace","genCid","nodeCid","$protobuf","$Reader","Reader","$Writer","Writer","$util","$root","roots","PBLink","ks","newBuffer","Long","fromBits","uint32","uint64","skipType","fromObject","base64","fromValue","unsigned","LongBits","low","high","toObject","defaults","longs","toJSONOptions","PBNode","emptyArray","fork","ldelim","DAG_PB","format","protobuf","toProtoBuf","pbn","pbf","writer","finish","serializeDAGNodeLike","objects","Block","mergeOptions","ipldDagCbor","ipldDagPb","ipldRaw","typical","extendIterator","IPLDResolver","blockService","bs","resolvers","loadFormat","formats","addFormat","ipld","generator","getFormat","_error","cids","isIterable","formatImpl","onlyHash","cidOptions","nodes","remove","offsetPath","recursive","maybeRecurse","treePath","treePaths","queue","basePath","paths","fullPath","startsWith","last","values","callBind","define","implementation","getPolyfill","shim","NaN","createKeccak","createShake","KeccakState","Keccak","Shake","rate","capacity","delimitedSuffix","hashBitLength","_rate","_capacity","_delimitedSuffix","_hashBitLength","_options","_state","initialize","absorb","absorbLastFewBits","squeeze","_resetState","dataByteLength","P1600_ROUND_CONSTANTS","p1600","lo0","hi0","lo1","hi1","lo2","hi2","lo3","hi3","lo4","hi4","t1slo0","t1shi0","t1slo5","t1shi5","t1slo10","t1shi10","t1slo15","t1shi15","t1slo20","t1shi20","t1slo1","t1shi1","t1slo6","t1shi6","t1slo11","t1shi11","t1slo16","t1shi16","t1slo21","t1shi21","t1slo2","t1shi2","t1slo7","t1shi7","t1slo12","t1shi12","t1slo17","t1shi17","t1slo22","t1shi22","t1slo3","t1shi3","t1slo8","t1shi8","t1slo13","t1shi13","t1slo18","t1shi18","t1slo23","t1shi23","t1slo4","t1shi4","t1slo9","t1shi9","t1slo14","t1shi14","t1slo19","t1shi19","t1slo24","t1shi24","t2slo0","t2shi0","t2slo16","t2shi16","t2slo7","t2shi7","t2slo23","t2shi23","t2slo14","t2shi14","t2slo10","t2shi10","t2slo1","t2shi1","t2slo17","t2shi17","t2slo8","t2shi8","t2slo24","t2shi24","t2slo20","t2shi20","t2slo11","t2shi11","t2slo2","t2shi2","t2slo18","t2shi18","t2slo9","t2shi9","t2slo5","t2shi5","t2slo21","t2shi21","t2slo12","t2shi12","t2slo3","t2shi3","t2slo19","t2shi19","t2slo15","t2shi15","t2slo6","t2shi6","t2slo22","t2shi22","t2slo13","t2shi13","t2slo4","t2shi4","keccakState","squeezing","ARRAY16","_b","_c","rotl","fnF","fnG","fnH","fnI","M","readInt32LE","writeUInt32LE","writeInt32LE","TrieNode","parseNode","keyVal","setValue","setKey","terminator","removeHexPrefix","isTerminator","stringToNibbles","nibbles","nibblesToBuffer","getNodeType","children","MAX_BYTES","MAX_UINT32","global","generated","nextTick","objectKeys","Duplex","Readable","Writable","method","allowHalfOpen","readable","onend","_writableState","ended","onEndNT","highWaterMark","getBuffer","_readableState","destroyed","PassThrough","ReadableState","EElistenerCount","Stream","OurUint8Array","debug","debugUtil","debuglog","createReadableStreamAsyncIterator","BufferList","destroyImpl","getHighWaterMark","ERR_STREAM_PUSH_AFTER_EOF","ERR_METHOD_NOT_IMPLEMENTED","ERR_STREAM_UNSHIFT_AFTER_END_EVENT","errorOrDestroy","kProxyEvents","stream","isDuplex","objectMode","readableObjectMode","pipes","pipesCount","flowing","endEmitted","reading","sync","needReadable","emittedReadable","readableListening","resumeScheduled","paused","emitClose","autoDestroy","defaultEncoding","awaitDrain","readingMore","read","_read","destroy","_destroy","readableAddChunk","addToFront","skipChunkCheck","emitReadable","emitReadable_","onEofChunk","chunkInvalid","_uint8ArrayToBuffer","addChunk","maybeReadMore","_undestroy","undestroy","isPaused","setEncoding","head","content","clear","MAX_HWM","howMuchToRead","computeNewHighWaterMark","flow","maybeReadMore_","updateReadableListening","resume","nReadingNextTick","resume_","fromList","consume","endReadable","endReadableNT","wState","finished","xs","nOrig","doRead","pipe","pipeOpts","src","endFn","stdout","unpipe","onunpipe","unpipeInfo","hasUnpiped","onclose","onfinish","ondrain","onerror","ondata","cleanedUp","needDrain","pipeOnDrain","pause","event","dests","ev","wrap","asyncIterator","_fromList","iterable","ERR_MULTIPLE_CALLBACK","ERR_TRANSFORM_ALREADY_TRANSFORMING","ERR_TRANSFORM_WITH_LENGTH_0","afterTransform","ts","_transformState","transforming","writecb","writechunk","rs","needTransform","writeencoding","flush","prefinish","_write","err2","CorkedRequest","corkReq","pendingcb","corkedRequestsFree","onCorkedFinish","WritableState","internalUtil","deprecate","realHasInstance","ERR_STREAM_CANNOT_PIPE","ERR_STREAM_DESTROYED","ERR_STREAM_NULL_VALUES","ERR_STREAM_WRITE_AFTER_END","ERR_UNKNOWN_ENCODING","nop","writableObjectMode","finalCalled","ending","noDecode","decodeStrings","writing","corked","bufferProcessing","onwrite","writelen","onwriteStateUpdate","finishMaybe","errorEmitted","onwriteError","needFinish","bufferedRequest","clearBuffer","afterWrite","lastBufferedRequest","prefinished","bufferedRequestCount","writev","_writev","doWrite","onwriteDrain","holder","allBuffers","isBuf","callFinal","need","rState","hasInstance","writeAfterEnd","validChunk","newChunk","decodeChunk","writeOrBuffer","cork","uncork","setDefaultEncoding","endWritable","_Object$setPrototypeO","kLastResolve","kLastReject","kError","kEnded","kLastPromise","kHandlePromise","kStream","createIterResult","readAndResolve","onReadable","AsyncIteratorPrototype","ReadableStreamAsyncIteratorPrototype","promise","lastPromise","wrapForNext","_this2","_Object$create","enumerableOnly","symbols","tail","hasStrings","_getString","_getBuffer","nb","getOwnPropertyDescriptors","emitErrorAndCloseNT","emitErrorNT","emitCloseNT","readableDestroyed","writableDestroyed","ERR_STREAM_PREMATURE_CLOSE","noop","eos","called","onlegacyfinish","writableEnded","readableEnded","onrequest","req","setHeader","abort","isRequest","destroyer","closed","popCallback","streams","destroys","ERR_INVALID_OPT_VALUE","duplexKey","hwm","highWaterMarkFrom","isFinite","pipeline","zr","sl","sr","hr","fn1","fn2","fn3","fn4","fn5","ar","br","cr","dr","tl","tr","safeParseInt","encodeLength","hexLength","firstByte","_decode","llength","innerRemainder","decoded","remainder","totalLength","integer","inputBuf","inputBuffer","copyProps","dst","SafeBuffer","encodingOrOffset","allocUnsafeSlow","SlowBuffer","loadPublicKey","xbuf","loadCompressedPublicKey","ybuf","x3","loadUncompressedPublicKey","savePublicKey","contextRandomize","seckey","tweaked","pair","publicKeyNegate","pubkeys","pairs","sigR","sigS","lenR","posR","lenS","posS","outputlen","_noncefn","counter","msg32","sigr","sigs","cond","isUint8Array","numbers","isCompressed","toTypeString","getAssertedOutput","finalSize","_finalSize","accum","assigned","rem","writeUInt32BE","lowBits","highBits","Algorithm","Sha","_w","rotl30","ft","readInt32BE","H","writeInt32BE","Sha1","rotl5","Sha256","Sha224","_f","_g","_h","maj","sigma0","sigma1","gamma0","Sha384","_ah","_bh","_ch","_dh","_eh","_fh","_gh","_hh","_al","_bl","_cl","_dl","_el","_fl","_gl","_hl","writeInt64BE","Sha512","Gamma0","Gamma0l","Gamma1","Gamma1l","getCarry","gamma0l","gamma1","gamma1l","Wi7h","Wi7l","Wi16h","Wi16l","Wil","Wih","majh","majl","sigma0h","sigma0l","sigma1h","sigma1l","Kih","Kil","chh","chl","t1l","t1h","t2l","t2h","isSmartBufferOptions","utils_1","INVALID_SMARTBUFFER_SIZE","_buff","buff","INVALID_SMARTBUFFER_BUFFER","INVALID_SMARTBUFFER_OBJECT","_readNumberValue","readInt8","readInt16BE","readInt16LE","readBigInt64BE","readBigInt64LE","_writeNumberValue","writeInt8","_insertNumberValue","writeInt16BE","writeInt16LE","writeBigInt64BE","writeBigInt64LE","readUInt8","readUInt16BE","readUInt16LE","readUInt32BE","readUInt32LE","readBigUInt64BE","readBigUInt64LE","writeUInt16BE","writeUInt16LE","writeBigUInt64BE","writeBigUInt64LE","readFloatBE","readFloatLE","writeFloatBE","writeFloatLE","readDoubleBE","readDoubleLE","writeDoubleBE","writeDoubleLE","lengthVal","_readOffset","_handleString","nullPos","insertString","insertUInt8","writeOffset","endPoint","_handleBuffer","insertBuffer","_writeOffset","encodingVal","isInsert","offsetVal","ensureInsertable","_ensureWriteable","INVALID_READ_BEYOND_BOUNDS","dataLength","_ensureCapacity","minLength","oldLength","newLength","func","byteSize","ensureReadable","INVALID_WRITE_BEYOND_BOUNDS","castOptions","ERRORS","INVALID_ENCODING","INVALID_OFFSET","INVALID_OFFSET_NON_NUMBER","INVALID_LENGTH","INVALID_LENGTH_NON_NUMBER","INVALID_TARGET_OFFSET","INVALID_TARGET_LENGTH","isFiniteInteger","isInteger","checkOffsetOrLengthValue","isEncoding","bufferMethod","EE","_isStdio","didOnEnd","cleanup","Locales","de_DE","days","shortDays","months","shortMonths","AM","PM","am","pm","F","X","en_CA","ordinalSuffixes","en_US","es_MX","fr_FR","it_IT","nl_NL","pt_BR","ru_RU","tr_TR","zh_CN","DefaultLocale","defaultStrftime","Strftime","locale","customTimezoneOffset","useUtcTimezone","_cachedDate","_locale","_customTimezoneOffset","_useUtcBasedDate","_cachedDateTimestamp","_processFormat","resultString","isInScope","extendedTZ","currentCharCode","getDay","getMonth","padTill2","getFullYear","getHours","hours12","padTill3","getMinutes","getSeconds","weekNumber","tzString","getDate","day","ordinal","getTimezoneOffset","sep","hours","mins","utcOffset","getTimestampToUtcOffsetFor","newUTCOffset","currentTimestamp","now","localize","localizeByIdentifier","localeIdentifier","useUtcBasedDate","timezoneType","utc","numberToPad","paddingChar","hour","firstWeekday","weekday","firstDayOfYearUtc","UTC","dateUtc","weekNum","nenc","retried","_normalizeEncoding","normalizeEncoding","utf16Text","utf16End","fillLast","utf8FillLast","base64Text","base64End","simpleWrite","simpleEnd","lastNeed","lastTotal","lastChar","utf8CheckByte","utf8CheckExtraBytes","utf8CheckIncomplete","config","localStorage","trace","_superPropBase","property","_get","typeofs","objectTypeNames","typeOf","objectType","objectTypeName","getObjectType","Type","major","terminal","majorEncoded","typ","uint","negint","float","false","true","null","break","Token","encodedLength","encodedBytes","byteValue","useBuffer","globalThis","browser","asU8A","utf8Slice","fromString","utf8ToBytes","chunks","codePoint","units","leadSurrogate","bytesPerSequence","secondByte","thirdByte","fourthByte","tempCodePoint","decodeCodePointsArray","codePoints","Bl","chunkSize","cursor","maxCursor","_initReuseChunk","topChunk","chunkPos","byts","reset","decodeErrPrefix","encodeErrPrefix","uintMinorPrefixBytes","assertEnoughData","uintBoundaries","readUint8","readUint16","readUint32","readUint64","MAX_SAFE_INTEGER","allowBigInt","encodeUint","token","encodeUintValue","nuint","buint","encodedSize","compareTokens","tok1","tok2","neg1b","pos1b","encodeNegint","toToken","decodeBytesCompact","minor","tokenBytes","encodeBytes","totLength","tok","retainStringBytes","decodeStringCompact","encodeString","_data","_pos","decodeArrayCompact","encodeArray","decodeMapCompact","encodeMap","decodeTagCompact","encodeTag","createToken","allowNaN","allowInfinity","encodeFloat","inp","success","float64","encodeFloat16","readFloat16","ui8a","encodeFloat32","readFloat32","dataView","setFloat64","readFloat64","ArrayBuffer","DataView","setUint16","setFloat32","valu32","getUint32","exponent","mantissa","logicalExponent","mant","getFloat32","getFloat64","invalidMinor","errorer","jump","_minor","int","MIN_SAFE_INTEGER","allowIndefinite","allowUndefined","coerceUndefinedToNull","quick","encoders","makeCborEncoders","Ref","simpleTokens","emptyMap","typeEncoders","_typ","_refStack","isSafeInteger","bigint","boolean","_obj","refStack","addBreakTokens","createCheck","objectToTokens","mapSorter","sortMapEntries","customTypeEncoder","tokens","typeEncoder","tokensToEncoded","encodeCustom","quickEncodeToken","quickBytes","encoder","defaultDecodeOptions","Tokeniser","byt","padStart","DONE","for","BREAK","tokensToObject","tokeniser","tokenToArray","useMaps","tokenToMap","tagged","JSONEncoder","inRecursive","recurs","elements","isa","_buf","_token","stringify","dp","defaultEncodeOptions","e1","e2","keyToken1","keyToken2","Tokenizer","modeStack","lastToken","startPos","swallow","chars","numStr","parseFloat","readu4","u4","readUtf8Char","ch1","parseString","expect","parseNumber","skipWhitespace","currentMode","parseValue","tokenizer","bytesEncoder","bytesString","encodeOptions","asCID","cidString","DagJsonTokenizer","tokenBuffer","_next","keyToken","valueToken","innerKeyToken","innerValueToken","cborgJson","decodeOptions","isNumber","isPlainObject","isArrayLike","isObject","isDefined","isUndefined","isNull","isDefinedValue","isClass","isPrimitive","isThenable","isString","isFunction"],"sourceRoot":""}