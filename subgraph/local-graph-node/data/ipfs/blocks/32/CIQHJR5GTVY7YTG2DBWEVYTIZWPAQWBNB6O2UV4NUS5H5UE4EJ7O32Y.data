indPeer: require('./find-peer')(config),\n  provide: require('./provide')(config),\n  // find closest peerId to given peerId\n  query: require('./query')(config)\n})\n","'use strict'\n\nconst CID = require('cids')\nconst multiaddr = require('multiaddr')\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').ImplementsMethod<'provide', import('ipfs-core/src/components/dht')>}\n   */\n  async function * provide (cids, options = {}) {\n    cids = Array.isArray(cids) ? cids : [cids]\n\n    const res = await api.post('dht/provide', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: cids.map(cid => new CID(cid).toString()),\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    for await (let message of res.ndjson()) {\n      message = toCamel(message)\n      message.id = new CID(message.id)\n      if (message.responses) {\n        message.responses = message.responses.map(({ ID, Addrs }) => ({\n          id: ID,\n          addrs: (Addrs || []).map(a => multiaddr(a))\n        }))\n      } else {\n        message.responses = []\n      }\n      yield message\n    }\n  }\n\n  return provide\n})\n","'use strict'\n\nconst CID = require('cids')\nconst multiaddr = require('multiaddr')\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\nconst multipartRequest = require('../lib/multipart-request')\nconst abortSignal = require('../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').ImplementsMethod<'put', import('ipfs-core/src/components/dht')>}\n   */\n  async function * put (key, value, options = {}) {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const res = await api.post('dht/put', {\n      timeout: options.timeout,\n      signal,\n      searchParams: toUrlSearchParams({\n        arg: key,\n        ...options\n      }),\n      ...(\n        await multipartRequest(value, controller, options.headers)\n      )\n    })\n\n    for await (let message of res.ndjson()) {\n      message = toCamel(message)\n      message.id = new CID(message.id)\n      if (message.responses) {\n        message.responses = message.responses.map(({ ID, Addrs }) => ({\n          id: ID,\n          addrs: (Addrs || []).map(a => multiaddr(a))\n        }))\n      }\n      yield message\n    }\n  }\n\n  return put\n})\n","'use strict'\n\nconst CID = require('cids')\nconst multiaddr = require('multiaddr')\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').ImplementsMethod<'query', import('ipfs-core/src/components/dht')>}\n   */\n  async function * query (peerId, options = {}) {\n    const res = await api.post('dht/query', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: new CID(`${peerId}`),\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    for await (let message of res.ndjson()) {\n      message = toCamel(message)\n      message.id = new CID(message.id)\n      message.responses = (message.responses || []).map(({ ID, Addrs }) => ({\n        id: ID,\n        addrs: (Addrs || []).map(a => multiaddr(a))\n      }))\n      yield message\n    }\n  }\n\n  return query\n})\n","'use strict'\n\n// Response types are defined here:\n// https://github.com/libp2p/go-libp2p-core/blob/6e566d10f4a5447317a66d64c7459954b969bdab/routing/query.go#L15-L24\nmodule.exports = {\n  SendingQuery: 0,\n  PeerResponse: 1,\n  FinalPeer: 2,\n  QueryError: 3,\n  Provider: 4,\n  Value: 5,\n  AddingPeer: 6,\n  DialingPeer: 7\n}\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('diag/cmds', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    return res.json()\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  net: require('./net')(config),\n  sys: require('./sys')(config),\n  cmds: require('./cmds')(config)\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('diag/net', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    return res.json()\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('diag/sys', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    return res.json()\n  }\n})\n","'use strict'\n\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/dns')>}\n   */\n  const dns = async (domain, options = {}) => {\n    const res = await api.post('dns', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: domain,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return data.Path\n  }\n\n  return dns\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/chmod')>}\n   */\n  async function chmod (path, mode, options = {}) {\n    const res = await api.post('files/chmod', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        mode,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return chmod\n})\n","'use strict'\n\nconst CID = require('cids')\nconst { findSources } = require('./utils')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/cp')>}\n   */\n  async function cp (...args) {\n    const { sources, options } = findSources(args)\n\n    const res = await api.post('files/cp', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: sources.map(src => CID.isCID(src) ? `/ipfs/${src}` : src),\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return cp\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/flush')>}\n   */\n  async function flush (path, options = {}) {\n    if (!path || typeof path !== 'string') {\n      throw new Error('ipfs.files.flush requires a path')\n    }\n\n    const res = await api.post('files/flush', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return new CID(data.Cid)\n  }\n\n  return flush\n})\n","'use strict'\n\nmodule.exports = config => ({\n  chmod: require('./chmod')(config),\n  cp: require('./cp')(config),\n  flush: require('./flush')(config),\n  ls: require('./ls')(config),\n  mkdir: require('./mkdir')(config),\n  mv: require('./mv')(config),\n  read: require('./read')(config),\n  rm: require('./rm')(config),\n  stat: require('./stat')(config),\n  touch: require('./touch')(config),\n  write: require('./write')(config)\n})\n","'use strict'\n\nconst CID = require('cids')\nconst toCamelWithMetadata = require('../lib/object-to-camel-with-metadata')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/ls')>}\n   */\n  async function * ls (path, options = {}) {\n    if (!path || typeof path !== 'string') {\n      throw new Error('ipfs.files.ls requires a path')\n    }\n\n    const res = await api.post('files/ls', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: CID.isCID(path) ? `/ipfs/${path}` : path,\n        // default long to true, diverges from go-ipfs where its false by default\n        long: true,\n        ...options,\n        stream: true\n      }),\n      headers: options.headers\n    })\n\n    for await (const result of res.ndjson()) {\n      // go-ipfs does not yet support the \"stream\" option\n      if ('Entries' in result) {\n        for (const entry of result.Entries || []) {\n          yield toCoreInterface(toCamelWithMetadata(entry))\n        }\n      } else {\n        yield toCoreInterface(toCamelWithMetadata(result))\n      }\n    }\n  }\n\n  return ls\n})\n\nfunction toCoreInterface (entry) {\n  if (entry.hash) {\n    entry.cid = new CID(entry.hash)\n  }\n\n  delete entry.hash\n\n  entry.type = entry.type === 1 ? 'directory' : 'file'\n\n  return entry\n}\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/mkdir')>}\n   */\n  async function mkdir (path, options = {}) {\n    const res = await api.post('files/mkdir', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return mkdir\n})\n","'use strict'\n\nconst CID = require('cids')\nconst { findSources } = require('./utils')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/mv')>}\n   */\n  async function mv (...args) {\n    const { sources, options } = findSources(args)\n\n    const res = await api.post('files/mv', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: sources.map(src => CID.isCID(src) ? `/ipfs/${src}` : src),\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return mv\n})\n","'use strict'\n\nconst toIterable = require('stream-to-it/source')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/read')>}\n   */\n  async function * read (path, options = {}) {\n    const res = await api.post('files/read', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        count: options.length,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    yield * toIterable(res.body)\n  }\n\n  return read\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst { findSources } = require('./utils')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/rm')>}\n   */\n  async function rm (...args) {\n    const { sources, options } = findSources(args)\n\n    const res = await api.post('files/rm', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: sources,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return rm\n})\n","'use strict'\n\nconst CID = require('cids')\nconst toCamelWithMetadata = require('../lib/object-to-camel-with-metadata')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/stat')>}\n   */\n  async function stat (path, options = {}) {\n    if (typeof path !== 'string') {\n      options = path || {}\n      path = '/'\n    }\n\n    const res = await api.post('files/stat', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    data.WithLocality = data.WithLocality || false\n    return toCoreInterface(toCamelWithMetadata(data))\n  }\n\n  return stat\n})\n\nfunction toCoreInterface (entry) {\n  entry.cid = new CID(entry.hash)\n  delete entry.hash\n  return entry\n}\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/touch')>}\n   */\n  async function touch (path, options = {}) {\n    const res = await api.post('files/touch', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n\n  return touch\n})\n","'use strict'\n\nexports.findSources = (args) => {\n  /** @type {Record<any, any>} */\n  let options = {}\n  let sources = []\n\n  if (!Array.isArray(args[args.length - 1]) && typeof args[args.length - 1] === 'object') {\n    options = args.pop()\n  }\n\n  if (args.length === 1 && Array.isArray(args[0])) {\n    // support ipfs.files.cp([src, dest], opts)\n    sources = args[0]\n  } else {\n    // support ipfs.files.cp(src, dest, opts) and ipfs.files.cp(src1, src2, dest, opts)\n    sources = args\n  }\n\n  return {\n    sources,\n    options\n  }\n}\n","'use strict'\n\nconst modeToString = require('../lib/mode-to-string')\nconst { mtimeToObject } = require('ipfs-core-utils/src/files/normalise-input/utils')\nconst configure = require('../lib/configure')\nconst multipartRequest = require('../lib/multipart-request')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\nconst abortSignal = require('../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('..').Implements<typeof import('ipfs-core/src/components/files/write')>}\n   */\n  async function write (path, input, options = {}) {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const res = await api.post('files/write', {\n      timeout: options.timeout,\n      signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        streamChannels: true,\n        count: options.length,\n        ...options\n      }),\n      ...(\n        await multipartRequest({\n          content: input,\n          path: 'arg',\n          mode: modeToString(options.mode),\n          mtime: mtimeToObject(options.mtime)\n        }, controller, options.headers)\n      )\n    })\n\n    await res.text()\n  }\n\n  return write\n})\n","'use strict'\n\nconst configure = require('./lib/configure')\n\nmodule.exports = configure(api => {\n  return () => {\n    const url = new URL(api.opts.base || '')\n    return {\n      host: url.hostname,\n      port: url.port,\n      protocol: url.protocol,\n      pathname: url.pathname,\n      'api-path': url.pathname\n    }\n  }\n})\n","'use strict'\n\nconst Tar = require('it-tar')\nconst CID = require('cids')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\nconst map = require('it-map')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/get')>}\n   */\n  async function * get (path, options = {}) {\n    const res = await api.post('get', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${path instanceof Uint8Array ? new CID(path) : path}`,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    const extractor = Tar.extract()\n\n    for await (const { header, body } of extractor(res.iterator())) {\n      if (header.type === 'directory') {\n        // @ts-ignore - Missing the following properties from type 'Directory':\n        // cid, name, size, depthts\n        yield {\n          type: 'dir',\n          path: header.name\n        }\n      } else {\n        // @ts-ignore - Missing the following properties from type 'File':\n        // cid, name, size, depthts\n        yield {\n          type: 'file',\n          path: header.name,\n          content: map(body, (chunk) => chunk.slice()) // convert bl to Buffer/Uint8Array\n        }\n      }\n    }\n  }\n\n  return get\n})\n","'use strict'\n\nconst toCamel = require('./lib/object-to-camel')\nconst multiaddr = require('multiaddr')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/id')>}\n   */\n  async function id (options = {}) {\n    const res = await api.post('id', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    const output = toCamel(data)\n\n    if (output.addresses) {\n      output.addresses = output.addresses.map(ma => multiaddr(ma))\n    }\n\n    return output\n  }\n  return id\n})\n","'use strict'\n/* eslint-env browser */\n\nconst CID = require('cids')\nconst multiaddr = require('multiaddr')\nconst multibase = require('multibase')\nconst multicodec = require('multicodec')\nconst multihash = require('multihashes')\nconst globSource = require('ipfs-utils/src/files/glob-source')\nconst urlSource = require('ipfs-utils/src/files/url-source')\n\n/**\n * @param {import(\"./lib/core\").ClientOptions} options\n */\nfunction ipfsClient (options = {}) {\n  return {\n    add: require('./add')(options),\n    addAll: require('./add-all')(options),\n    bitswap: require('./bitswap')(options),\n    block: require('./block')(options),\n    bootstrap: require('./bootstrap')(options),\n    cat: require('./cat')(options),\n    commands: require('./commands')(options),\n    config: require('./config')(options),\n    dag: require('./dag')(options),\n    dht: require('./dht')(options),\n    diag: require('./diag')(options),\n    dns: require('./dns')(options),\n    files: require('./files')(options),\n    get: require('./get')(options),\n    getEndpointConfig: require('./get-endpoint-config')(options),\n    id: require('./id')(options),\n    key: require('./key')(options),\n    log: require('./log')(options),\n    ls: require('./ls')(options),\n    mount: require('./mount')(options),\n    name: require('./name')(options),\n    object: require('./object')(options),\n    pin: require('./pin')(options),\n    ping: require('./ping')(options),\n    pubsub: require('./pubsub')(options),\n    refs: require('./refs')(options),\n    repo: require('./repo')(options),\n    resolve: require('./resolve')(options),\n    stats: require('./stats')(options),\n    stop: require('./stop')(options),\n    shutdown: require('./stop')(options),\n    swarm: require('./swarm')(options),\n    version: require('./version')(options)\n  }\n}\n\nObject.assign(ipfsClient, { CID, multiaddr, multibase, multicodec, multihash, globSource, urlSource })\n\nmodule.exports = ipfsClient\n\n/**\n * @typedef {Object} HttpOptions\n * @property {Headers | Record<string, string>} [headers] - An object or [Headers](https://developer.mozilla.org/en-US/docs/Web/API/Headers) instance that can be used to set custom HTTP headers. Note that this option can also be [configured globally](#custom-headers) via the constructor options.\n * @property {URLSearchParams | Record<string, string>} [searchParams] - An object or [`URLSearchParams`](https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams) instance that can be used to add additional query parameters to the query string sent with each request.\n *\n * @typedef {import('ipfs-core/src/utils').AbortOptions} AbortOptions}\n */\n\n/**\n * This is an utility type that can be used to derive type of the HTTP Client\n * API from the Core API. It takes type of the API factory (from ipfs-core),\n * derives API from it's return type and extends it last `options` parameter\n * with `HttpOptions`.\n *\n * This can be used to avoid (re)typing API interface when implementing it in\n * http client e.g you can annotate `ipfs.addAll` implementation with\n *\n * `@type {Implements<typeof import('ipfs-core/src/components/add-all')>}`\n *\n * **Caution**: This supports APIs with up to four parameters and last optional\n * `options` parameter, anything else will result to `never` type.\n *\n * @template {(config:any) => any} APIFactory\n * @typedef {APIWithExtraOptions<ReturnType<APIFactory>, HttpOptions>} Implements\n */\n\n/**\n * @template Key\n * @template {(config:any) => any} APIFactory\n * @typedef {import('./interface').APIMethodWithExtraOptions<ReturnType<APIFactory>, Key, HttpOptions>} ImplementsMethod\n */\n\n/**\n * @template API, Extra\n * @typedef {import('./interface').APIWithExtraOptions<API, Extra>} APIWithExtraOptions\n */\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (name, options = {}) => {\n    const res = await api.post('key/gen', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: name,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return toCamel(data)\n  }\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (name, pem, password, options = {}) => {\n    if (typeof password !== 'string') {\n      options = password || {}\n      password = null\n    }\n\n    const res = await api.post('key/import', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: name,\n        pem,\n        password,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return toCamel(data)\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  gen: require('./gen')(config),\n  list: require('./list')(config),\n  rename: require('./rename')(config),\n  rm: require('./rm')(config),\n  import: require('./import')(config)\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('key/list', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return (data.Keys || []).map(k => toCamel(k))\n  }\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (oldName, newName, options = {}) => {\n    const res = await api.post('key/rename', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: [\n          oldName,\n          newName\n        ],\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (name, options = {}) => {\n    const res = await api.post('key/rm', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: name,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return toCamel(data.Keys[0])\n  }\n})\n","'use strict'\n\nconst { anySignal } = require('any-signal')\n\n/**\n * @typedef {AbortSignal | undefined} MaybeSignal\n *\n * @param  {MaybeSignal[]} signals\n * @returns {AbortSignal[]}\n */\nfunction filter (signals) {\n  // @ts-ignore\n  return signals.filter(Boolean)\n}\n\n/**\n * @param  {...AbortSignal|undefined} signals\n */\nmodule.exports = (...signals) => {\n  return anySignal(filter(signals))\n}\n","'use strict'\n/* eslint-env browser */\n\nconst Client = require('./core')\n\n// Set default configuration and call create function with them\n/**\n * @typedef { import(\"./core\").ClientOptions } ClientOptions\n */\n\n/**\n * @template T\n * @typedef {(client: Client, clientOptions: ClientOptions) => T} Fn\n */\n\n/**\n * @template T\n * @typedef {(clientOptions: ClientOptions) => T} Factory\n */\n\n/**\n * @template T\n * @param {Fn<T>} fn\n * @returns {Factory<T>}\n */\nconst configure = (fn) => {\n  return (options) => {\n    return fn(new Client(options), options)\n  }\n}\nmodule.exports = configure\n","'use strict'\n/* eslint-env browser */\nconst Multiaddr = require('multiaddr')\nconst { isBrowser, isWebWorker, isNode } = require('ipfs-utils/src/env')\nconst { default: parseDuration } = require('parse-duration')\nconst log = require('debug')('ipfs-http-client:lib:error-handler')\nconst HTTP = require('ipfs-utils/src/http')\nconst merge = require('merge-options')\nconst toUrlString = require('ipfs-core-utils/src/to-url-string')\nconst http = require('http')\nconst https = require('https')\n\nconst DEFAULT_PROTOCOL = isBrowser || isWebWorker ? location.protocol : 'http'\nconst DEFAULT_HOST = isBrowser || isWebWorker ? location.hostname : 'localhost'\nconst DEFAULT_PORT = isBrowser || isWebWorker ? location.port : '5001'\n\n/**\n * @param {ClientOptions|URL|Multiaddr|string} [options]\n * @returns {ClientOptions}\n */\nconst normalizeOptions = (options = {}) => {\n  let url\n  let opts = {}\n  let agent\n\n  if (typeof options === 'string' || Multiaddr.isMultiaddr(options)) {\n    url = new URL(toUrlString(options))\n  } else if (options instanceof URL) {\n    url = options\n  } else if (typeof options.url === 'string' || Multiaddr.isMultiaddr(options.url)) {\n    url = new URL(toUrlString(options.url))\n    opts = options\n  } else if (options.url instanceof URL) {\n    url = options.url\n    opts = options\n  } else {\n    opts = options || {}\n\n    const protocol = (opts.protocol || DEFAULT_PROTOCOL).replace(':', '')\n    const host = (opts.host || DEFAULT_HOST).split(':')[0]\n    const port = (opts.port || DEFAULT_PORT)\n\n    url = new URL(`${protocol}://${host}:${port}`)\n  }\n\n  if (opts.apiPath) {\n    url.pathname = opts.apiPath\n  } else if (url.pathname === '/' || url.pathname === undefined) {\n    url.pathname = 'api/v0'\n  }\n\n  if (isNode) {\n    const Agent = url.protocol.startsWith('https') ? https.Agent : http.Agent\n\n    agent = opts.agent || new Agent({\n      keepAlive: true,\n      // Similar to browsers which limit connections to six per host\n      maxSockets: 6\n    })\n  }\n\n  return {\n    ...opts,\n    host: url.host,\n    protocol: url.protocol.replace(':', ''),\n    port: Number(url.port),\n    apiPath: url.pathname,\n    url,\n    agent\n  }\n}\n\nconst errorHandler = async (response) => {\n  let msg\n\n  try {\n    if ((response.headers.get('Content-Type') || '').startsWith('application/json')) {\n      const data = await response.json()\n      log(data)\n      msg = data.Message || data.message\n    } else {\n      msg = await response.text()\n    }\n  } catch (err) {\n    log('Failed to parse error response', err)\n    // Failed to extract/parse error message from response\n    msg = err.message\n  }\n\n  /** @type {Error} */\n  let error = new HTTP.HTTPError(response)\n\n  // This is what go-ipfs returns where there's a timeout\n  if (msg && msg.includes('context deadline exceeded')) {\n    error = new HTTP.TimeoutError(response)\n  }\n\n  // This also gets returned\n  if (msg && msg.includes('request timed out')) {\n    error = new HTTP.TimeoutError(response)\n  }\n\n  // If we managed to extract a message from the response, use it\n  if (msg) {\n    error.message = msg\n  }\n\n  throw error\n}\n\nconst KEBAB_REGEX = /[A-Z\\u00C0-\\u00D6\\u00D8-\\u00DE]/g\nconst kebabCase = (str) => {\n  return str.replace(KEBAB_REGEX, function (match) {\n    return '-' + match.toLowerCase()\n  })\n}\n\nconst parseTimeout = (value) => {\n  return typeof value === 'string' ? parseDuration(value) : value\n}\n\n/**\n * @typedef {import('http').Agent} HttpAgent\n * @typedef {import('https').Agent} HttpsAgent\n *\n * @typedef {Object} ClientOptions\n * @property {string} [host]\n * @property {number} [port]\n * @property {string} [protocol]\n * @property {Headers|Record<string, string>} [headers] - Request headers.\n * @property {number|string} [timeout] - Amount of time until request should timeout in ms or humand readable. https://www.npmjs.com/package/parse-duration for valid string values.\n * @property {string} [apiPath] - Path to the API.\n * @property {URL|string|Multiaddr} [url] - Full API URL.\n * @property {object} [ipld]\n * @property {any[]} [ipld.formats] - An array of additional [IPLD formats](https://github.com/ipld/interface-ipld-format) to support\n * @property {(format: string) => Promise<any>} [ipld.loadFormat] - an async function that takes the name of an [IPLD format](https://github.com/ipld/interface-ipld-format) as a string and should return the implementation of that codec\n * @property {HttpAgent|HttpsAgent} [agent] - A [http.Agent](https://nodejs.org/api/http.html#http_class_http_agent) used to control connection persistence and reuse for HTTP clients (only supported in node.js)\n */\nclass Client extends HTTP {\n  /**\n   * @param {ClientOptions|URL|Multiaddr|string} [options]\n   */\n  constructor (options = {}) {\n    const opts = normalizeOptions(options)\n\n    super({\n      timeout: parseTimeout(opts.timeout) || 60000 * 20,\n      headers: opts.headers,\n      base: `${opts.url}`,\n      handleError: errorHandler,\n      transformSearchParams: (search) => {\n        const out = new URLSearchParams()\n\n        // @ts-ignore https://developer.mozilla.org/en-US/docs/Web/API/URLSearchParams\n        for (const [key, value] of search) {\n          if (\n            value !== 'undefined' &&\n            value !== 'null' &&\n            key !== 'signal'\n          ) {\n            out.append(kebabCase(key), value)\n          }\n\n          // @ts-ignore server timeouts are strings\n          if (key === 'timeout' && !isNaN(value)) {\n            out.append(kebabCase(key), value)\n          }\n        }\n\n        return out\n      },\n      // @ts-ignore this can be a https agent or a http agent\n      agent: opts.agent\n    })\n\n    // @ts-ignore\n    delete this.get\n    // @ts-ignore\n    delete this.put\n    // @ts-ignore\n    delete this.delete\n    // @ts-ignore\n    delete this.options\n\n    const fetch = this.fetch\n\n    this.fetch = (resource, options = {}) => {\n      if (typeof resource === 'string' && !resource.startsWith('/')) {\n        resource = `${opts.url}/${resource}`\n      }\n\n      return fetch.call(this, resource, merge(options, {\n        method: 'POST'\n      }))\n    }\n  }\n}\n\nClient.errorHandler = errorHandler\n\nmodule.exports = Client\n","'use strict'\n\nconst dagPB = require('ipld-dag-pb')\nconst dagCBOR = require('ipld-dag-cbor')\nconst raw = require('ipld-raw')\nconst multicodec = require('multicodec')\n\nconst noop = () => {}\n\n/**\n * @typedef {import('cids')} CID\n */\n\n/**\n * Return an object containing supported IPLD Formats\n *\n * @param {object} [options] - IPLD options passed to the http client constructor\n * @param {Array} [options.formats] - A list of IPLD Formats to use\n * @param {Function} [options.loadFormat] - An async function that can load a format when passed a codec number\n * @returns {Function}\n */\nmodule.exports = ({ formats = [], loadFormat = noop } = {}) => {\n  formats = formats || []\n  loadFormat = loadFormat || noop\n\n  const configuredFormats = {\n    [multicodec.DAG_PB]: dagPB,\n    [multicodec.DAG_CBOR]: dagCBOR,\n    [multicodec.RAW]: raw\n  }\n\n  formats.forEach(format => {\n    configuredFormats[format.codec] = format\n  })\n\n  /**\n   * Attempts to load an IPLD format for the passed CID\n   *\n   * @param {import('multicodec').CodecName} codec - The code to load the format for\n   * @returns {Promise<object>} - An IPLD format\n   */\n  const loadResolver = async (codec) => {\n    // @ts-ignore - codec is a string and not a CodecName\n    const number = multicodec.getNumber(codec)\n    const format = configuredFormats[number] || await loadFormat(codec)\n\n    if (!format) {\n      throw Object.assign(\n        new Error(`Missing IPLD format \"${codec}\"`),\n        { missingMulticodec: codec }\n      )\n    }\n\n    return format\n  }\n\n  return loadResolver\n}\n","'use strict'\n\nmodule.exports = (mode) => {\n  if (mode === undefined || mode === null) {\n    return undefined\n  }\n\n  if (typeof mode === 'string' || mode instanceof String) {\n    return mode\n  }\n\n  return mode.toString(8).padStart(4, '0')\n}\n","'use strict'\n\n// Import browser version otherwise electron-renderer will end up with node\n// version and fail.\nconst normaliseInput = require('ipfs-core-utils/src/files/normalise-input/index.browser')\nconst modeToString = require('./mode-to-string')\n\nasync function multipartRequest (source = '', abortController, headers = {}) {\n  const parts = []\n  const formData = new FormData()\n  let index = 0\n  let total = 0\n\n  for await (const { content, path, mode, mtime } of normaliseInput(source)) {\n    let fileSuffix = ''\n    const type = content ? 'file' : 'dir'\n\n    if (index > 0) {\n      fileSuffix = `-${index}`\n    }\n\n    let fieldName = type + fileSuffix\n    const qs = []\n\n    if (mode !== null && mode !== undefined) {\n      qs.push(`mode=${modeToString(mode)}`)\n    }\n\n    if ((mtime) != null) {\n      const { secs, nsecs } = (mtime)\n\n      qs.push(`mtime=${secs}`)\n\n      if (nsecs != null) {\n        qs.push(`mtime-nsecs=${nsecs}`)\n      }\n    }\n\n    if (qs.length) {\n      fieldName = `${fieldName}?${qs.join('&')}`\n    }\n\n    if (content) {\n      formData.set(fieldName, content, encodeURIComponent(path))\n      const end = total + content.size\n      parts.push({ name: path, start: total, end })\n      total = end\n    } else {\n      formData.set(fieldName, new File([''], encodeURIComponent(path), { type: 'application/x-directory' }))\n    }\n\n    index++\n  }\n\n  return {\n    total,\n    parts,\n    headers,\n    body: formData\n  }\n}\n\nmodule.exports = multipartRequest\n","'use strict'\n\nconst toCamel = require('./object-to-camel')\n\nfunction toCamelWithMetadata (entry) {\n  const file = toCamel(entry)\n\n  if (Object.prototype.hasOwnProperty.call(file, 'mode')) {\n    file.mode = parseInt(file.mode, 8)\n  }\n\n  if (Object.prototype.hasOwnProperty.call(file, 'mtime')) {\n    file.mtime = {\n      secs: file.mtime,\n      nsecs: file.mtimeNsecs || 0\n    }\n\n    delete file.mtimeNsecs\n  }\n\n  return file\n}\n\nmodule.exports = toCamelWithMetadata\n","'use strict'\n\n// Convert object properties to camel case.\n// NOT recursive!\n// e.g.\n// AgentVersion => agentVersion\n// ID => id\nmodule.exports = obj => {\n  if (obj == null) return obj\n  const caps = /^[A-Z]+$/\n  return Object.keys(obj).reduce((camelObj, k) => {\n    if (caps.test(k)) { // all caps\n      camelObj[k.toLowerCase()] = obj[k]\n    } else if (caps.test(k[0])) { // pascal\n      camelObj[k[0].toLowerCase() + k.slice(1)] = obj[k]\n    } else {\n      camelObj[k] = obj[k]\n    }\n    return camelObj\n  }, {})\n}\n","'use strict'\n\nconst modeToString = require('./mode-to-string')\nconst { mtimeToObject } = require('ipfs-core-utils/src/files/normalise-input/utils')\n\n/**\n * @param {*} params\n * @returns {URLSearchParams}\n */\nmodule.exports = ({ arg, searchParams, hashAlg, mtime, mode, ...options } = {}) => {\n  if (searchParams) {\n    options = {\n      ...options,\n      ...searchParams\n    }\n  }\n\n  if (hashAlg) {\n    options.hash = hashAlg\n  }\n\n  if (mtime != null) {\n    mtime = mtimeToObject(mtime)\n\n    options.mtime = mtime.secs\n    options.mtimeNsecs = mtime.nsecs\n  }\n\n  if (mode != null) {\n    options.mode = modeToString(mode)\n  }\n\n  if (options.timeout && !isNaN(options.timeout)) {\n    // server API expects timeouts as strings\n    options.timeout = `${options.timeout}ms`\n  }\n\n  if (arg === undefined || arg === null) {\n    arg = []\n  } else if (!Array.isArray(arg)) {\n    arg = [arg]\n  }\n\n  const urlSearchParams = new URLSearchParams(options)\n\n  arg.forEach(arg => urlSearchParams.append('arg', arg))\n\n  return urlSearchParams\n}\n","'use strict'\n\nmodule.exports = config => ({\n  tail: require('./tail')(config),\n  ls: require('./ls')(config),\n  level: require('./level')(config)\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (subsystem, level, options = {}) => {\n    const res = await api.post('log/level', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: [\n          subsystem,\n          level\n        ],\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('log/ls', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    const data = await res.json()\n    return data.Strings\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * tail (options = {}) {\n    const res = await api.post('log/tail', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    yield * res.ndjson()\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\nconst stat = require('./files/stat')\n\nmodule.exports = configure((api, opts) => {\n  return async function * ls (path, options = {}) {\n    const pathStr = `${path instanceof Uint8Array ? new CID(path) : path}`\n\n    async function mapLink (link) {\n      let hash = link.Hash\n\n      if (hash.includes('/')) {\n        // the hash is a path, but we need the CID\n        const ipfsPath = hash.startsWith('/ipfs/') ? hash : `/ipfs/${hash}`\n        const stats = await stat(opts)(ipfsPath)\n\n        hash = stats.cid\n      }\n\n      const entry = {\n        name: link.Name,\n        path: pathStr + (link.Name ? `/${link.Name}` : ''),\n        size: link.Size,\n        cid: new CID(hash),\n        type: typeOf(link),\n        depth: link.Depth || 1\n      }\n\n      if (link.Mode) {\n        entry.mode = parseInt(link.Mode, 8)\n      }\n\n      if (link.Mtime !== undefined && link.Mtime !== null) {\n        entry.mtime = {\n          secs: link.Mtime\n        }\n\n        if (link.MtimeNsecs !== undefined && link.MtimeNsecs !== null) {\n          entry.mtime.nsecs = link.MtimeNsecs\n        }\n      }\n\n      return entry\n    }\n\n    const res = await api.post('ls', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: pathStr,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    for await (let result of res.ndjson()) {\n      result = result.Objects\n\n      if (!result) {\n        throw new Error('expected .Objects in results')\n      }\n\n      result = result[0]\n      if (!result) {\n        throw new Error('expected one array in results.Objects')\n      }\n\n      const links = result.Links\n      if (!Array.isArray(links)) {\n        throw new Error('expected one array in results.Objects[0].Links')\n      }\n\n      if (!links.length) {\n        // no links, this is a file, yield a single result\n        yield mapLink(result)\n\n        return\n      }\n\n      yield * links.map(mapLink)\n    }\n  }\n})\n\nfunction typeOf (link) {\n  switch (link.Type) {\n    case 1:\n    case 5:\n      return 'dir'\n    case 2:\n      return 'file'\n    default:\n      return 'unknown'\n  }\n}\n","'use strict'\n\nconst toCamel = require('./lib/object-to-camel')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('dns', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  publish: require('./publish')(config),\n  resolve: require('./resolve')(config),\n  pubsub: require('./pubsub')(config)\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (path, options = {}) => {\n    const res = await api.post('name/publish', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nconst toCamel = require('../../lib/object-to-camel')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (name, options = {}) => {\n    const res = await api.post('name/pubsub/cancel', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: name,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  cancel: require('./cancel')(config),\n  state: require('./state')(config),\n  subs: require('./subs')(config)\n})\n","'use strict'\n\nconst toCamel = require('../../lib/object-to-camel')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('name/pubsub/state', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n})\n","'use strict'\n\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('name/pubsub/subs', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return data.Strings || []\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * (path, options = {}) {\n    const res = await api.post('name/resolve', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        stream: true,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    for await (const result of res.ndjson()) {\n      yield result.Path\n    }\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function data (cid, options = {}) {\n    const res = await api.post('object/data', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.arrayBuffer()\n\n    return new Uint8Array(data, 0, data.byteLength)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst { DAGNode, DAGLink } = require('ipld-dag-pb')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\nmodule.exports = configure(api => {\n  return async (cid, options = {}) => {\n    const res = await api.post('object/get', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n        dataEncoding: 'base64',\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return new DAGNode(\n      uint8ArrayFromString(data.Data, 'base64pad'),\n      (data.Links || []).map(l => new DAGLink(l.Name, l.Size, l.Hash))\n    )\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  data: require('./data')(config),\n  get: require('./get')(config),\n  links: require('./links')(config),\n  new: require('./new')(config),\n  patch: require('./patch')(config),\n  put: require('./put')(config),\n  stat: require('./stat')(config)\n})\n","'use strict'\n\nconst CID = require('cids')\nconst { DAGLink } = require('ipld-dag-pb')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (cid, options = {}) => {\n    const res = await api.post('object/links', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return (data.Links || []).map(l => new DAGLink(l.Name, l.Size, l.Hash))\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('object/new', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: options.template,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    const { Hash } = await res.json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (cid, dLink, options = {}) => {\n    const res = await api.post('object/patch/add-link', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: [\n          `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n          dLink.Name || dLink.name || '',\n          (dLink.Hash || dLink.cid || '').toString() || null\n        ],\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    const { Hash } = await res.json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst multipartRequest = require('../../lib/multipart-request')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\nconst abortSignal = require('../../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\n\nmodule.exports = configure(api => {\n  return async (cid, data, options = {}) => {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const res = await api.post('object/patch/append-data', {\n      timeout: options.timeout,\n      signal,\n      searchParams: toUrlSearchParams({\n        arg: `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n        ...options\n      }),\n      ...(\n        await multipartRequest(data, controller, options.headers)\n      )\n    })\n\n    const { Hash } = await res.json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  addLink: require('./add-link')(config),\n  appendData: require('./append-data')(config),\n  rmLink: require('./rm-link')(config),\n  setData: require('./set-data')(config)\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (cid, dLink, options = {}) => {\n    const res = await api.post('object/patch/rm-link', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: [\n          `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n          dLink.Name || dLink.name || null\n        ],\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    const { Hash } = await res.json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst multipartRequest = require('../../lib/multipart-request')\nconst configure = require('../../lib/configure')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\nconst abortSignal = require('../../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\n\nmodule.exports = configure(api => {\n  return async (cid, data, options = {}) => {\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const { Hash } = await (await api.post('object/patch/set-data', {\n      timeout: options.timeout,\n      signal,\n      searchParams: toUrlSearchParams({\n        arg: [\n          `${cid instanceof Uint8Array ? new CID(cid) : cid}`\n        ],\n        ...options\n      }),\n      ...(\n        await multipartRequest(data, controller, options.headers)\n      )\n    })).json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst { DAGNode } = require('ipld-dag-pb')\nconst multipartRequest = require('../lib/multipart-request')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\nconst abortSignal = require('../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\nconst unit8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\nmodule.exports = configure(api => {\n  return async (obj, options = {}) => {\n    let tmpObj = {\n      Links: []\n    }\n\n    if (obj instanceof Uint8Array) {\n      if (!options.enc) {\n        tmpObj = {\n          Data: unit8ArrayToString(obj),\n          Links: []\n        }\n      }\n    } else if (DAGNode.isDAGNode(obj)) {\n      tmpObj = {\n        Data: unit8ArrayToString(obj.Data),\n        Links: obj.Links.map(l => ({\n          Name: l.Name,\n          Hash: l.Hash.toString(),\n          Size: l.Tsize\n        }))\n      }\n    } else if (typeof obj === 'object') {\n      tmpObj.Data = unit8ArrayToString(obj.Data)\n      tmpObj.Links = obj.Links\n    } else {\n      throw new Error('obj not recognized')\n    }\n\n    let buf\n    if (obj instanceof Uint8Array && options.enc) {\n      buf = obj\n    } else {\n      options.enc = 'json'\n      buf = uint8ArrayFromString(JSON.stringify(tmpObj))\n    }\n\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const res = await api.post('object/put', {\n      timeout: options.timeout,\n      signal,\n      searchParams: toUrlSearchParams(options),\n      ...(\n        await multipartRequest(buf, controller, options.headers)\n      )\n    })\n\n    const { Hash } = await res.json()\n\n    return new CID(Hash)\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (cid, options = {}) => {\n    const res = await api.post('object/stat', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${cid instanceof Uint8Array ? new CID(cid) : cid}`,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    return res.json()\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst normaliseInput = require('ipfs-core-utils/src/pins/normalise-input')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * addAll (source, options = {}) {\n    for await (const { path, recursive, metadata } of normaliseInput(source)) {\n      const res = await api.post('pin/add', {\n        timeout: options.timeout,\n        signal: options.signal,\n        searchParams: toUrlSearchParams({\n          ...options,\n          arg: path,\n          recursive,\n          metadata: metadata ? JSON.stringify(metadata) : undefined,\n          stream: true\n        }),\n        headers: options.headers\n      })\n\n      for await (const pin of res.ndjson()) {\n        if (pin.Pins) { // non-streaming response\n          for (const cid of pin.Pins) {\n            yield new CID(cid)\n          }\n          continue\n        }\n\n        yield new CID(pin)\n      }\n    }\n  }\n})\n","'use strict'\n\nconst addAll = require('./add-all')\nconst last = require('it-last')\nconst configure = require('../lib/configure')\n\nmodule.exports = (options) => {\n  const all = addAll(options)\n\n  return configure(() => {\n    return async function add (path, options = {}) { // eslint-disable-line require-await\n      return last(all({\n        path,\n        ...options\n      }, options))\n    }\n  })(options)\n}\n","'use strict'\n\nconst Remote = require('./remote')\n\nmodule.exports = config => ({\n  add: require('./add')(config),\n  addAll: require('./add-all')(config),\n  ls: require('./ls')(config),\n  rm: require('./rm')(config),\n  rmAll: require('./rm-all')(config),\n  remote: new Remote(config)\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nfunction toPin (type, cid, metadata) {\n  const pin = {\n    type,\n    cid: new CID(cid)\n  }\n\n  if (metadata) {\n    pin.metadata = metadata\n  }\n\n  return pin\n}\n\nmodule.exports = configure(api => {\n  return async function * ls (options = {}) {\n    if (options.paths) {\n      options.paths = Array.isArray(options.paths) ? options.paths : [options.paths]\n    }\n\n    const res = await api.post('pin/ls', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        ...options,\n        arg: (options.paths || []).map(path => `${path}`),\n        stream: true\n      }),\n      headers: options.headers\n    })\n\n    for await (const pin of res.ndjson()) {\n      if (pin.Keys) { // non-streaming response\n        for (const cid of Object.keys(pin.Keys)) {\n          yield toPin(pin.Keys[cid].Type, cid, pin.Keys[cid].Metadata)\n        }\n        return\n      }\n\n      yield toPin(pin.Type, pin.Cid, pin.Metadata)\n    }\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst Client = require('../../lib/core')\nconst Service = require('./service')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\n/**\n * @typedef {import('../..').HttpOptions} HttpOptions\n * @typedef {import('../../lib/core').ClientOptions} ClientOptions\n * @typedef {import('ipfs-core-types/src/basic').AbortOptions} AbortOptions\n * @typedef {import('ipfs-core-types/src/pin/remote').API} API\n * @typedef {import('ipfs-core-types/src/pin/remote').Pin} Pin\n * @typedef {import('ipfs-core-types/src/pin/remote').AddOptions} AddOptions\n * @typedef {import('ipfs-core-types/src/pin/remote').Query} Query\n * @typedef {import('ipfs-core-types/src/pin/remote').Status} Status\n *\n * @implements {API}\n */\nclass Remote {\n  /**\n   * @param {ClientOptions} options\n   */\n  constructor (options) {\n    /** @private */\n    this.client = new Client(options)\n    /** @readonly */\n    this.service = new Service(options)\n  }\n\n  /**\n   * Stores an IPFS object(s) from a given path to a remote pinning service.\n   *\n   * @param {CID} cid\n   * @param {AddOptions & AbortOptions & HttpOptions} options\n   * @returns {Promise<Pin>}\n   */\n  add (cid, options) {\n    return Remote.add(this.client, cid, options)\n  }\n\n  /**\n   * @param {Client} client\n   * @param {CID} cid\n   * @param {AddOptions & AbortOptions & HttpOptions} options\n   */\n  static async add (client, cid, { timeout, signal, headers, ...options }) {\n    const response = await client.post('pin/remote/add', {\n      timeout,\n      signal,\n      headers,\n      searchParams: encodeAddParams({ cid, ...options })\n    })\n\n    return Remote.decodePin(await response.json())\n  }\n\n  /**\n   * @param {Object} json\n   * @param {string} json.Name\n   * @param {string} json.Cid\n   * @param {Status} json.Status\n   * @returns {Pin}\n   */\n  static decodePin ({ Name: name, Status: status, Cid: cid }) {\n    return {\n      cid: new CID(cid),\n      name,\n      status\n    }\n  }\n\n  /**\n   * Returns a list of matching pins on the remote pinning service.\n   *\n   * @param {Query & AbortOptions & HttpOptions} query\n   */\n  ls (query) {\n    return Remote.ls(this.client, query)\n  }\n\n  /**\n   *\n   * @param {Client} client\n   * @param {Query & AbortOptions & HttpOptions} options\n   * @returns {AsyncIterable<Pin>}\n   */\n  static async * ls (client, { timeout, signal, headers, ...query }) {\n    const response = await client.post('pin/remote/ls', {\n      signal,\n      timeout,\n      headers,\n      searchParams: encodeQuery(query)\n    })\n\n    for await (const pin of response.ndjson()) {\n      yield Remote.decodePin(pin)\n    }\n  }\n\n  /**\n   * Removes a single pin object matching query allowing it to be garbage\n   * collected (if needed). Will error if multiple pins mtach provided\n   * query. To remove all matches use `rmAll` instead.\n   *\n   * @param {Query & AbortOptions & HttpOptions} query\n   */\n  rm (query) {\n    return Remote.rm(this.client, { ...query, all: false })\n  }\n\n  /**\n   * Removes all pin object that match given query allowing them to be garbage\n   * collected if needed.\n   *\n   * @param {Query & AbortOptions & HttpOptions} query\n   */\n  rmAll (query) {\n    return Remote.rm(this.client, { ...query, all: true })\n  }\n\n  /**\n   *\n   * @param {Client} client\n   * @param {{all: boolean} & Query & AbortOptions & HttpOptions} options\n   */\n  static async rm (client, { timeout, signal, headers, ...query }) {\n    await client.post('pin/remote/rm', {\n      timeout,\n      signal,\n      headers,\n      searchParams: encodeQuery(query)\n    })\n  }\n}\n\n/**\n * @param {any} service\n * @returns {string}\n */\nconst encodeService = (service) => {\n  if (typeof service === 'string' && service !== '') {\n    return service\n  } else {\n    throw new TypeError('service name must be passed')\n  }\n}\n\n/**\n * @param {any} cid\n * @returns {string}\n */\nconst encodeCID = (cid) => {\n  if (CID.isCID(cid)) {\n    return cid.toString()\n  } else {\n    throw new TypeError(`CID instance expected instead of ${cid}`)\n  }\n}\n\n/**\n * @param {Query & { all?: boolean }} query\n * @returns {URLSearchParams}\n */\nconst encodeQuery = ({ service, cid, name, status, all }) => {\n  const query = toUrlSearchParams({\n    service: encodeService(service),\n    name,\n    force: all ? true : undefined\n  })\n\n  if (cid) {\n    for (const value of cid) {\n      query.append('cid', encodeCID(value))\n    }\n  }\n\n  if (status) {\n    for (const value of status) {\n      query.append('status', value)\n    }\n  }\n\n  return query\n}\n\n/**\n * @param {AddOptions & {cid:CID}} options\n * @returns {URLSearchParams}\n */\nconst encodeAddParams = ({ cid, service, background, name, origins }) => {\n  const params = toUrlSearchParams({\n    arg: encodeCID(cid),\n    service: encodeService(service),\n    name,\n    background: background ? true : undefined\n  })\n\n  if (origins) {\n    for (const origin of origins) {\n      params.append('origin', origin.toString())\n    }\n  }\n\n  return params\n}\n\nmodule.exports = Remote\n","'use strict'\n\nconst Client = require('../../lib/core')\nconst toUrlSearchParams = require('../../lib/to-url-search-params')\n\n/**\n * @typedef {import('../../lib/core').ClientOptions} ClientOptions\n * @typedef {import('../..').HttpOptions} HttpOptions\n * @typedef {import('ipfs-core-types/src/basic').AbortOptions} AbortOptions\n * @typedef {import('ipfs-core-types/src/pin/remote/service').API} API\n * @typedef {import('ipfs-core-types/src/pin/remote/service').Credentials} Credentials\n * @typedef {import('ipfs-core-types/src/pin/remote/service').RemotePinService} RemotePinService\n * @typedef {import('ipfs-core-types/src/pin/remote/service').RemotePinServiceWithStat} RemotePinServiceWithStat\n * @implements {API}\n */\nclass Service {\n  /**\n   * @param {ClientOptions} options\n   */\n  constructor (options) {\n    /** @private */\n    this.client = new Client(options)\n  }\n\n  /**\n   * @param {Client} client\n   * @param {string} name\n   * @param {Credentials & AbortOptions & HttpOptions} options\n   */\n  static async add (client, name, options) {\n    const { endpoint, key, headers, timeout, signal } = options\n    await client.post('pin/remote/service/add', {\n      timeout,\n      signal,\n      searchParams: toUrlSearchParams({\n        arg: [name, Service.encodeEndpoint(endpoint), key]\n      }),\n      headers\n    })\n  }\n\n  /**\n   * @param {URL} url\n   */\n  static encodeEndpoint (url) {\n    const href = String(url)\n    if (href === 'undefined') {\n      throw Error('endpoint is required')\n    }\n    // Workaround trailing `/` issue in go-ipfs\n    // @see https://github.com/ipfs/go-ipfs/issues/7826\n    return href[href.length - 1] === '/' ? href.slice(0, -1) : href\n  }\n\n  /**\n   * @param {Client} client\n   * @param {string} name\n   * @param {AbortOptions & HttpOptions} [options]\n   */\n  static async rm (client, name, { timeout, signal, headers } = {}) {\n    await client.post('pin/remote/service/rm', {\n      timeout,\n      signal,\n      headers,\n      searchParams: toUrlSearchParams({\n        arg: name\n      })\n    })\n  }\n\n  /**\n   * @template {true} Stat\n   * @param {Client} client\n   * @param {{ stat?: Stat } & AbortOptions & HttpOptions} [options]\n   */\n  static async ls (client, { stat, timeout, signal, headers } = {}) {\n    const response = await client.post('pin/remote/service/ls', {\n      searchParams: stat === true ? toUrlSearchParams({ stat }) : undefined,\n      timeout,\n      signal,\n      headers\n    })\n\n    /** @type {{RemoteServices: Object[]}} */\n    const { RemoteServices } = await response.json()\n\n    /** @type {Stat extends true ? RemotePinServiceWithStat[] : RemotePinService []} */\n    return (RemoteServices.map(Service.decodeRemoteService))\n  }\n\n  /**\n   * @param {Object} json\n   * @returns {RemotePinServiceWithStat}\n   */\n  static decodeRemoteService (json) {\n    return {\n      service: json.Service,\n      endpoint: new URL(json.ApiEndpoint),\n      ...(json.Stat && { stat: Service.decodeStat(json.Stat) })\n    }\n  }\n\n  /**\n   * @param {Object} json\n   * @returns {import('ipfs-core-types/src/pin/remote/service').Stat}\n   */\n  static decodeStat (json) {\n    switch (json.Status) {\n      case 'valid': {\n        const { Pinning, Pinned, Queued, Failed } = json.PinCount\n        return {\n          status: 'valid',\n          pinCount: {\n            queued: Queued,\n            pinning: Pinning,\n            pinned: Pinned,\n            failed: Failed\n          }\n        }\n      }\n      case 'invalid': {\n        return { status: 'invalid' }\n      }\n      default: {\n        return { status: json.Status }\n      }\n    }\n  }\n\n  /**\n   * Registers remote pinning service with a given name. Errors if service\n   * with the given name is already registered.\n   *\n   * @param {string} name\n   * @param {Credentials & AbortOptions & HttpOptions} options\n   */\n  add (name, options) {\n    return Service.add(this.client, name, options)\n  }\n\n  /**\n   * Unregisteres remote pinning service with a given name. If service with such\n   * name isn't registerede this is a noop.\n   *\n   * @param {string} name\n   * @param {AbortOptions & HttpOptions} [options]\n   */\n  rm (name, options) {\n    return Service.rm(this.client, name, options)\n  }\n\n  /**\n   * List registered remote pinning services.\n   *\n   * @param {{ stat?: true } & AbortOptions & HttpOptions} [options]\n   */\n  ls (options) {\n    return Service.ls(this.client, options)\n  }\n}\n\nmodule.exports = Service\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst normaliseInput = require('ipfs-core-utils/src/pins/normalise-input')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * rmAll (source, options = {}) {\n    for await (const { path, recursive } of normaliseInput(source)) {\n      const searchParams = new URLSearchParams(options.searchParams)\n      searchParams.append('arg', `${path}`)\n\n      if (recursive != null) searchParams.set('recursive', String(recursive))\n\n      const res = await api.post('pin/rm', {\n        timeout: options.timeout,\n        signal: options.signal,\n        headers: options.headers,\n        searchParams: toUrlSearchParams({\n          ...options,\n          arg: `${path}`,\n          recursive\n        })\n      })\n\n      for await (const pin of res.ndjson()) {\n        if (pin.Pins) { // non-streaming response\n          yield * pin.Pins.map(cid => new CID(cid))\n          continue\n        }\n        yield new CID(pin)\n      }\n    }\n  }\n})\n","'use strict'\n\nconst rmAll = require('./rm-all')\nconst last = require('it-last')\nconst configure = require('../lib/configure')\n\nmodule.exports = (options) => {\n  const all = rmAll(options)\n\n  return configure(() => {\n    return async function rm (path, options = {}) { // eslint-disable-line require-await\n      return last(all({\n        path,\n        ...options\n      }, options))\n    }\n  })(options)\n}\n","'use strict'\n\nconst toCamel = require('./lib/object-to-camel')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * ping (peerId, options = {}) {\n    const res = await api.post('ping', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: `${peerId}`,\n        ...options\n      }),\n      headers: options.headers,\n      transform: toCamel\n    })\n\n    yield * res.ndjson()\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  ls: require('./ls')(config),\n  peers: require('./peers')(config),\n  publish: require('./publish')(config),\n  subscribe: require('./subscribe')(config),\n  unsubscribe: require('./unsubscribe')(config)\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const { Strings } = await (await api.post('pubsub/ls', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })).json()\n\n    return Strings || []\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (topic, options = {}) => {\n    if (!options && typeof topic === 'object') {\n      options = topic || {}\n      topic = null\n    }\n\n    const res = await api.post('pubsub/peers', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: topic,\n        ...options\n      }),\n      headers: options.headers\n    })\n\n    const { Strings } = await res.json()\n\n    return Strings || []\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\nconst multipartRequest = require('../lib/multipart-request')\nconst abortSignal = require('../lib/abort-signal')\nconst { AbortController } = require('native-abort-controller')\n\nmodule.exports = configure(api => {\n  return async (topic, data, options = {}) => {\n    const searchParams = toUrlSearchParams({\n      arg: topic,\n      ...options\n    })\n\n    // allow aborting requests on body errors\n    const controller = new AbortController()\n    const signal = abortSignal(controller.signal, options.signal)\n\n    // @ts-ignore https://github.com/ipfs/js-ipfs-utils/issues/90\n    const res = await api.post('pubsub/pub', {\n      timeout: options.timeout,\n      signal,\n      searchParams,\n      ...(\n        await multipartRequest(data, controller, options.headers)\n      )\n    })\n\n    await res.text()\n  }\n})\n","'use strict'\n\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst log = require('debug')('ipfs-http-client:pubsub:subscribe')\nconst SubscriptionTracker = require('./subscription-tracker')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure((api, options) => {\n  const subsTracker = SubscriptionTracker.singleton()\n\n  return async (topic, handler, options = {}) => { // eslint-disable-line require-await\n    options.signal = subsTracker.subscribe(topic, handler, options.signal)\n\n    let done\n    let fail\n\n    const result = new Promise((resolve, reject) => {\n      done = resolve\n      fail = reject\n    })\n\n    // In Firefox, the initial call to fetch does not resolve until some data\n    // is received. If this doesn't happen within 1 second assume success\n    const ffWorkaround = setTimeout(() => done(), 1000)\n\n    // Do this async to not block Firefox\n    setTimeout(() => {\n      api.post('pubsub/sub', {\n        timeout: options.timeout,\n        signal: options.signal,\n        searchParams: toUrlSearchParams({\n          arg: topic,\n          ...options\n        }),\n        headers: options.headers\n      })\n        .catch((err) => {\n          // Initial subscribe fail, ensure we clean up\n          subsTracker.unsubscribe(topic, handler)\n\n          fail(err)\n        })\n        .then((response) => {\n          clearTimeout(ffWorkaround)\n\n          if (!response) {\n            // if there was no response, the subscribe failed\n            return\n          }\n\n          readMessages(response.ndjson(), {\n            onMessage: handler,\n            onEnd: () => subsTracker.unsubscribe(topic, handler),\n            onError: options.onError\n          })\n\n          done()\n        })\n    }, 0)\n\n    return result\n  }\n})\n\nasync function readMessages (msgStream, { onMessage, onEnd, onError }) {\n  onError = onError || log\n\n  try {\n    for await (const msg of msgStream) {\n      try {\n        if (!msg.from) {\n          continue\n        }\n\n        onMessage({\n          from: uint8ArrayToString(uint8ArrayFromString(msg.from, 'base64pad'), 'base58btc'),\n          data: uint8ArrayFromString(msg.data, 'base64pad'),\n          seqno: uint8ArrayFromString(msg.seqno, 'base64pad'),\n          topicIDs: msg.topicIDs\n        })\n      } catch (err) {\n        err.message = `Failed to parse pubsub message: ${err.message}`\n        onError(err, false, msg) // Not fatal\n      }\n    }\n  } catch (err) {\n    // FIXME: In testing with Chrome, err.type is undefined (should not be!)\n    // Temporarily use the name property instead.\n    if (err.type !== 'aborted' && err.name !== 'AbortError') {\n      onError(err, true) // Fatal\n    }\n  } finally {\n    onEnd()\n  }\n}\n","'use strict'\n\nconst { AbortController } = require('native-abort-controller')\n\nclass SubscriptionTracker {\n  constructor () {\n    this._subs = new Map()\n  }\n\n  static singleton () {\n    if (SubscriptionTracker.instance) return SubscriptionTracker.instance\n    SubscriptionTracker.instance = new SubscriptionTracker()\n    return SubscriptionTracker.instance\n  }\n\n  subscribe (topic, handler, signal) {\n    const topicSubs = this._subs.get(topic) || []\n\n    if (topicSubs.find(s => s.handler === handler)) {\n      throw new Error(`Already subscribed to ${topic} with this handler`)\n    }\n\n    // Create controller so a call to unsubscribe can cancel the request\n    const controller = new AbortController()\n\n    this._subs.set(topic, [{ handler, controller }].concat(topicSubs))\n\n    // If there is an external signal, forward the abort event\n    if (signal) {\n      signal.addEventListener('abort', () => this.unsubscribe(topic, handler))\n    }\n\n    return controller.signal\n  }\n\n  unsubscribe (topic, handler) {\n    const subs = this._subs.get(topic) || []\n    let unsubs\n\n    if (handler) {\n      this._subs.set(topic, subs.filter(s => s.handler !== handler))\n      unsubs = subs.filter(s => s.handler === handler)\n    } else {\n      this._subs.set(topic, [])\n      unsubs = subs\n    }\n\n    unsubs.forEach(s => s.controller.abort())\n  }\n}\n\nSubscriptionTracker.instance = null\n\nmodule.exports = SubscriptionTracker\n","'use strict'\n\nconst SubscriptionTracker = require('./subscription-tracker')\n\nmodule.exports = api => {\n  const subsTracker = SubscriptionTracker.singleton()\n  // eslint-disable-next-line require-await\n  return async (topic, handler) => subsTracker.unsubscribe(topic, handler)\n}\n","'use strict'\n\nconst CID = require('cids')\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure((api, options) => {\n  const refs = async function * (args, options = {}) {\n    if (!Array.isArray(args)) {\n      args = [args]\n    }\n\n    const res = await api.post('refs', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: args.map(arg => `${arg instanceof Uint8Array ? new CID(arg) : arg}`),\n        ...options\n      }),\n      headers: options.headers,\n      transform: toCamel\n    })\n\n    yield * res.ndjson()\n  }\n  refs.local = require('./local')(options)\n\n  return refs\n})\n","'use strict'\n\nconst toCamel = require('../lib/object-to-camel')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * refsLocal (options = {}) {\n    const res = await api.post('refs/local', {\n      timeout: options.timeout,\n      signal: options.signal,\n      transform: toCamel,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    yield * res.ndjson()\n  }\n})\n","'use strict'\n\nconst CID = require('cids')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * gc (options = {}) {\n    const res = await api.post('repo/gc', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers,\n      transform: (res) => {\n        return {\n          err: res.Error ? new Error(res.Error) : null,\n          cid: (res.Key || {})['/'] ? new CID(res.Key['/']) : null\n        }\n      }\n    })\n\n    yield * res.ndjson()\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  gc: require('./gc')(config),\n  stat: require('./stat')(config),\n  version: require('./version')(config)\n})\n","'use strict'\n\nconst { BigNumber } = require('bignumber.js')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('repo/stat', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const data = await res.json()\n\n    return {\n      numObjects: new BigNumber(data.NumObjects),\n      repoSize: new BigNumber(data.RepoSize),\n      repoPath: data.RepoPath,\n      version: data.Version,\n      storageMax: new BigNumber(data.StorageMax)\n    }\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await (await api.post('repo/version', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })).json()\n\n    return res.Version\n  }\n})\n","'use strict'\n\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/resolve')>}\n   */\n  async function resolve (path, options = {}) {\n    const res = await api.post('resolve', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: path,\n        ...options\n      }),\n      headers: options.headers\n    })\n    const { Path } = await res.json()\n    return Path\n  }\n  return resolve\n})\n","'use strict'\n\nconst { BigNumber } = require('bignumber.js')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async function * bw (options = {}) {\n    const res = await api.post('stats/bw', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers,\n      transform: (stats) => ({\n        totalIn: new BigNumber(stats.TotalIn),\n        totalOut: new BigNumber(stats.TotalOut),\n        rateIn: new BigNumber(stats.RateIn),\n        rateOut: new BigNumber(stats.RateOut)\n      })\n    })\n\n    yield * res.ndjson()\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  bitswap: require('../bitswap/stat')(config),\n  bw: require('./bw')(config),\n  repo: require('../repo/stat')(config)\n})\n","'use strict'\n\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('shutdown', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    await res.text()\n  }\n})\n","'use strict'\n\nconst multiaddr = require('multiaddr')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('swarm/addrs', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const { Addrs } = await res.json()\n\n    return Object.keys(Addrs).map(id => ({\n      id,\n      addrs: (Addrs[id] || []).map(a => multiaddr(a))\n    }))\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (addrs, options = {}) => {\n    addrs = Array.isArray(addrs) ? addrs : [addrs]\n\n    const res = await api.post('swarm/connect', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: addrs.map(addr => `${addr}`),\n        ...options\n      }),\n      headers: options.headers\n    })\n    const { Strings } = await res.json()\n\n    return Strings || []\n  }\n})\n","'use strict'\n\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (addrs, options = {}) => {\n    addrs = Array.isArray(addrs) ? addrs : [addrs]\n\n    const res = await api.post('swarm/disconnect', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams({\n        arg: addrs.map(addr => `${addr}`),\n        ...options\n      }),\n      headers: options.headers\n    })\n    const { Strings } = await res.json()\n\n    return Strings || []\n  }\n})\n","'use strict'\n\nmodule.exports = config => ({\n  addrs: require('./addrs')(config),\n  connect: require('./connect')(config),\n  disconnect: require('./disconnect')(config),\n  localAddrs: require('./localAddrs')(config),\n  peers: require('./peers')(config)\n})\n","'use strict'\n\nconst multiaddr = require('multiaddr')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await api.post('swarm/addrs/local', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n    const { Strings } = await res.json()\n\n    return (Strings || []).map(a => multiaddr(a))\n  }\n})\n","'use strict'\n\nconst multiaddr = require('multiaddr')\nconst configure = require('../lib/configure')\nconst toUrlSearchParams = require('../lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  return async (options = {}) => {\n    const res = await (await api.post('swarm/peers', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })).json()\n\n    return (res.Peers || []).map(peer => {\n      const info = {}\n      try {\n        info.addr = multiaddr(peer.Addr)\n        info.peer = peer.Peer\n      } catch (error) {\n        info.error = error\n        info.rawPeerInfo = peer\n      }\n      if (peer.Muxer) {\n        info.muxer = peer.Muxer\n      }\n      if (peer.Latency) {\n        info.latency = peer.Latency\n      }\n      if (peer.Streams) {\n        info.streams = peer.Streams\n      }\n      if (peer.Direction != null) {\n        info.direction = peer.Direction\n      }\n      return info\n    })\n  }\n})\n","'use strict'\n\nconst toCamel = require('./lib/object-to-camel')\nconst configure = require('./lib/configure')\nconst toUrlSearchParams = require('./lib/to-url-search-params')\n\nmodule.exports = configure(api => {\n  /**\n   * @type {import('.').Implements<typeof import('ipfs-core/src/components/version')>}\n   */\n  async function version (options = {}) {\n    const res = await api.post('version', {\n      timeout: options.timeout,\n      signal: options.signal,\n      searchParams: toUrlSearchParams(options),\n      headers: options.headers\n    })\n\n    return toCamel(await res.json())\n  }\n\n  return version\n})\n","'use strict'\n\nconst {\n  URLWithLegacySupport,\n  format,\n  URLSearchParams,\n  defaultBase\n} = require('./src/url')\nconst relative = require('./src/relative')\n\nmodule.exports = {\n  URL: URLWithLegacySupport,\n  URLSearchParams,\n  format,\n  relative,\n  defaultBase\n}\n","'use strict'\n\nconst { URLWithLegacySupport, format } = require('./url')\n\n/**\n * @param {string | undefined} url\n * @param {any} [location]\n * @param {any} [protocolMap]\n * @param {any} [defaultProtocol]\n */\nmodule.exports = (url, location = {}, protocolMap = {}, defaultProtocol) => {\n  let protocol = location.protocol\n    ? location.protocol.replace(':', '')\n    : 'http'\n\n  // Check protocol map\n  protocol = (protocolMap[protocol] || defaultProtocol || protocol) + ':'\n  let urlParsed\n\n  try {\n    urlParsed = new URLWithLegacySupport(url)\n  } catch (err) {\n    urlParsed = {}\n  }\n\n  const base = Object.assign({}, location, {\n    protocol: protocol || urlParsed.protocol,\n    host: location.host || urlParsed.host\n  })\n\n  return new URLWithLegacySupport(url, format(base)).toString()\n}\n","'use strict'\n\nconst isReactNative =\n    typeof navigator !== 'undefined' &&\n    navigator.product === 'ReactNative'\n\nfunction getDefaultBase () {\n  if (isReactNative) {\n    return 'http://localhost'\n  }\n\n  return self.location.protocol + '//' + self.location.host\n}\n\nconst URL = self.URL\nconst defaultBase = getDefaultBase()\n\nclass URLWithLegacySupport {\n  constructor (url = '', base = defaultBase) {\n    this.super = new URL(url, base)\n    this.path = this.pathname + this.search\n    this.auth =\n            this.username && this.password\n              ? this.username + ':' + this.password\n              : null\n\n    this.query =\n            this.search && this.search.startsWith('?')\n              ? this.search.slice(1)\n              : null\n  }\n\n  get hash () {\n    return this.super.hash\n  }\n\n  get host () {\n    return this.super.host\n  }\n\n  get hostname () {\n    return this.super.hostname\n  }\n\n  get href () {\n    return this.super.href\n  }\n\n  get origin () {\n    return this.super.origin\n  }\n\n  get password () {\n    return this.super.password\n  }\n\n  get pathname () {\n    return this.super.pathname\n  }\n\n  get port () {\n    return this.super.port\n  }\n\n  get protocol () {\n    return this.super.protocol\n  }\n\n  get search () {\n    return this.super.search\n  }\n\n  get searchParams () {\n    return this.super.searchParams\n  }\n\n  get username () {\n    return this.super.username\n  }\n\n  set hash (hash) {\n    this.super.hash = hash\n  }\n\n  set host (host) {\n    this.super.host = host\n  }\n\n  set hostname (hostname) {\n    this.super.hostname = hostname\n  }\n\n  set href (href) {\n    this.super.href = href\n  }\n\n  set password (password) {\n    this.super.password = password\n  }\n\n  set pathname (pathname) {\n    this.super.pathname = pathname\n  }\n\n  set port (port) {\n    this.super.port = port\n  }\n\n  set protocol (protocol) {\n    this.super.protocol = protocol\n  }\n\n  set search (search) {\n    this.super.search = search\n  }\n\n  set username (username) {\n    this.super.username = username\n  }\n\n  /**\n   * @param {any} o\n   */\n  static createObjectURL (o) {\n    return URL.createObjectURL(o)\n  }\n\n  /**\n   * @param {string} o\n   */\n  static revokeObjectURL (o) {\n    URL.revokeObjectURL(o)\n  }\n\n  toJSON () {\n    return this.super.toJSON()\n  }\n\n  toString () {\n    return this.super.toString()\n  }\n\n  format () {\n    return this.toString()\n  }\n}\n\n/**\n * @param {string | import('url').UrlObject} obj\n */\nfunction format (obj) {\n  if (typeof obj === 'string') {\n    const url = new URL(obj)\n\n    return url.toString()\n  }\n\n  if (!(obj instanceof URL)) {\n    const userPass =\n            // @ts-ignore its not supported in node but we normalise\n            obj.username && obj.password\n              // @ts-ignore its not supported in node but we normalise\n              ? `${obj.username}:${obj.password}@`\n              : ''\n    const auth = obj.auth ? obj.auth + '@' : ''\n    const port = obj.port ? ':' + obj.port : ''\n    const protocol = obj.protocol ? obj.protocol + '//' : ''\n    const host = obj.host || ''\n    const hostname = obj.hostname || ''\n    const search = obj.search || (obj.query ? '?' + obj.query : '')\n    const hash = obj.hash || ''\n    const pathname = obj.pathname || ''\n    // @ts-ignore - path is not supported in node but we normalise\n    const path = obj.path || pathname + search\n\n    return `${protocol}${userPass || auth}${\n            host || hostname + port\n        }${path}${hash}`\n  }\n}\n\nmodule.exports = {\n  URLWithLegacySupport,\n  URLSearchParams: self.URLSearchParams,\n  defaultBase,\n  format\n}\n","'use strict'\n\nmodule.exports = {\n  DEFAULT_HTTP_API: '/ip4/127.0.0.1/tcp/5001'\n}\n","'use strict'\n\nmodule.exports = {\n  httpClient: 'httpClient',\n  windowIpfs: 'windowIpfs',\n  jsIpfs: 'jsIpfs',\n  webExt: 'webExt'\n}\n","'use strict'\n/* global self */\n\n// Establish the root object, `window` in the browser, `self` in Service Worker. or `global` on the server.\n// Credit: https://github.com/megawac/underscore/commit/365311c9a440438531ca1c6bfd49e3c7c5f46079\nmodule.exports = (typeof self === 'object' && self.self === self && self) ||\n  (typeof global === 'object' && global.global === global && global) ||\n  this\n","'use strict'\n\nconst root = require('./constants/root')\nconst mergeOptions = require('merge-options')\nconst tryWebExt = require('./providers/webext')\nconst tryWindow = require('./providers/window-ipfs')\nconst tryHttpClient = require('./providers/http-client')\nconst tryJsIpfs = require('./providers/js-ipfs')\n\nconst defaultGlobalOpts = {\n  connectionTest: async (ipfs) => {\n    // ipfs connection is working if we can fetch data via async iterator API\n    const cid = 'QmUNLLsPACCz1vLxQVkXqqLX5R1X345qqfHbsf67hvA3Nn' // TODO: switch to identity hash when js-ipfs is fixed: https://github.com/ipfs/js-ipfs/issues/3289\n    for await (const file of ipfs.get(cid)) {\n      if (file.type === 'dir' && file.name === cid) return true\n    }\n    return false\n  }\n}\n\nconst makeProvider = (fn, defaults = {}) => {\n  return (options = {}) => {\n    return (globalOpts) => {\n      options = mergeOptions(defaultGlobalOpts, defaults, globalOpts, options)\n      return fn(options)\n    }\n  }\n}\n\nconst providers = {\n  httpClient: makeProvider((options) => {\n    return tryHttpClient({ root, ...options })\n  }),\n  windowIpfs: makeProvider(options => {\n    return tryWindow({ root, ...options })\n  }),\n  jsIpfs: makeProvider(options => {\n    return tryJsIpfs(options)\n  }),\n  webExt: makeProvider(options => {\n    return tryWebExt({ root, ...options })\n  })\n}\n\nconst defaultProviders = [\n  providers.windowIpfs(),\n  providers.httpClient()\n]\n\nasync function getIpfs ({ providers = defaultProviders, ...options } = {}) {\n  for (const provider of providers) {\n    try {\n      const res = await provider(options)\n      if (res) return res\n    } catch (err) {\n      // provider failed unexpectedly, log error and move to the next one\n      console.error('[ipfs-provider]', err) // eslint-disable-line no-console\n    }\n  }\n}\n\nmodule.exports = {\n  getIpfs,\n  providers,\n  makeProvider\n}\n","'use strict'\n\nconst { URL } = require('iso-url')\nconst PROVIDERS = require('../constants/providers')\nconst { DEFAULT_HTTP_API } = require('../constants/defaults')\n\n/*\n * This provider lazy-loads https://github.com/ipfs/js-ipfs/tree/master/packages/ipfs-http-client\n * so it is not included as a dependency if not used.\n *\n * HTTP Client init fallback:\n * 1. Use constructor returned by loadHttpClientModule function\n * 2. Fallback to window.IpfsHttpClient\n *\n * API URL fallback order:\n * 1. Try user specified API address\n * 2. Try current origin\n * 3. Try DEFAULT_HTTP_API\n*/\nasync function tryHttpClient ({ loadHttpClientModule, apiAddress, root, connectionTest, ...options }) {\n  // Find HTTP client\n  let httpClient\n  if (loadHttpClientModule) httpClient = await loadHttpClientModule()\n\n  // Final fallback to window.IpfsHttpClient or error\n  if (!httpClient) {\n    if (root.IpfsHttpClient) {\n      httpClient = root.IpfsHttpClient\n    } else {\n      throw new Error('ipfs-provider could not initialize js-ipfs-http-client: make sure its constructor is returned by loadHttpClientModule function or exposed at window.IpfsHttpClient')\n    }\n  }\n\n  // Allow the use of `import` or `require` on `loadHttpClientModule` fn\n  httpClient = httpClient.default || httpClient // TODO: create 'import' demo in examples/\n\n  // If explicit custom apiAddress provided, only try that.\n  if (apiAddress || options.url || options.host) {\n    return maybeApi({ apiAddress, connectionTest, httpClient, ...options })\n  }\n\n  // Current origin is not localhost:5001 so try with current origin info\n  const { location } = root\n  if (location && !(location.port === '5001' && location.hostname.match(/^127.0.0.1$|^localhost$/))) {\n    const origin = new URL(location.origin)\n    origin.pathname = '/'\n    const res = await maybeApi({\n      apiAddress: origin.toString(),\n      connectionTest,\n      httpClient,\n      ...options\n    })\n    if (res) return res\n  }\n\n  // ...otherwise try /ip4/127.0.0.1/tcp/5001\n  return maybeApi({ apiAddress: DEFAULT_HTTP_API, connectionTest, httpClient, ...options })\n}\n\n// Init and test an api client against provided API address.\n// Returns js-ipfs-http-client instance or null\nasync function maybeApi ({ apiAddress, connectionTest, httpClient, ...options }) {\n  try {\n    let ipfs\n    try {\n      ipfs = httpClient.create({ ...options, ...clientOptions(apiAddress) })\n    } catch (_) {\n      ipfs = httpClient({ ...options, ...clientOptions(apiAddress) })\n    }\n    await connectionTest(ipfs)\n    return { ipfs, provider: PROVIDERS.httpClient, apiAddress }\n  } catch (error) {\n    // Failed to connect to ipfs-api in `apiAddress`\n    // console.error('[ipfs-provider:httpClient]', error)\n    return null\n  }\n}\n\n// Convert string with URL or Multiaddr to explicit configuration object\n// https://www.npmjs.com/package/ipfs-http-client#usage\nconst clientOptions = (apiAddress) => {\n  switch (typeof apiAddress) {\n    case 'string':\n      return { url: apiAddress }\n    case 'object':\n      return JSON.parse(JSON.stringify(apiAddress)) // ensure deep copy\n    case 'undefined':\n      return {}\n    default:\n      throw new Error('invalid apiAddress passed to httpClient')\n  }\n}\n\nmodule.exports = tryHttpClient\n","'use strict'\n\nconst PROVIDERS = require('../constants/providers')\n\nasync function createIpfs (ipfsModule, opts) {\n  // Allow the use of `import` or `require` on `getJsIpfs` fn\n  ipfsModule = ipfsModule.default || ipfsModule\n  return ipfsModule.create(opts)\n}\n\nasync function tryJsIpfs ({ connectionTest, loadJsIpfsModule, options, init = createIpfs }) {\n  const ipfsModule = await loadJsIpfsModule()\n  const ipfs = await init(ipfsModule, options)\n  await connectionTest(ipfs)\n  return { ipfs, provider: PROVIDERS.jsIpfs }\n}\n\nmodule.exports = tryJsIpfs\n","'use strict'\n\nconst PROVIDERS = require('../constants/providers')\n\nasync function tryWebExt ({ root, connectionTest }) {\n  // Opportunistic optimizations when running inside of web extension (eg. ipfs-companion)\n  if (typeof root.chrome === 'object' && root.chrome.extension && root.chrome.extension.getBackgroundPage) {\n    // Note: under some vendors getBackgroundPage() will return null if window is in incognito mode\n    // https://bugzilla.mozilla.org/show_bug.cgi?id=1329304\n    let bg = null\n    try {\n      bg = root.chrome.extension.getBackgroundPage()\n    } catch (err) {\n      // not in browser extension\n      return null\n    }\n    // If extension is exposing IPFS API as `ipfs` on the background page\n    // it can be used directly for the best performance\n    if (bg && bg.ipfs) {\n      const { ipfs } = bg\n      await connectionTest(ipfs)\n      return { ipfs, provider: PROVIDERS.webExt }\n    }\n    /*  Other endpoints can be added here in the future.\n        For example, Companion could provide API for other browser extensions:\n        https://github.com/ipfs-shipyard/ipfs-companion/issues/307 */\n  }\n}\n\nmodule.exports = tryWebExt\n","'use strict'\n\nconst PROVIDERS = require('../constants/providers')\n\nasync function tryWindow ({ root, permissions, connectionTest }) {\n  if (root.ipfs) {\n    // files.get is required for testing if API works, ensure we request it\n    if (!(permissions && permissions.commands && permissions.commands.includes('files.get'))) {\n      permissions = permissions || {}\n      permissions = JSON.parse(JSON.stringify(permissions)) // deep copy to work with freezed objects\n      permissions.commands = permissions.commands || []\n      permissions.commands.push('files.get')\n    }\n    // try window.ipfs.enable first: https://github.com/ipfs-shipyard/ipfs-companion/issues/589\n    const ipfs = typeof root.ipfs.enable === 'function'\n      ? await root.ipfs.enable(permissions)\n      : root.ipfs\n    await connectionTest(ipfs)\n    return { ipfs, provider: PROVIDERS.windowIpfs }\n  }\n}\n\nmodule.exports = tryWindow\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict'\n\nconst {\n  Data: PBData\n} = require('./unixfs')\nconst errcode = require('err-code')\n\n/**\n * @typedef {import('./types').Mtime} Mtime\n * @typedef {import('./types').MtimeLike} MtimeLike\n */\n\nconst types = [\n  'raw',\n  'directory',\n  'file',\n  'metadata',\n  'symlink',\n  'hamt-sharded-directory'\n]\n\nconst dirTypes = [\n  'directory',\n  'hamt-sharded-directory'\n]\n\nconst DEFAULT_FILE_MODE = parseInt('0644', 8)\nconst DEFAULT_DIRECTORY_MODE = parseInt('0755', 8)\n\n/**\n * @param {string | number | undefined} [mode]\n */\nfunction parseMode (mode) {\n  if (mode == null) {\n    return undefined\n  }\n\n  if (typeof mode === 'number') {\n    return mode & 0xFFF\n  }\n\n  mode = mode.toString()\n\n  if (mode.substring(0, 1) === '0') {\n    // octal string\n    return parseInt(mode, 8) & 0xFFF\n  }\n\n  // decimal string\n  return parseInt(mode, 10) & 0xFFF\n}\n\n/**\n * @param {any} input\n */\nfunction parseMtime (input) {\n  if (input == null) {\n    return undefined\n  }\n\n  /** @type {Mtime | undefined} */\n  let mtime\n\n  // { secs, nsecs }\n  if (input.secs != null) {\n    mtime = {\n      secs: input.secs,\n      nsecs: input.nsecs\n    }\n  }\n\n  // UnixFS TimeSpec\n  if (input.Seconds != null) {\n    mtime = {\n      secs: input.Seconds,\n      nsecs: input.FractionalNanoseconds\n    }\n  }\n\n  // process.hrtime()\n  if (Array.isArray(input)) {\n    mtime = {\n      secs: input[0],\n      nsecs: input[1]\n    }\n  }\n\n  // Javascript Date\n  if (input instanceof Date) {\n    const ms = input.getTime()\n    const secs = Math.floor(ms / 1000)\n\n    mtime = {\n      secs: secs,\n      nsecs: (ms - (secs * 1000)) * 1000\n    }\n  }\n\n  /*\n  TODO: https://github.com/ipfs/aegir/issues/487\n\n  // process.hrtime.bigint()\n  if (input instanceof BigInt) {\n    const secs = input / BigInt(1e9)\n    const nsecs = input - (secs * BigInt(1e9))\n\n    mtime = {\n      secs: parseInt(secs.toString()),\n      nsecs: parseInt(nsecs.toString())\n    }\n  }\n  */\n\n  if (!Object.prototype.hasOwnProperty.call(mtime, 'secs')) {\n    return undefined\n  }\n\n  if (mtime != null && mtime.nsecs != null && (mtime.nsecs < 0 || mtime.nsecs > 999999999)) {\n    throw errcode(new Error('mtime-nsecs must be within the range [0,999999999]'), 'ERR_INVALID_MTIME_NSECS')\n  }\n\n  return mtime\n}\n\nclass Data {\n  /**\n   * Decode from protobuf https://github.com/ipfs/specs/blob/master/UNIXFS.md\n   *\n   * @param {Uint8Array} marshaled\n   */\n  static unmarshal (marshaled) {\n    const message = PBData.decode(marshaled)\n    const decoded = PBData.toObject(message, {\n      defaults: false,\n      arrays: true,\n      longs: Number,\n      objects: false\n    })\n\n    const data = new Data({\n      type: types[decoded.Type],\n      data: decoded.Data,\n      blockSizes: decoded.blocksizes,\n      mode: decoded.mode,\n      mtime: decoded.mtime\n        ? {\n            secs: decoded.mtime.Seconds,\n            nsecs: decoded.mtime.FractionalNanoseconds\n          }\n        : undefined\n    })\n\n    // make sure we honour the original mode\n    data._originalMode = decoded.mode || 0\n\n    return data\n  }\n\n  /**\n   * @param {object} [options]\n   * @param {string} [options.type='file']\n   * @param {Uint8Array} [options.data]\n   * @param {number[]} [options.blockSizes]\n   * @param {number} [options.hashType]\n   * @param {number} [options.fanout]\n   * @param {MtimeLike | null} [options.mtime]\n   * @param {number | string} [options.mode]\n   */\n  constructor (options = {\n    type: 'file'\n  }) {\n    const {\n      type,\n      data,\n      blockSizes,\n      hashType,\n      fanout,\n      mtime,\n      mode\n    } = options\n\n    if (type && !types.includes(type)) {\n      throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    this.type = type || 'file'\n    this.data = data\n    this.hashType = hashType\n    this.fanout = fanout\n\n    /** @type {number[]} */\n    this.blockSizes = blockSizes || []\n    this._originalMode = 0\n    this.mode = parseMode(mode)\n\n    if (mtime) {\n      this.mtime = parseMtime(mtime)\n\n      if (this.mtime && !this.mtime.nsecs) {\n        this.mtime.nsecs = 0\n      }\n    }\n  }\n\n  /**\n   * @param {number | undefined} mode\n   */\n  set mode (mode) {\n    this._mode = this.isDirectory() ? DEFAULT_DIRECTORY_MODE : DEFAULT_FILE_MODE\n\n    const parsedMode = parseMode(mode)\n\n    if (parsedMode !== undefined) {\n      this._mode = parsedMode\n    }\n  }\n\n  /**\n   * @returns {number | undefined}\n   */\n  get mode () {\n    return this._mode\n  }\n\n  isDirectory () {\n    return Boolean(this.type && dirTypes.includes(this.type))\n  }\n\n  /**\n   * @param {number} size\n   */\n  addBlockSize (size) {\n    this.blockSizes.push(size)\n  }\n\n  /**\n   * @param {number} index\n   */\n  removeBlockSize (index) {\n    this.blockSizes.splice(index, 1)\n  }\n\n  /**\n   * Returns `0` for directories or `data.length + sum(blockSizes)` for everything else\n   */\n  fileSize () {\n    if (this.isDirectory()) {\n      // dirs don't have file size\n      return 0\n    }\n\n    let sum = 0\n    this.blockSizes.forEach((size) => {\n      sum += size\n    })\n\n    if (this.data) {\n      sum += this.data.length\n    }\n\n    return sum\n  }\n\n  /**\n   * encode to protobuf Uint8Array\n   */\n  marshal () {\n    let type\n\n    switch (this.type) {\n      case 'raw': type = PBData.DataType.Raw; break\n      case 'directory': type = PBData.DataType.Directory; break\n      case 'file': type = PBData.DataType.File; break\n      case 'metadata': type = PBData.DataType.Metadata; break\n      case 'symlink': type = PBData.DataType.Symlink; break\n      case 'hamt-sharded-directory': type = PBData.DataType.HAMTShard; break\n      default:\n        throw errcode(new Error('Type: ' + type + ' is not valid'), 'ERR_INVALID_TYPE')\n    }\n\n    let data = this.data\n\n    if (!this.data || !this.data.length) {\n      data = undefined\n    }\n\n    let mode\n\n    if (this.mode != null) {\n      mode = (this._originalMode & 0xFFFFF000) | (parseMode(this.mode) || 0)\n\n      if (mode === DEFAULT_FILE_MODE && !this.isDirectory()) {\n        mode = undefined\n      }\n\n      if (mode === DEFAULT_DIRECTORY_MODE && this.isDirectory()) {\n        mode = undefined\n      }\n    }\n\n    let mtime\n\n    if (this.mtime != null) {\n      const parsed = parseMtime(this.mtime)\n\n      if (parsed) {\n        mtime = {\n          Seconds: parsed.secs,\n          FractionalNanoseconds: parsed.nsecs\n        }\n\n        if (mtime.FractionalNanoseconds === 0) {\n          delete mtime.FractionalNanoseconds\n        }\n      }\n    }\n\n    const pbData = {\n      Type: type,\n      Data: data,\n      filesize: this.isDirectory() ? undefined : this.fileSize(),\n      blocksizes: this.blockSizes,\n      hashType: this.hashType,\n      fanout: this.fanout,\n      mode,\n      mtime\n    }\n\n    return PBData.encode(pbData).finish()\n  }\n}\n\nmodule.exports = {\n  UnixFS: Data,\n  parseMode,\n  parseMtime\n}\n","/*eslint-disable*/\n\"use strict\";\n\nvar $protobuf = require(\"protobufjs/minimal\");\n\n// Common aliases\nvar $Reader = $protobuf.Reader, $Writer = $protobuf.Writer, $util = $protobuf.util;\n\n// Exported root namespace\nvar $root = $protobuf.roots[\"default\"] || ($protobuf.roots[\"default\"] = {});\n\n$root.Data = (function() {\n\n    /**\n     * Properties of a Data.\n     * @exports IData\n     * @interface IData\n     * @property {Data.DataType} Type Data Type\n     * @property {Uint8Array|null} [Data] Data Data\n     * @property {number|null} [filesize] Data filesize\n     * @property {Array.<number>|null} [blocksizes] Data blocksizes\n     * @property {number|null} [hashType] Data hashType\n     * @property {number|null} [fanout] Data fanout\n     * @property {number|null} [mode] Data mode\n     * @property {IUnixTime|null} [mtime] Data mtime\n     */\n\n    /**\n     * Constructs a new Data.\n     * @exports Data\n     * @classdesc Represents a Data.\n     * @implements IData\n     * @constructor\n     * @param {IData=} [p] Properties to set\n     */\n    function Data(p) {\n        this.blocksizes = [];\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Data Type.\n     * @member {Data.DataType} Type\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Type = 0;\n\n    /**\n     * Data Data.\n     * @member {Uint8Array} Data\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.Data = $util.newBuffer([]);\n\n    /**\n     * Data filesize.\n     * @member {number} filesize\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.filesize = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data blocksizes.\n     * @member {Array.<number>} blocksizes\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.blocksizes = $util.emptyArray;\n\n    /**\n     * Data hashType.\n     * @member {number} hashType\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.hashType = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data fanout.\n     * @member {number} fanout\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.fanout = $util.Long ? $util.Long.fromBits(0,0,true) : 0;\n\n    /**\n     * Data mode.\n     * @member {number} mode\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mode = 0;\n\n    /**\n     * Data mtime.\n     * @member {IUnixTime|null|undefined} mtime\n     * @memberof Data\n     * @instance\n     */\n    Data.prototype.mtime = null;\n\n    /**\n     * Encodes the specified Data message. Does not implicitly {@link Data.verify|verify} messages.\n     * @function encode\n     * @memberof Data\n     * @static\n     * @param {IData} m Data message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Data.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int32(m.Type);\n        if (m.Data != null && Object.hasOwnProperty.call(m, \"Data\"))\n            w.uint32(18).bytes(m.Data);\n        if (m.filesize != null && Object.hasOwnProperty.call(m, \"filesize\"))\n            w.uint32(24).uint64(m.filesize);\n        if (m.blocksizes != null && m.blocksizes.length) {\n            for (var i = 0; i < m.blocksizes.length; ++i)\n                w.uint32(32).uint64(m.blocksizes[i]);\n        }\n        if (m.hashType != null && Object.hasOwnProperty.call(m, \"hashType\"))\n            w.uint32(40).uint64(m.hashType);\n        if (m.fanout != null && Object.hasOwnProperty.call(m, \"fanout\"))\n            w.uint32(48).uint64(m.fanout);\n        if (m.mode != null && Object.hasOwnProperty.call(m, \"mode\"))\n            w.uint32(56).uint32(m.mode);\n        if (m.mtime != null && Object.hasOwnProperty.call(m, \"mtime\"))\n            $root.UnixTime.encode(m.mtime, w.uint32(66).fork()).ldelim();\n        return w;\n    };\n\n    /**\n     * Decodes a Data message from the specified reader or buffer.\n     * @function decode\n     * @memberof Data\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Data} Data\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Data.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Data();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Type = r.int32();\n                break;\n            case 2:\n                m.Data = r.bytes();\n                break;\n            case 3:\n                m.filesize = r.uint64();\n                break;\n            case 4:\n                if (!(m.blocksizes && m.blocksizes.length))\n                    m.blocksizes = [];\n                if ((t & 7) === 2) {\n                    var c2 = r.uint32() + r.pos;\n                    while (r.pos < c2)\n                        m.blocksizes.push(r.uint64());\n                } else\n                    m.blocksizes.push(r.uint64());\n                break;\n            case 5:\n                m.hashType = r.uint64();\n                break;\n            case 6:\n                m.fanout = r.uint64();\n                break;\n            case 7:\n                m.mode = r.uint32();\n                break;\n            case 8:\n                m.mtime = $root.UnixTime.decode(r, r.uint32());\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Type\"))\n            throw $util.ProtocolError(\"missing required 'Type'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates a Data message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Data\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Data} Data\n     */\n    Data.fromObject = function fromObject(d) {\n        if (d instanceof $root.Data)\n            return d;\n        var m = new $root.Data();\n        switch (d.Type) {\n        case \"Raw\":\n        case 0:\n            m.Type = 0;\n            break;\n        case \"Directory\":\n        case 1:\n            m.Type = 1;\n            break;\n        case \"File\":\n        case 2:\n            m.Type = 2;\n            break;\n        case \"Metadata\":\n        case 3:\n            m.Type = 3;\n            break;\n        case \"Symlink\":\n        case 4:\n            m.Type = 4;\n            break;\n        case \"HAMTShard\":\n        case 5:\n            m.Type = 5;\n            break;\n        }\n        if (d.Data != null) {\n            if (typeof d.Data === \"string\")\n                $util.base64.decode(d.Data, m.Data = $util.newBuffer($util.base64.length(d.Data)), 0);\n            else if (d.Data.length)\n                m.Data = d.Data;\n        }\n        if (d.filesize != null) {\n            if ($util.Long)\n                (m.filesize = $util.Long.fromValue(d.filesize)).unsigned = true;\n            else if (typeof d.filesize === \"string\")\n                m.filesize = parseInt(d.filesize, 10);\n            else if (typeof d.filesize === \"number\")\n                m.filesize = d.filesize;\n            else if (typeof d.filesize === \"object\")\n                m.filesize = new $util.LongBits(d.filesize.low >>> 0, d.filesize.high >>> 0).toNumber(true);\n        }\n        if (d.blocksizes) {\n            if (!Array.isArray(d.blocksizes))\n                throw TypeError(\".Data.blocksizes: array expected\");\n            m.blocksizes = [];\n            for (var i = 0; i < d.blocksizes.length; ++i) {\n                if ($util.Long)\n                    (m.blocksizes[i] = $util.Long.fromValue(d.blocksizes[i])).unsigned = true;\n                else if (typeof d.blocksizes[i] === \"string\")\n                    m.blocksizes[i] = parseInt(d.blocksizes[i], 10);\n                else if (typeof d.blocksizes[i] === \"number\")\n                    m.blocksizes[i] = d.blocksizes[i];\n                else if (typeof d.blocksizes[i] === \"object\")\n                    m.blocksizes[i] = new $util.LongBits(d.blocksizes[i].low >>> 0, d.blocksizes[i].high >>> 0).toNumber(true);\n            }\n        }\n        if (d.hashType != null) {\n            if ($util.Long)\n                (m.hashType = $util.Long.fromValue(d.hashType)).unsigned = true;\n            else if (typeof d.hashType === \"string\")\n                m.hashType = parseInt(d.hashType, 10);\n            else if (typeof d.hashType === \"number\")\n                m.hashType = d.hashType;\n            else if (typeof d.hashType === \"object\")\n                m.hashType = new $util.LongBits(d.hashType.low >>> 0, d.hashType.high >>> 0).toNumber(true);\n        }\n        if (d.fanout != null) {\n            if ($util.Long)\n                (m.fanout = $util.Long.fromValue(d.fanout)).unsigned = true;\n            else if (typeof d.fanout === \"string\")\n                m.fanout = parseInt(d.fanout, 10);\n            else if (typeof d.fanout === \"number\")\n                m.fanout = d.fanout;\n            else if (typeof d.fanout === \"object\")\n                m.fanout = new $util.LongBits(d.fanout.low >>> 0, d.fanout.high >>> 0).toNumber(true);\n        }\n        if (d.mode != null) {\n            m.mode = d.mode >>> 0;\n        }\n        if (d.mtime != null) {\n            if (typeof d.mtime !== \"object\")\n                throw TypeError(\".Data.mtime: object expected\");\n            m.mtime = $root.UnixTime.fromObject(d.mtime);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Data message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Data\n     * @static\n     * @param {Data} m Data\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Data.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.arrays || o.defaults) {\n            d.blocksizes = [];\n        }\n        if (o.defaults) {\n            d.Type = o.enums === String ? \"Raw\" : 0;\n            if (o.bytes === String)\n                d.Data = \"\";\n            else {\n                d.Data = [];\n                if (o.bytes !== Array)\n                    d.Data = $util.newBuffer(d.Data);\n            }\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.filesize = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.filesize = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.hashType = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.hashType = o.longs === String ? \"0\" : 0;\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, true);\n                d.fanout = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.fanout = o.longs === String ? \"0\" : 0;\n            d.mode = 0;\n            d.mtime = null;\n        }\n        if (m.Type != null && m.hasOwnProperty(\"Type\")) {\n            d.Type = o.enums === String ? $root.Data.DataType[m.Type] : m.Type;\n        }\n        if (m.Data != null && m.hasOwnProperty(\"Data\")) {\n            d.Data = o.bytes === String ? $util.base64.encode(m.Data, 0, m.Data.length) : o.bytes === Array ? Array.prototype.slice.call(m.Data) : m.Data;\n        }\n        if (m.filesize != null && m.hasOwnProperty(\"filesize\")) {\n            if (typeof m.filesize === \"number\")\n                d.filesize = o.longs === String ? String(m.filesize) : m.filesize;\n            else\n                d.filesize = o.longs === String ? $util.Long.prototype.toString.call(m.filesize) : o.longs === Number ? new $util.LongBits(m.filesize.low >>> 0, m.filesize.high >>> 0).toNumber(true) : m.filesize;\n        }\n        if (m.blocksizes && m.blocksizes.length) {\n            d.blocksizes = [];\n            for (var j = 0; j < m.blocksizes.length; ++j) {\n                if (typeof m.blocksizes[j] === \"number\")\n                    d.blocksizes[j] = o.longs === String ? String(m.blocksizes[j]) : m.blocksizes[j];\n                else\n                    d.blocksizes[j] = o.longs === String ? $util.Long.prototype.toString.call(m.blocksizes[j]) : o.longs === Number ? new $util.LongBits(m.blocksizes[j].low >>> 0, m.blocksizes[j].high >>> 0).toNumber(true) : m.blocksizes[j];\n            }\n        }\n        if (m.hashType != null && m.hasOwnProperty(\"hashType\")) {\n            if (typeof m.hashType === \"number\")\n                d.hashType = o.longs === String ? String(m.hashType) : m.hashType;\n            else\n                d.hashType = o.longs === String ? $util.Long.prototype.toString.call(m.hashType) : o.longs === Number ? new $util.LongBits(m.hashType.low >>> 0, m.hashType.high >>> 0).toNumber(true) : m.hashType;\n        }\n        if (m.fanout != null && m.hasOwnProperty(\"fanout\")) {\n            if (typeof m.fanout === \"number\")\n                d.fanout = o.longs === String ? String(m.fanout) : m.fanout;\n            else\n                d.fanout = o.longs === String ? $util.Long.prototype.toString.call(m.fanout) : o.longs === Number ? new $util.LongBits(m.fanout.low >>> 0, m.fanout.high >>> 0).toNumber(true) : m.fanout;\n        }\n        if (m.mode != null && m.hasOwnProperty(\"mode\")) {\n            d.mode = m.mode;\n        }\n        if (m.mtime != null && m.hasOwnProperty(\"mtime\")) {\n            d.mtime = $root.UnixTime.toObject(m.mtime, o);\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Data to JSON.\n     * @function toJSON\n     * @memberof Data\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Data.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    /**\n     * DataType enum.\n     * @name Data.DataType\n     * @enum {number}\n     * @property {number} Raw=0 Raw value\n     * @property {number} Directory=1 Directory value\n     * @property {number} File=2 File value\n     * @property {number} Metadata=3 Metadata value\n     * @property {number} Symlink=4 Symlink value\n     * @property {number} HAMTShard=5 HAMTShard value\n     */\n    Data.DataType = (function() {\n        var valuesById = {}, values = Object.create(valuesById);\n        values[valuesById[0] = \"Raw\"] = 0;\n        values[valuesById[1] = \"Directory\"] = 1;\n        values[valuesById[2] = \"File\"] = 2;\n        values[valuesById[3] = \"Metadata\"] = 3;\n        values[valuesById[4] = \"Symlink\"] = 4;\n        values[valuesById[5] = \"HAMTShard\"] = 5;\n        return values;\n    })();\n\n    return Data;\n})();\n\n$root.UnixTime = (function() {\n\n    /**\n     * Properties of an UnixTime.\n     * @exports IUnixTime\n     * @interface IUnixTime\n     * @property {number} Seconds UnixTime Seconds\n     * @property {number|null} [FractionalNanoseconds] UnixTime FractionalNanoseconds\n     */\n\n    /**\n     * Constructs a new UnixTime.\n     * @exports UnixTime\n     * @classdesc Represents an UnixTime.\n     * @implements IUnixTime\n     * @constructor\n     * @param {IUnixTime=} [p] Properties to set\n     */\n    function UnixTime(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * UnixTime Seconds.\n     * @member {number} Seconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.Seconds = $util.Long ? $util.Long.fromBits(0,0,false) : 0;\n\n    /**\n     * UnixTime FractionalNanoseconds.\n     * @member {number} FractionalNanoseconds\n     * @memberof UnixTime\n     * @instance\n     */\n    UnixTime.prototype.FractionalNanoseconds = 0;\n\n    /**\n     * Encodes the specified UnixTime message. Does not implicitly {@link UnixTime.verify|verify} messages.\n     * @function encode\n     * @memberof UnixTime\n     * @static\n     * @param {IUnixTime} m UnixTime message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    UnixTime.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        w.uint32(8).int64(m.Seconds);\n        if (m.FractionalNanoseconds != null && Object.hasOwnProperty.call(m, \"FractionalNanoseconds\"))\n            w.uint32(21).fixed32(m.FractionalNanoseconds);\n        return w;\n    };\n\n    /**\n     * Decodes an UnixTime message from the specified reader or buffer.\n     * @function decode\n     * @memberof UnixTime\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {UnixTime} UnixTime\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    UnixTime.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.UnixTime();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.Seconds = r.int64();\n                break;\n            case 2:\n                m.FractionalNanoseconds = r.fixed32();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        if (!m.hasOwnProperty(\"Seconds\"))\n            throw $util.ProtocolError(\"missing required 'Seconds'\", { instance: m });\n        return m;\n    };\n\n    /**\n     * Creates an UnixTime message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof UnixTime\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {UnixTime} UnixTime\n     */\n    UnixTime.fromObject = function fromObject(d) {\n        if (d instanceof $root.UnixTime)\n            return d;\n        var m = new $root.UnixTime();\n        if (d.Seconds != null) {\n            if ($util.Long)\n                (m.Seconds = $util.Long.fromValue(d.Seconds)).unsigned = false;\n            else if (typeof d.Seconds === \"string\")\n                m.Seconds = parseInt(d.Seconds, 10);\n            else if (typeof d.Seconds === \"number\")\n                m.Seconds = d.Seconds;\n            else if (typeof d.Seconds === \"object\")\n                m.Seconds = new $util.LongBits(d.Seconds.low >>> 0, d.Seconds.high >>> 0).toNumber();\n        }\n        if (d.FractionalNanoseconds != null) {\n            m.FractionalNanoseconds = d.FractionalNanoseconds >>> 0;\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from an UnixTime message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof UnixTime\n     * @static\n     * @param {UnixTime} m UnixTime\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    UnixTime.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            if ($util.Long) {\n                var n = new $util.Long(0, 0, false);\n                d.Seconds = o.longs === String ? n.toString() : o.longs === Number ? n.toNumber() : n;\n            } else\n                d.Seconds = o.longs === String ? \"0\" : 0;\n            d.FractionalNanoseconds = 0;\n        }\n        if (m.Seconds != null && m.hasOwnProperty(\"Seconds\")) {\n            if (typeof m.Seconds === \"number\")\n                d.Seconds = o.longs === String ? String(m.Seconds) : m.Seconds;\n            else\n                d.Seconds = o.longs === String ? $util.Long.prototype.toString.call(m.Seconds) : o.longs === Number ? new $util.LongBits(m.Seconds.low >>> 0, m.Seconds.high >>> 0).toNumber() : m.Seconds;\n        }\n        if (m.FractionalNanoseconds != null && m.hasOwnProperty(\"FractionalNanoseconds\")) {\n            d.FractionalNanoseconds = m.FractionalNanoseconds;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this UnixTime to JSON.\n     * @function toJSON\n     * @memberof UnixTime\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    UnixTime.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return UnixTime;\n})();\n\n$root.Metadata = (function() {\n\n    /**\n     * Properties of a Metadata.\n     * @exports IMetadata\n     * @interface IMetadata\n     * @property {string|null} [MimeType] Metadata MimeType\n     */\n\n    /**\n     * Constructs a new Metadata.\n     * @exports Metadata\n     * @classdesc Represents a Metadata.\n     * @implements IMetadata\n     * @constructor\n     * @param {IMetadata=} [p] Properties to set\n     */\n    function Metadata(p) {\n        if (p)\n            for (var ks = Object.keys(p), i = 0; i < ks.length; ++i)\n                if (p[ks[i]] != null)\n                    this[ks[i]] = p[ks[i]];\n    }\n\n    /**\n     * Metadata MimeType.\n     * @member {string} MimeType\n     * @memberof Metadata\n     * @instance\n     */\n    Metadata.prototype.MimeType = \"\";\n\n    /**\n     * Encodes the specified Metadata message. Does not implicitly {@link Metadata.verify|verify} messages.\n     * @function encode\n     * @memberof Metadata\n     * @static\n     * @param {IMetadata} m Metadata message or plain object to encode\n     * @param {$protobuf.Writer} [w] Writer to encode to\n     * @returns {$protobuf.Writer} Writer\n     */\n    Metadata.encode = function encode(m, w) {\n        if (!w)\n            w = $Writer.create();\n        if (m.MimeType != null && Object.hasOwnProperty.call(m, \"MimeType\"))\n            w.uint32(10).string(m.MimeType);\n        return w;\n    };\n\n    /**\n     * Decodes a Metadata message from the specified reader or buffer.\n     * @function decode\n     * @memberof Metadata\n     * @static\n     * @param {$protobuf.Reader|Uint8Array} r Reader or buffer to decode from\n     * @param {number} [l] Message length if known beforehand\n     * @returns {Metadata} Metadata\n     * @throws {Error} If the payload is not a reader or valid buffer\n     * @throws {$protobuf.util.ProtocolError} If required fields are missing\n     */\n    Metadata.decode = function decode(r, l) {\n        if (!(r instanceof $Reader))\n            r = $Reader.create(r);\n        var c = l === undefined ? r.len : r.pos + l, m = new $root.Metadata();\n        while (r.pos < c) {\n            var t = r.uint32();\n            switch (t >>> 3) {\n            case 1:\n                m.MimeType = r.string();\n                break;\n            default:\n                r.skipType(t & 7);\n                break;\n            }\n        }\n        return m;\n    };\n\n    /**\n     * Creates a Metadata message from a plain object. Also converts values to their respective internal types.\n     * @function fromObject\n     * @memberof Metadata\n     * @static\n     * @param {Object.<string,*>} d Plain object\n     * @returns {Metadata} Metadata\n     */\n    Metadata.fromObject = function fromObject(d) {\n        if (d instanceof $root.Metadata)\n            return d;\n        var m = new $root.Metadata();\n        if (d.MimeType != null) {\n            m.MimeType = String(d.MimeType);\n        }\n        return m;\n    };\n\n    /**\n     * Creates a plain object from a Metadata message. Also converts values to other types if specified.\n     * @function toObject\n     * @memberof Metadata\n     * @static\n     * @param {Metadata} m Metadata\n     * @param {$protobuf.IConversionOptions} [o] Conversion options\n     * @returns {Object.<string,*>} Plain object\n     */\n    Metadata.toObject = function toObject(m, o) {\n        if (!o)\n            o = {};\n        var d = {};\n        if (o.defaults) {\n            d.MimeType = \"\";\n        }\n        if (m.MimeType != null && m.hasOwnProperty(\"MimeType\")) {\n            d.MimeType = m.MimeType;\n        }\n        return d;\n    };\n\n    /**\n     * Converts this Metadata to JSON.\n     * @function toJSON\n     * @memberof Metadata\n     * @instance\n     * @returns {Object.<string,*>} JSON object\n     */\n    Metadata.prototype.toJSON = function toJSON() {\n        return this.constructor.toObject(this, $protobuf.util.toJSONOptions);\n    };\n\n    return Metadata;\n})();\n\nmodule.exports = $root;\n","'use strict';\n\nconst {\n    URLWithLegacySupport,\n    format,\n    URLSearchParams,\n    defaultBase\n} = require('./src/url');\nconst relative = require('./src/relative');\n\nmodule.exports = {\n    URL: URLWithLegacySupport,\n    URLSearchParams,\n    format,\n    relative,\n    defaultBase\n};\n","'use strict';\n\nconst { URLWithLegacySupport, format } = require('./url');\n\nmodule.exports = (url, location = {}, protocolMap = {}, defaultProtocol) => {\n    let protocol = location.protocol ?\n        location.protocol.replace(':', '') :\n        'http';\n\n    // Check protocol map\n    protocol = (protocolMap[protocol] || defaultProtocol || protocol) + ':';\n    let urlParsed;\n\n    try {\n        urlParsed = new URLWithLegacySupport(url);\n    } catch (err) {\n        urlParsed = {};\n    }\n\n    const base = Object.assign({}, location, {\n        protocol: protocol || urlParsed.protocol,\n        host: location.host || urlParsed.host\n    });\n\n    return new URLWithLegacySupport(url, format(base)).toString();\n};\n","'use strict';\n\nconst defaultBase = self.location && self.location.protocol + '//' + self.location.host;\nconst URL = self.URL;\n\nclass URLWithLegacySupport {\n    constructor(url = '', base = defaultBase) {\n        this.super = new URL(url, base);\n        this.path = this.pathname + this.search;\n        this.auth =\n            this.username && this.password ?\n                this.username + ':' + this.password :\n                null;\n\n        this.query =\n            this.search && this.search.startsWith('?') ?\n                this.search.slice(1) :\n                null;\n    }\n\n    get hash() {\n        return this.super.hash;\n    }\n    get host() {\n        return this.super.host;\n    }\n    get hostname() {\n        return this.super.hostname;\n    }\n    get href() {\n        return this.super.href;\n    }\n    get origin() {\n        return this.super.origin;\n    }\n    get password() {\n        return this.super.password;\n    }\n    get pathname() {\n        return this.super.pathname;\n    }\n    get port() {\n        return this.super.port;\n    }\n    get protocol() {\n        return this.super.protocol;\n    }\n    get search() {\n        return this.super.search;\n    }\n    get searchParams() {\n        return this.super.searchParams;\n    }\n    get username() {\n        return this.super.username;\n    }\n\n    set hash(hash) {\n        this.super.hash = hash;\n    }\n    set host(host) {\n        this.super.host = host;\n    }\n    set hostname(hostname) {\n        this.super.hostname = hostname;\n    }\n    set href(href) {\n        this.super.href = href;\n    }\n    set origin(origin) {\n        this.super.origin = origin;\n    }\n    set password(password) {\n        this.super.password = password;\n    }\n    set pathname(pathname) {\n        this.super.pathname = pathname;\n    }\n    set port(port) {\n        this.super.port = port;\n    }\n    set protocol(protocol) {\n        this.super.protocol = protocol;\n    }\n    set search(search) {\n        this.super.search = search;\n    }\n    set searchParams(searchParams) {\n        this.super.searchParams = searchParams;\n    }\n    set username(username) {\n        this.super.username = username;\n    }\n\n    createObjectURL(o) {\n        return this.super.createObjectURL(o);\n    }\n    revokeObjectURL(o) {\n        this.super.revokeObjectURL(o);\n    }\n    toJSON() {\n        return this.super.toJSON();\n    }\n    toString() {\n        return this.super.toString();\n    }\n    format() {\n        return this.toString();\n    }\n}\n\nfunction format(obj) {\n    if (typeof obj === 'string') {\n        const url = new URL(obj);\n\n        return url.toString();\n    }\n\n    if (!(obj instanceof URL)) {\n        const userPass =\n            obj.username && obj.password ?\n                `${obj.username}:${obj.password}@` :\n                '';\n        const auth = obj.auth ? obj.auth + '@' : '';\n        const port = obj.port ? ':' + obj.port : '';\n        const protocol = obj.protocol ? obj.protocol + '//' : '';\n        const host = obj.host || '';\n        const hostname = obj.hostname || '';\n        const search = obj.search || (obj.query ? '?' + obj.query : '');\n        const hash = obj.hash || '';\n        const pathname = obj.pathname || '';\n        const path = obj.path || pathname + search;\n\n        return `${protocol}${userPass || auth}${host ||\n            hostname + port}${path}${hash}`;\n    }\n}\n\nmodule.exports = {\n    URLWithLegacySupport,\n    URLSearchParams: self.URLSearchParams,\n    defaultBase,\n    format\n};\n","'use strict'\n\nlet impl\n\nif (globalThis.AbortController && globalThis.AbortSignal) {\n  impl = globalThis\n} else {\n  impl = require('abort-controller')\n}\n\nmodule.exports = {\n  AbortController: impl.AbortController,\n  AbortSignal: impl.AbortSignal\n}\n","'use strict'\nconst isElectron = require('is-electron')\n\nconst IS_ENV_WITH_DOM = typeof window === 'object' && typeof document === 'object' && document.nodeType === 9\nconst IS_ELECTRON = isElectron()\nconst IS_BROWSER = IS_ENV_WITH_DOM && !IS_ELECTRON\nconst IS_ELECTRON_MAIN = IS_ELECTRON && !IS_ENV_WITH_DOM\nconst IS_ELECTRON_RENDERER = IS_ELECTRON && IS_ENV_WITH_DOM\nconst IS_NODE = typeof require === 'function' && typeof process !== 'undefined' && typeof process.release !== 'undefined' && process.release.name === 'node' && !IS_ELECTRON\n// @ts-ignore - we either ignore worker scope or dom scope\nconst IS_WEBWORKER = typeof importScripts === 'function' && typeof self !== 'undefined' && typeof WorkerGlobalScope !== 'undefined' && self instanceof WorkerGlobalScope\nconst IS_TEST = typeof process !== 'undefined' && typeof process.env !== 'undefined' && process.env.NODE_ENV === 'test'\n\nmodule.exports = {\n  isTest: IS_TEST,\n  isElectron: IS_ELECTRON,\n  isElectronMain: IS_ELECTRON_MAIN,\n  isElectronRenderer: IS_ELECTRON_RENDERER,\n  isNode: IS_NODE,\n  /**\n   * Detects browser main thread  **NOT** web worker or service worker\n   */\n  isBrowser: IS_BROWSER,\n  isWebWorker: IS_WEBWORKER,\n  isEnvWithDom: IS_ENV_WITH_DOM\n}\n","'use strict'\n\nconst { isElectronMain } = require('./env')\n\nif (isElectronMain) {\n  module.exports = require('electron-fetch')\n} else {\n// use window.fetch if it is available, fall back to node-fetch if not\n  module.exports = require('native-fetch')\n}\n","'use strict'\n\nconst HTTP = require('../http')\n\n/**\n *\n * @param {string} url\n * @param {import(\"../types\").HTTPOptions} [options]\n * @returns {{ path: string; content?: AsyncIterable<Uint8Array> }}\n */\nconst urlSource = (url, options) => {\n  return {\n    path: decodeURIComponent(new URL(url).pathname.split('/').pop() || ''),\n    content: readURLContent(url, options)\n  }\n}\n\n/**\n *\n * @param {string} url\n * @param {import(\"../types\").HTTPOptions} [options]\n * @returns {AsyncIterable<Uint8Array>}\n */\nasync function * readURLContent (url, options) {\n  const http = new HTTP()\n  const response = await http.get(url, options)\n\n  yield * response.iterator()\n}\n\nmodule.exports = urlSource\n","/* eslint-disable no-undef */\n'use strict'\n\nconst { fetch, Request, Headers } = require('./http/fetch')\nconst { TimeoutError, HTTPError } = require('./http/error')\nconst merge = require('merge-options').bind({ ignoreUndefined: true })\nconst { URL, URLSearchParams } = require('iso-url')\nconst TextDecoder = require('./text-decoder')\nconst { AbortController } = require('native-abort-controller')\nconst anySignal = require('any-signal')\n\n/**\n * @typedef {import('electron-fetch').Response} Response\n * @typedef {import('stream').Readable} NodeReadableStream\n * @typedef {import('stream').Duplex} NodeDuplexStream\n * @typedef {import('./types').HTTPOptions} HTTPOptions\n */\n\n/**\n * @template TResponse\n * @param {Promise<TResponse>} promise\n * @param {number | undefined} ms\n * @param {AbortController} abortController\n * @returns {Promise<TResponse>}\n */\nconst timeout = (promise, ms, abortController) => {\n  if (ms === undefined) {\n    return promise\n  }\n\n  const start = Date.now()\n\n  const timedOut = () => {\n    const time = Date.now() - start\n\n    return time >= ms\n  }\n\n  return new Promise((resolve, reject) => {\n    const timeoutID = setTimeout(() => {\n      if (timedOut()) {\n        reject(new TimeoutError())\n        abortController.abort()\n      }\n    }, ms)\n\n    /**\n     * @param {(value: any) => void } next\n     */\n    const after = (next) => {\n      /**\n       * @param {any} res\n       */\n      const fn = (res) => {\n        clearTimeout(timeoutID)\n\n        if (timedOut()) {\n          reject(new TimeoutError())\n          return\n        }\n\n        next(res)\n      }\n      return fn\n    }\n\n    promise\n      .then(after(resolve), after(reject))\n  })\n}\n\nconst defaults = {\n  throwHttpErrors: true,\n  credentials: 'same-origin'\n}\n\nclass HTTP {\n  /**\n   *\n   * @param {HTTPOptions} options\n   */\n  constructor (options = {}) {\n    /** @type {HTTPOptions} */\n    this.opts = merge(defaults, options)\n  }\n\n  /**\n   * Fetch\n   *\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  async fetch (resource, options = {}) {\n    /** @type {HTTPOptions} */\n    const opts = merge(this.opts, options)\n    const headers = new Headers(opts.headers)\n\n    // validate resource type\n    if (typeof resource !== 'string' && !(resource instanceof URL || resource instanceof Request)) {\n      throw new TypeError('`resource` must be a string, URL, or Request')\n    }\n\n    const url = new URL(resource.toString(), opts.base)\n\n    const {\n      searchParams,\n      transformSearchParams,\n      json\n    } = opts\n\n    if (searchParams) {\n      if (typeof transformSearchParams === 'function') {\n        // @ts-ignore\n        url.search = transformSearchParams(new URLSearchParams(opts.searchParams))\n      } else {\n        // @ts-ignore\n        url.search = new URLSearchParams(opts.searchParams)\n      }\n    }\n\n    if (json) {\n      opts.body = JSON.stringify(opts.json)\n      headers.set('content-type', 'application/json')\n    }\n\n    const abortController = new AbortController()\n    // @ts-ignore\n    const signal = anySignal([abortController.signal, opts.signal])\n\n    const response = await timeout(\n      fetch(\n        url.toString(),\n        {\n          ...opts,\n          signal,\n          timeout: undefined,\n          headers\n        }\n      ),\n      opts.timeout,\n      abortController\n    )\n\n    if (!response.ok && opts.throwHttpErrors) {\n      if (opts.handleError) {\n        await opts.handleError(response)\n      }\n      throw new HTTPError(response)\n    }\n\n    response.iterator = function () {\n      return fromStream(response.body)\n    }\n\n    response.ndjson = async function * () {\n      for await (const chunk of ndjson(response.iterator())) {\n        if (options.transform) {\n          yield options.transform(chunk)\n        } else {\n          yield chunk\n        }\n      }\n    }\n\n    return response\n  }\n\n  /**\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  post (resource, options = {}) {\n    return this.fetch(resource, { ...options, method: 'POST' })\n  }\n\n  /**\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  get (resource, options = {}) {\n    return this.fetch(resource, { ...options, method: 'GET' })\n  }\n\n  /**\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  put (resource, options = {}) {\n    return this.fetch(resource, { ...options, method: 'PUT' })\n  }\n\n  /**\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  delete (resource, options = {}) {\n    return this.fetch(resource, { ...options, method: 'DELETE' })\n  }\n\n  /**\n   * @param {string | Request} resource\n   * @param {HTTPOptions} options\n   * @returns {Promise<Response>}\n   */\n  options (resource, options = {}) {\n    return this.fetch(resource, { ...options, method: 'OPTIONS' })\n  }\n}\n\n/**\n * Parses NDJSON chunks from an iterator\n *\n * @param {AsyncIterable<Uint8Array>} source\n * @returns {AsyncIterable<any>}\n */\nconst ndjson = async function * (source) {\n  const decoder = new TextDecoder()\n  let buf = ''\n\n  for await (const chunk of source) {\n    buf += decoder.decode(chunk, { stream: true })\n    const lines = buf.split(/\\r?\\n/)\n\n    for (let i = 0; i < lines.length - 1; i++) {\n      const l = lines[i].trim()\n      if (l.length > 0) {\n        yield JSON.parse(l)\n      }\n    }\n    buf = lines[lines.length - 1]\n  }\n  buf += decoder.decode()\n  buf = buf.trim()\n  if (buf.length !== 0) {\n    yield JSON.parse(buf)\n  }\n}\n\n/**\n * Stream to AsyncIterable\n *\n * @template TChunk\n * @param {ReadableStream<TChunk> | NodeReadableStream | null} source\n * @returns {AsyncIterable<TChunk>}\n */\nconst fromStream = (source) => {\n  // Workaround for https://github.com/node-fetch/node-fetch/issues/766\n  if (isNodeReadableStream(source)) {\n    const iter = source[Symbol.asyncIterator]()\n    return {\n      [Symbol.asyncIterator] () {\n        return {\n          next: iter.next.bind(iter),\n          return (value) {\n            source.destroy()\n            if (typeof iter.return === 'function') {\n              return iter.return()\n            }\n            return Promise.resolve({ done: true, value })\n          }\n        }\n      }\n    }\n  }\n\n  if (isWebReadableStream(source)) {\n    const reader = source.getReader()\n    return (async function * () {\n      try {\n        while (true) {\n          // Read from the stream\n          const { done, value } = await reader.read()\n          // Exit if we're done\n          if (done) return\n          // Else yield the chunk\n          if (value) {\n            yield value\n          }\n        }\n      } finally {\n        reader.releaseLock()\n      }\n    })()\n  }\n\n  if (isAsyncIterable(source)) {\n    return source\n  }\n\n  throw new TypeError('Body can\\'t be converted to AsyncIterable')\n}\n\n/**\n * Check if it's an AsyncIterable\n *\n * @template {unknown} TChunk\n * @template {any} Other\n * @param {Other|AsyncIterable<TChunk>} value\n * @returns {value is AsyncIterable<TChunk>}\n */\nconst isAsyncIterable = (value) => {\n  return typeof value === 'object' &&\n  value !== null &&\n  typeof /** @type {any} */(value)[Symbol.asyncIterator] === 'function'\n}\n\n/**\n * Check for web readable stream\n *\n * @template {unknown} TChunk\n * @template {any} Other\n * @param {Other|ReadableStream<TChunk>} value\n * @returns {value is ReadableStream<TChunk>}\n */\nconst isWebReadableStream = (value) => {\n  return value && typeof /** @type {any} */(value).getReader === 'function'\n}\n\n/**\n * @param {any} value\n * @returns {value is NodeReadableStream}\n */\nconst isNodeReadableStream = (value) =>\n  Object.prototype.hasOwnProperty.call(value, 'readable') &&\n  Object.prototype.hasOwnProperty.call(value, 'writable')\n\nHTTP.HTTPError = HTTPError\nHTTP.TimeoutError = TimeoutError\nHTTP.streamToAsyncIterator = fromStream\n\n/**\n * @param {string | Request} resource\n * @param {HTTPOptions} [options]\n * @returns {Promise<Response>}\n */\nHTTP.post = (resource, options) => new HTTP(options).post(resource, options)\n\n/**\n * @param {string | Request} resource\n * @param {HTTPOptions} [options]\n * @returns {Promise<Response>}\n */\nHTTP.get = (resource, options) => new HTTP(options).get(resource, options)\n\n/**\n * @param {string | Request} resource\n * @param {HTTPOptions} [options]\n * @returns {Promise<Response>}\n */\nHTTP.put = (resource, options) => new HTTP(options).put(resource, options)\n\n/**\n * @param {string | Request} resource\n * @param {HTTPOptions} [options]\n * @returns {Promise<Response>}\n */\nHTTP.delete = (resource, options) => new HTTP(options).delete(resource, options)\n\n/**\n * @param {string | Request} resource\n * @param {HTTPOptions} [options]\n * @returns {Promise<Response>}\n */\nHTTP.options = (resource, options) => new HTTP(options).options(resource, options)\n\nmodule.exports = HTTP\n","'use strict'\n\nclass TimeoutError extends Error {\n  constructor (message = 'Request timed out') {\n    super(message)\n    this.name = 'TimeoutError'\n  }\n}\nexports.TimeoutError = TimeoutError\n\nclass AbortError extends Error {\n  constructor (message = 'The operation was aborted.') {\n    super(message)\n    this.name = 'AbortError'\n  }\n}\nexports.AbortError = AbortError\n\nclass HTTPError extends Error {\n  /**\n   * @param {import('electron-fetch').Response} response\n   */\n  constructor (response) {\n    super(response.statusText)\n    this.name = 'HTTPError'\n    this.response = response\n  }\n}\nexports.HTTPError = HTTPError\n","'use strict'\n\nconst { TimeoutError, AbortError } = require('./error')\nconst { Response, Request, Headers, default: fetch } = require('../fetch')\n\n/**\n * @typedef {import('../types').FetchOptions} FetchOptions\n * @typedef {import('../types').ProgressFn} ProgressFn\n */\n\n/**\n * Fetch with progress\n *\n * @param {string | Request} url\n * @param {FetchOptions} [options]\n * @returns {Promise<ResponseWithURL>}\n */\nconst fetchWithProgress = (url, options = {}) => {\n  const request = new XMLHttpRequest()\n  request.open(options.method || 'GET', url.toString(), true)\n\n  const { timeout, headers } = options\n\n  if (timeout && timeout > 0 && timeout < Infinity) {\n    request.timeout = timeout\n  }\n\n  if (options.overrideMimeType != null) {\n    request.overrideMimeType(options.overrideMimeType)\n  }\n\n  if (headers) {\n    for (const [name, value] of new Headers(headers)) {\n      request.setRequestHeader(name, value)\n    }\n  }\n\n  if (options.signal) {\n    options.signal.onabort = () => request.abort()\n  }\n\n  if (options.onUploadProgress) {\n    request.upload.onprogress = options.onUploadProgress\n  }\n\n  // Note: Need to use `arraybuffer` here instead of `blob` because `Blob`\n  // instances coming from JSDOM are not compatible with `Response` from\n  // node-fetch (which is the setup we get when testing with jest because\n  // it uses JSDOM which does not provide a global fetch\n  // https://github.com/jsdom/jsdom/issues/1724)\n  request.responseType = 'arraybuffer'\n\n  return new Promise((resolve, reject) => {\n    /**\n     * @param {Event} event\n     */\n    const handleEvent = (event) => {\n      switch (event.type) {\n        case 'error': {\n          resolve(Response.error())\n          break\n        }\n        case 'load': {\n          resolve(\n            new ResponseWithURL(request.responseURL, request.response, {\n              status: request.status,\n              statusText: request.statusText,\n              headers: parseHeaders(request.getAllResponseHeaders())\n            })\n          )\n          break\n        }\n        case 'timeout': {\n          reject(new TimeoutError())\n          break\n        }\n        case 'abort': {\n          reject(new AbortError())\n          break\n        }\n        default: {\n          break\n        }\n      }\n    }\n    request.onerror = handleEvent\n    request.onload = handleEvent\n    request.ontimeout = handleEvent\n    request.onabort = handleEvent\n\n    request.send(/** @type {BodyInit} */(options.body))\n  })\n}\n\nconst fetchWithStreaming = fetch\n\n/**\n * @param {string | Request} url\n * @param {FetchOptions} options\n */\nconst fetchWith = (url, options = {}) =>\n  (options.onUploadProgress != null)\n    ? fetchWithProgress(url, options)\n    : fetchWithStreaming(url, options)\n\n/**\n * Parse Headers from a XMLHttpRequest\n *\n * @param {string} input\n * @returns {Headers}\n */\nconst parseHeaders = (input) => {\n  const headers = new Headers()\n  for (const line of input.trim().split(/[\\r\\n]+/)) {\n    const index = line.indexOf(': ')\n    if (index > 0) {\n      headers.set(line.slice(0, index), line.slice(index + 1))\n    }\n  }\n\n  return headers\n}\n\nclass ResponseWithURL extends Response {\n  /**\n   * @param {string} url\n   * @param {BodyInit} body\n   * @param {ResponseInit} options\n   */\n  constructor (url, body, options) {\n    super(body, options)\n    Object.defineProperty(this, 'url', { value: url })\n  }\n}\n\nmodule.exports = {\n  fetch: fetchWith,\n  Request,\n  Headers,\n  ResponseWithURL\n}\n","'use strict'\n\nmodule.exports = require('web-encoding').TextDecoder\n","'use strict'\n\nconst CID = require('cids')\n\nconst { version } = require('../package.json')\nconst blockSymbol = Symbol.for('@ipld/js-ipld-block/block')\nconst readonly = { writable: false, configurable: false, enumerable: true }\n\n/**\n * Represents an immutable block of data that is uniquely referenced with a cid.\n *\n * @example\n * const block = new Block(Uint8Array.from([0, 1, 2, 3]), new CID('...'))\n */\nclass Block {\n  /**\n   * @param {Uint8Array} data - The data to be stored in the block as a Uint8Array.\n   * @param {CID} cid - The cid of the data\n   */\n  constructor (data, cid) {\n    if (!data || !(data instanceof Uint8Array)) {\n      throw new Error('first argument  must be a Uint8Array')\n    }\n\n    if (!cid || !CID.isCID(cid)) {\n      throw new Error('second argument must be a CID')\n    }\n\n    this.data = data\n    this.cid = cid\n\n    Object.defineProperties(this, {\n      data: readonly,\n      cid: readonly\n    })\n  }\n\n  /**\n   * The data of this block.\n   *\n   * @deprecated\n   * @type {Uint8Array}\n   */\n  get _data () {\n    deprecateData()\n    return this.data\n  }\n\n  /**\n   * The cid of the data this block represents.\n   *\n   * @deprecated\n   * @type {CID}\n   */\n  get _cid () {\n    deprecateCID()\n    return this.cid\n  }\n\n  get [Symbol.toStringTag] () {\n    return 'Block'\n  }\n\n  get [blockSymbol] () {\n    return true\n  }\n\n  /**\n   * Check if the given value is a Block.\n   *\n   * @param {any} other\n   * @returns {other is Block}\n   */\n  static isBlock (other) {\n    return Boolean(other && other[blockSymbol])\n  }\n}\n\n/**\n * @param {RegExp} range\n * @param {string} message\n * @returns {() => void}\n */\nconst deprecate = (range, message) => {\n  let warned = false\n  return () => {\n    if (range.test(version)) {\n      if (!warned) {\n        warned = true\n        // eslint-disable-next-line no-console\n        console.warn(message)\n      }\n    } else {\n      throw new Error(message)\n    }\n  }\n}\n\nconst deprecateCID = deprecate(/^0\\.10|^0\\.11/, 'block._cid is deprecated and will be removed in 0.12 release. Please use block.cid instead')\nconst deprecateData = deprecate(/^0\\.10|^0.11/, 'block._data is deprecated and will be removed in 0.12 release. Please use block.data instead')\n\nmodule.exports = Block\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","/**\n * Implementation of the [multibase](https://github.com/multiformats/multibase) specification.\n *\n */\n'use strict'\n\nconst constants = require('./constants')\nconst { encodeText, decodeText, concat } = require('./util')\n\n/** @typedef {import('./base')} Base */\n/** @typedef {import(\"./types\").BaseNameOrCode} BaseNameOrCode */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n\n/**\n * Create a new Uint8Array with the multibase varint+code.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be prefixed with multibase.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction multibase (nameOrCode, buf) {\n  if (!buf) {\n    throw new Error('requires an encoded Uint8Array')\n  }\n  const { name, codeBuf } = encoding(nameOrCode)\n  validEncode(name, buf)\n\n  return concat([codeBuf, buf], codeBuf.length + buf.length)\n}\n\n/**\n * Encode data with the specified base and add the multibase prefix.\n *\n * @param {BaseNameOrCode} nameOrCode - The multibase name or code number.\n * @param {Uint8Array} buf - The data to be encoded.\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction encode (nameOrCode, buf) {\n  const enc = encoding(nameOrCode)\n  const data = encodeText(enc.encode(buf))\n\n  return concat([enc.codeBuf, data], enc.codeBuf.length + data.length)\n}\n\n/**\n * Takes a Uint8Array or string encoded with multibase header, decodes it and\n * returns the decoded buffer\n *\n * @param {Uint8Array|string} data\n * @returns {Uint8Array}\n * @throws {Error} Will throw if the encoding is not supported\n *\n */\nfunction decode (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n  const prefix = data[0]\n\n  // Make all encodings case-insensitive except the ones that include upper and lower chars in the alphabet\n  if (['f', 'F', 'v', 'V', 't', 'T', 'b', 'B', 'c', 'C', 'h', 'k', 'K'].includes(prefix)) {\n    data = data.toLowerCase()\n  }\n  const enc = encoding(/** @type {BaseCode} */(data[0]))\n  return enc.decode(data.substring(1))\n}\n\n/**\n * Is the given data multibase encoded?\n *\n * @param {Uint8Array|string} data\n * @returns {false | string}\n */\nfunction isEncoded (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  // Ensure bufOrString is a string\n  if (Object.prototype.toString.call(data) !== '[object String]') {\n    return false\n  }\n\n  try {\n    const enc = encoding(/** @type {BaseCode} */(data[0]))\n    return enc.name\n  } catch (err) {\n    return false\n  }\n}\n\n/**\n * Validate encoded data\n *\n * @param {BaseNameOrCode} name\n * @param {Uint8Array} buf\n * @returns {void}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction validEncode (name, buf) {\n  const enc = encoding(name)\n  enc.decode(decodeText(buf))\n}\n\n/**\n * Get the encoding by name or code\n *\n * @param {BaseNameOrCode} nameOrCode\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encoding (nameOrCode) {\n  if (Object.prototype.hasOwnProperty.call(constants.names, /** @type {BaseName} */(nameOrCode))) {\n    return constants.names[/** @type {BaseName} */(nameOrCode)]\n  } else if (Object.prototype.hasOwnProperty.call(constants.codes, /** @type {BaseCode} */(nameOrCode))) {\n    return constants.codes[/** @type {BaseCode} */(nameOrCode)]\n  } else {\n    throw new Error(`Unsupported encoding: ${nameOrCode}`)\n  }\n}\n\n/**\n * Get encoding from data\n *\n * @param {string|Uint8Array} data\n * @returns {Base}\n * @throws {Error} Will throw if the encoding is not supported\n */\nfunction encodingFromData (data) {\n  if (data instanceof Uint8Array) {\n    data = decodeText(data)\n  }\n\n  return encoding(/** @type {BaseCode} */(data[0]))\n}\n\nexports = module.exports = multibase\nexports.encode = encode\nexports.decode = decode\nexports.isEncoded = isEncoded\nexports.encoding = encoding\nexports.encodingFromData = encodingFromData\nconst names = Object.freeze(constants.names)\nconst codes = Object.freeze(constants.codes)\nexports.names = names\nexports.codes = codes\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","'use strict'\n\n// @ts-ignore\nconst { TextEncoder, TextDecoder } = require('web-encoding')\n\nconst textDecoder = new TextDecoder()\n/**\n * @param {ArrayBufferView|ArrayBuffer} bytes\n * @returns {string}\n */\nconst decodeText = (bytes) => textDecoder.decode(bytes)\n\nconst textEncoder = new TextEncoder()\n/**\n * @param {string} text\n * @returns {Uint8Array}\n */\nconst encodeText = (text) => textEncoder.encode(text)\n\n/**\n * Returns a new Uint8Array created by concatenating the passed Arrays\n *\n * @param {Array<ArrayLike<number>>} arrs\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrs, length) {\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrs) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = { decodeText, encodeText, concat }\n","// DO NOT CHANGE THIS FILE. IT IS GENERATED BY tools/update-table.js\n/* eslint quote-props: off */\n'use strict'\n\n/**\n * @type {import('./generated-types').NameCodeMap}\n */\nconst baseTable = Object.freeze({\n  'identity': 0x00,\n  'cidv1': 0x01,\n  'cidv2': 0x02,\n  'cidv3': 0x03,\n  'ip4': 0x04,\n  'tcp': 0x06,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'dccp': 0x21,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'ip6': 0x29,\n  'ip6zone': 0x2a,\n  'path': 0x2f,\n  'multicodec': 0x30,\n  'multihash': 0x31,\n  'multiaddr': 0x32,\n  'multibase': 0x33,\n  'dns': 0x35,\n  'dns4': 0x36,\n  'dns6': 0x37,\n  'dnsaddr': 0x38,\n  'protobuf': 0x50,\n  'cbor': 0x51,\n  'raw': 0x55,\n  'dbl-sha2-256': 0x56,\n  'rlp': 0x60,\n  'bencode': 0x63,\n  'dag-pb': 0x70,\n  'dag-cbor': 0x71,\n  'libp2p-key': 0x72,\n  'git-raw': 0x78,\n  'torrent-info': 0x7b,\n  'torrent-file': 0x7c,\n  'leofcoin-block': 0x81,\n  'leofcoin-tx': 0x82,\n  'leofcoin-pr': 0x83,\n  'sctp': 0x84,\n  'dag-jose': 0x85,\n  'dag-cose': 0x86,\n  'eth-block': 0x90,\n  'eth-block-list': 0x91,\n  'eth-tx-trie': 0x92,\n  'eth-tx': 0x93,\n  'eth-tx-receipt-trie': 0x94,\n  'eth-tx-receipt': 0x95,\n  'eth-state-trie': 0x96,\n  'eth-account-snapshot': 0x97,\n  'eth-storage-trie': 0x98,\n  'bitcoin-block': 0xb0,\n  'bitcoin-tx': 0xb1,\n  'bitcoin-witness-commitment': 0xb2,\n  'zcash-block': 0xc0,\n  'zcash-tx': 0xc1,\n  'docid': 0xce,\n  'stellar-block': 0xd0,\n  'stellar-tx': 0xd1,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'decred-block': 0xe0,\n  'decred-tx': 0xe1,\n  'ipld-ns': 0xe2,\n  'ipfs-ns': 0xe3,\n  'swarm-ns': 0xe4,\n  'ipns-ns': 0xe5,\n  'zeronet': 0xe6,\n  'secp256k1-pub': 0xe7,\n  'bls12_381-g1-pub': 0xea,\n  'bls12_381-g2-pub': 0xeb,\n  'x25519-pub': 0xec,\n  'ed25519-pub': 0xed,\n  'bls12_381-g1g2-pub': 0xee,\n  'dash-block': 0xf0,\n  'dash-tx': 0xf1,\n  'swarm-manifest': 0xfa,\n  'swarm-feed': 0xfb,\n  'udp': 0x0111,\n  'p2p-webrtc-star': 0x0113,\n  'p2p-webrtc-direct': 0x0114,\n  'p2p-stardust': 0x0115,\n  'p2p-circuit': 0x0122,\n  'dag-json': 0x0129,\n  'udt': 0x012d,\n  'utp': 0x012e,\n  'unix': 0x0190,\n  'thread': 0x0196,\n  'p2p': 0x01a5,\n  'ipfs': 0x01a5,\n  'https': 0x01bb,\n  'onion': 0x01bc,\n  'onion3': 0x01bd,\n  'garlic64': 0x01be,\n  'garlic32': 0x01bf,\n  'tls': 0x01c0,\n  'quic': 0x01cc,\n  'ws': 0x01dd,\n  'wss': 0x01de,\n  'p2p-websocket-star': 0x01df,\n  'http': 0x01e0,\n  'json': 0x0200,\n  'messagepack': 0x0201,\n  'libp2p-peer-record': 0x0301,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'p256-pub': 0x1200,\n  'p384-pub': 0x1201,\n  'p521-pub': 0x1202,\n  'ed448-pub': 0x1203,\n  'x448-pub': 0x1204,\n  'ed25519-priv': 0x1300,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402,\n  'zeroxcert-imprint-256': 0xce11,\n  'fil-commitment-unsealed': 0xf101,\n  'fil-commitment-sealed': 0xf102,\n  'holochain-adr-v0': 0x807124,\n  'holochain-adr-v1': 0x817124,\n  'holochain-key-v0': 0x947124,\n  'holochain-key-v1': 0x957124,\n  'holochain-sig-v0': 0xa27124,\n  'holochain-sig-v1': 0xa37124,\n  'skynet-ns': 0xb19910\n})\n\nmodule.exports = { baseTable }\n","/**\n * Implementation of the multicodec specification.\n *\n * @module multicodec\n * @example\n * const multicodec = require('multicodec')\n *\n * const prefixedProtobuf = multicodec.addPrefix('protobuf', protobufBuffer)\n * // prefixedProtobuf 0x50...\n *\n */\n'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecCode} CodecCode */\n\nconst varint = require('varint')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst util = require('./util')\nconst { nameToVarint, constantToCode, nameToCode, codeToName } = require('./maps')\n\n/**\n * Prefix a buffer with a multicodec-packed.\n *\n * @param {CodecName|Uint8Array} multicodecStrOrCode\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction addPrefix (multicodecStrOrCode, data) {\n  let prefix\n\n  if (multicodecStrOrCode instanceof Uint8Array) {\n    prefix = util.varintUint8ArrayEncode(multicodecStrOrCode)\n  } else {\n    if (nameToVarint[multicodecStrOrCode]) {\n      prefix = nameToVarint[multicodecStrOrCode]\n    } else {\n      throw new Error('multicodec not recognized')\n    }\n  }\n\n  return uint8ArrayConcat([prefix, data], prefix.length + data.length)\n}\n\n/**\n * Decapsulate the multicodec-packed prefix from the data.\n *\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction rmPrefix (data) {\n  varint.decode(/** @type {Buffer} */(data))\n  return data.slice(varint.decode.bytes)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getNameFromData (prefixedData) {\n  const code = /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n  const name = codeToName[code]\n  if (name === undefined) {\n    throw new Error(`Code \"${code}\" not found`)\n  }\n  return name\n}\n\n/**\n * Get the codec name from a code.\n *\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getNameFromCode (codec) {\n  return codeToName[codec]\n}\n\n/**\n * Get the code of the codec\n *\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getCodeFromName (name) {\n  const code = nameToCode[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCodeFromData (prefixedData) {\n  return /** @type {CodecCode} */(varint.decode(/** @type {Buffer} */(prefixedData)))\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getVarintFromName (name) {\n  const code = nameToVarint[name]\n  if (code === undefined) {\n    throw new Error(`Codec \"${name}\" not found`)\n  }\n  return code\n}\n\n/**\n * Get the varint of a code.\n *\n * @param {CodecCode} code\n * @returns {Uint8Array}\n */\nfunction getVarintFromCode (code) {\n  return util.varintEncode(code)\n}\n\n/**\n * Get the codec name of the prefixed data.\n *\n * @deprecated use getNameFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getCodec (prefixedData) {\n  return getNameFromData(prefixedData)\n}\n\n/**\n * Get the codec name from a code.\n *\n * @deprecated use getNameFromCode instead.\n * @param {CodecCode} codec\n * @returns {CodecName}\n */\nfunction getName (codec) {\n  return getNameFromCode(codec)\n}\n\n/**\n * Get the code of the codec\n *\n * @deprecated use getCodeFromName instead.\n * @param {CodecName} name\n * @returns {CodecCode}\n */\nfunction getNumber (name) {\n  return getCodeFromName(name)\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @deprecated use getCodeFromData instead.\n * @param {Uint8Array} prefixedData\n * @returns {CodecCode}\n */\nfunction getCode (prefixedData) {\n  return getCodeFromData(prefixedData)\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @deprecated use getVarintFromName instead.\n * @param {CodecName} name\n * @returns {Uint8Array}\n */\nfunction getCodeVarint (name) {\n  return getVarintFromName(name)\n}\n\n/**\n * Get the varint of a code.\n *\n * @deprecated use getVarintFromCode instead.\n * @param {CodecCode} code\n * @returns {Array.<number>}\n */\nfunction getVarint (code) {\n  return Array.from(getVarintFromCode(code))\n}\n\nmodule.exports = {\n  addPrefix,\n  rmPrefix,\n  getNameFromData,\n  getNameFromCode,\n  getCodeFromName,\n  getCodeFromData,\n  getVarintFromName,\n  getVarintFromCode,\n  // Deprecated\n  getCodec,\n  getName,\n  getNumber,\n  getCode,\n  getCodeVarint,\n  getVarint,\n  // Make the constants top-level constants\n  ...constantToCode,\n  // Export the maps\n  nameToVarint,\n  nameToCode,\n  codeToName\n}\n","'use strict'\n\n/** @typedef {import('./generated-types').ConstantCodeMap} ConstantCodeMap */\n/** @typedef {import('./generated-types').NameUint8ArrayMap} NameUint8ArrayMap */\n/** @typedef {import('./generated-types').CodeNameMap} CodeNameMap */\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecConstant} CodecConstant */\n\nconst { baseTable } = require('./generated-table')\nconst varintEncode = require('./util').varintEncode\n\nconst nameToVarint = /** @type {NameUint8ArrayMap} */ ({})\nconst constantToCode = /** @type {ConstantCodeMap} */({})\nconst codeToName = /** @type {CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const name in baseTable) {\n  const codecName = /** @type {CodecName} */(name)\n  const code = baseTable[codecName]\n  nameToVarint[codecName] = varintEncode(code)\n\n  const constant = /** @type {CodecConstant} */(codecName.toUpperCase().replace(/-/g, '_'))\n  constantToCode[constant] = code\n\n  if (!codeToName[code]) {\n    codeToName[code] = codecName\n  }\n}\n\nObject.freeze(nameToVarint)\nObject.freeze(constantToCode)\nObject.freeze(codeToName)\nconst nameToCode = Object.freeze(baseTable)\nmodule.exports = {\n  nameToVarint,\n  constantToCode,\n  nameToCode,\n  codeToName\n}\n","'use strict'\n\nconst varint = require('varint')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\nmodule.exports = {\n  numberToUint8Array,\n  uint8ArrayToNumber,\n  varintUint8ArrayEncode,\n  varintEncode\n}\n\n/**\n * @param {Uint8Array} buf\n */\nfunction uint8ArrayToNumber (buf) {\n  return parseInt(uint8ArrayToString(buf, 'base16'), 16)\n}\n\n/**\n * @param {number} num\n */\nfunction numberToUint8Array (num) {\n  let hexString = num.toString(16)\n  if (hexString.length % 2 === 1) {\n    hexString = '0' + hexString\n  }\n  return uint8ArrayFromString(hexString, 'base16')\n}\n\n/**\n * @param {Uint8Array} input\n */\nfunction varintUint8ArrayEncode (input) {\n  return Uint8Array.from(varint.encode(uint8ArrayToNumber(input)))\n}\n\n/**\n * @param {number} num\n */\nfunction varintEncode (num) {\n  return Uint8Array.from(varint.encode(num))\n}\n","/* eslint quote-props: off */\n'use strict'\n\n/**\n * Names for all available hashes\n *\n * @typedef { \"identity\" | \"sha1\" | \"sha2-256\" | \"sha2-512\" | \"sha3-512\" | \"sha3-384\" | \"sha3-256\" | \"sha3-224\" | \"shake-128\" | \"shake-256\" | \"keccak-224\" | \"keccak-256\" | \"keccak-384\" | \"keccak-512\" | \"blake3\" | \"murmur3-128\" | \"murmur3-32\" | \"dbl-sha2-256\" | \"md4\" | \"md5\" | \"bmt\" | \"sha2-256-trunc254-padded\" | \"ripemd-128\" | \"ripemd-160\" | \"ripemd-256\" | \"ripemd-320\" | \"x11\" | \"kangarootwelve\" | \"sm3-256\" | \"blake2b-8\" | \"blake2b-16\" | \"blake2b-24\" | \"blake2b-32\" | \"blake2b-40\" | \"blake2b-48\" | \"blake2b-56\" | \"blake2b-64\" | \"blake2b-72\" | \"blake2b-80\" | \"blake2b-88\" | \"blake2b-96\" | \"blake2b-104\" | \"blake2b-112\" | \"blake2b-120\" | \"blake2b-128\" | \"blake2b-136\" | \"blake2b-144\" | \"blake2b-152\" | \"blake2b-160\" | \"blake2b-168\" | \"blake2b-176\" | \"blake2b-184\" | \"blake2b-192\" | \"blake2b-200\" | \"blake2b-208\" | \"blake2b-216\" | \"blake2b-224\" | \"blake2b-232\" | \"blake2b-240\" | \"blake2b-248\" | \"blake2b-256\" | \"blake2b-264\" | \"blake2b-272\" | \"blake2b-280\" | \"blake2b-288\" | \"blake2b-296\" | \"blake2b-304\" | \"blake2b-312\" | \"blake2b-320\" | \"blake2b-328\" | \"blake2b-336\" | \"blake2b-344\" | \"blake2b-352\" | \"blake2b-360\" | \"blake2b-368\" | \"blake2b-376\" | \"blake2b-384\" | \"blake2b-392\" | \"blake2b-400\" | \"blake2b-408\" | \"blake2b-416\" | \"blake2b-424\" | \"blake2b-432\" | \"blake2b-440\" | \"blake2b-448\" | \"blake2b-456\" | \"blake2b-464\" | \"blake2b-472\" | \"blake2b-480\" | \"blake2b-488\" | \"blake2b-496\" | \"blake2b-504\" | \"blake2b-512\" | \"blake2s-8\" | \"blake2s-16\" | \"blake2s-24\" | \"blake2s-32\" | \"blake2s-40\" | \"blake2s-48\" | \"blake2s-56\" | \"blake2s-64\" | \"blake2s-72\" | \"blake2s-80\" | \"blake2s-88\" | \"blake2s-96\" | \"blake2s-104\" | \"blake2s-112\" | \"blake2s-120\" | \"blake2s-128\" | \"blake2s-136\" | \"blake2s-144\" | \"blake2s-152\" | \"blake2s-160\" | \"blake2s-168\" | \"blake2s-176\" | \"blake2s-184\" | \"blake2s-192\" | \"blake2s-200\" | \"blake2s-208\" | \"blake2s-216\" | \"blake2s-224\" | \"blake2s-232\" | \"blake2s-240\" | \"blake2s-248\" | \"blake2s-256\" | \"skein256-8\" | \"skein256-16\" | \"skein256-24\" | \"skein256-32\" | \"skein256-40\" | \"skein256-48\" | \"skein256-56\" | \"skein256-64\" | \"skein256-72\" | \"skein256-80\" | \"skein256-88\" | \"skein256-96\" | \"skein256-104\" | \"skein256-112\" | \"skein256-120\" | \"skein256-128\" | \"skein256-136\" | \"skein256-144\" | \"skein256-152\" | \"skein256-160\" | \"skein256-168\" | \"skein256-176\" | \"skein256-184\" | \"skein256-192\" | \"skein256-200\" | \"skein256-208\" | \"skein256-216\" | \"skein256-224\" | \"skein256-232\" | \"skein256-240\" | \"skein256-248\" | \"skein256-256\" | \"skein512-8\" | \"skein512-16\" | \"skein512-24\" | \"skein512-32\" | \"skein512-40\" | \"skein512-48\" | \"skein512-56\" | \"skein512-64\" | \"skein512-72\" | \"skein512-80\" | \"skein512-88\" | \"skein512-96\" | \"skein512-104\" | \"skein512-112\" | \"skein512-120\" | \"skein512-128\" | \"skein512-136\" | \"skein512-144\" | \"skein512-152\" | \"skein512-160\" | \"skein512-168\" | \"skein512-176\" | \"skein512-184\" | \"skein512-192\" | \"skein512-200\" | \"skein512-208\" | \"skein512-216\" | \"skein512-224\" | \"skein512-232\" | \"skein512-240\" | \"skein512-248\" | \"skein512-256\" | \"skein512-264\" | \"skein512-272\" | \"skein512-280\" | \"skein512-288\" | \"skein512-296\" | \"skein512-304\" | \"skein512-312\" | \"skein512-320\" | \"skein512-328\" | \"skein512-336\" | \"skein512-344\" | \"skein512-352\" | \"skein512-360\" | \"skein512-368\" | \"skein512-376\" | \"skein512-384\" | \"skein512-392\" | \"skein512-400\" | \"skein512-408\" | \"skein512-416\" | \"skein512-424\" | \"skein512-432\" | \"skein512-440\" | \"skein512-448\" | \"skein512-456\" | \"skein512-464\" | \"skein512-472\" | \"skein512-480\" | \"skein512-488\" | \"skein512-496\" | \"skein512-504\" | \"skein512-512\" | \"skein1024-8\" | \"skein1024-16\" | \"skein1024-24\" | \"skein1024-32\" | \"skein1024-40\" | \"skein1024-48\" | \"skein1024-56\" | \"skein1024-64\" | \"skein1024-72\" | \"skein1024-80\" | \"skein1024-88\" | \"skein1024-96\" | \"skein1024-104\" | \"skein1024-112\" | \"skein1024-120\" | \"skein1024-128\" | \"skein1024-136\" | \"skein1024-144\" | \"skein1024-152\" | \"skein1024-160\" | \"skein1024-168\" | \"skein1024-176\" | \"skein1024-184\" | \"skein1024-192\" | \"skein1024-200\" | \"skein1024-208\" | \"skein1024-216\" | \"skein1024-224\" | \"skein1024-232\" | \"skein1024-240\" | \"skein1024-248\" | \"skein1024-256\" | \"skein1024-264\" | \"skein1024-272\" | \"skein1024-280\" | \"skein1024-288\" | \"skein1024-296\" | \"skein1024-304\" | \"skein1024-312\" | \"skein1024-320\" | \"skein1024-328\" | \"skein1024-336\" | \"skein1024-344\" | \"skein1024-352\" | \"skein1024-360\" | \"skein1024-368\" | \"skein1024-376\" | \"skein1024-384\" | \"skein1024-392\" | \"skein1024-400\" | \"skein1024-408\" | \"skein1024-416\" | \"skein1024-424\" | \"skein1024-432\" | \"skein1024-440\" | \"skein1024-448\" | \"skein1024-456\" | \"skein1024-464\" | \"skein1024-472\" | \"skein1024-480\" | \"skein1024-488\" | \"skein1024-496\" | \"skein1024-504\" | \"skein1024-512\" | \"skein1024-520\" | \"skein1024-528\" | \"skein1024-536\" | \"skein1024-544\" | \"skein1024-552\" | \"skein1024-560\" | \"skein1024-568\" | \"skein1024-576\" | \"skein1024-584\" | \"skein1024-592\" | \"skein1024-600\" | \"skein1024-608\" | \"skein1024-616\" | \"skein1024-624\" | \"skein1024-632\" | \"skein1024-640\" | \"skein1024-648\" | \"skein1024-656\" | \"skein1024-664\" | \"skein1024-672\" | \"skein1024-680\" | \"skein1024-688\" | \"skein1024-696\" | \"skein1024-704\" | \"skein1024-712\" | \"skein1024-720\" | \"skein1024-728\" | \"skein1024-736\" | \"skein1024-744\" | \"skein1024-752\" | \"skein1024-760\" | \"skein1024-768\" | \"skein1024-776\" | \"skein1024-784\" | \"skein1024-792\" | \"skein1024-800\" | \"skein1024-808\" | \"skein1024-816\" | \"skein1024-824\" | \"skein1024-832\" | \"skein1024-840\" | \"skein1024-848\" | \"skein1024-856\" | \"skein1024-864\" | \"skein1024-872\" | \"skein1024-880\" | \"skein1024-888\" | \"skein1024-896\" | \"skein1024-904\" | \"skein1024-912\" | \"skein1024-920\" | \"skein1024-928\" | \"skein1024-936\" | \"skein1024-944\" | \"skein1024-952\" | \"skein1024-960\" | \"skein1024-968\" | \"skein1024-976\" | \"skein1024-984\" | \"skein1024-992\" | \"skein1024-1000\" | \"skein1024-1008\" | \"skein1024-1016\" | \"skein1024-1024\" | \"poseidon-bls12_381-a2-fc1\" | \"poseidon-bls12_381-a2-fc1-sc\" } HashName\n */\n/**\n * Codes for all available hashes\n *\n * @typedef { 0x00 | 0x11 | 0x12 | 0x13 | 0x14 | 0x15 | 0x16 | 0x17 | 0x18 | 0x19 | 0x1a | 0x1b | 0x1c | 0x1d | 0x1e | 0x22 | 0x23 | 0x56 | 0xd4 | 0xd5 | 0xd6 | 0x1012 | 0x1052 | 0x1053 | 0x1054 | 0x1055 | 0x1100 | 0x1d01 | 0x534d | 0xb201 | 0xb202 | 0xb203 | 0xb204 | 0xb205 | 0xb206 | 0xb207 | 0xb208 | 0xb209 | 0xb20a | 0xb20b | 0xb20c | 0xb20d | 0xb20e | 0xb20f | 0xb210 | 0xb211 | 0xb212 | 0xb213 | 0xb214 | 0xb215 | 0xb216 | 0xb217 | 0xb218 | 0xb219 | 0xb21a | 0xb21b | 0xb21c | 0xb21d | 0xb21e | 0xb21f | 0xb220 | 0xb221 | 0xb222 | 0xb223 | 0xb224 | 0xb225 | 0xb226 | 0xb227 | 0xb228 | 0xb229 | 0xb22a | 0xb22b | 0xb22c | 0xb22d | 0xb22e | 0xb22f | 0xb230 | 0xb231 | 0xb232 | 0xb233 | 0xb234 | 0xb235 | 0xb236 | 0xb237 | 0xb238 | 0xb239 | 0xb23a | 0xb23b | 0xb23c | 0xb23d | 0xb23e | 0xb23f | 0xb240 | 0xb241 | 0xb242 | 0xb243 | 0xb244 | 0xb245 | 0xb246 | 0xb247 | 0xb248 | 0xb249 | 0xb24a | 0xb24b | 0xb24c | 0xb24d | 0xb24e | 0xb24f | 0xb250 | 0xb251 | 0xb252 | 0xb253 | 0xb254 | 0xb255 | 0xb256 | 0xb257 | 0xb258 | 0xb259 | 0xb25a | 0xb25b | 0xb25c | 0xb25d | 0xb25e | 0xb25f | 0xb260 | 0xb301 | 0xb302 | 0xb303 | 0xb304 | 0xb305 | 0xb306 | 0xb307 | 0xb308 | 0xb309 | 0xb30a | 0xb30b | 0xb30c | 0xb30d | 0xb30e | 0xb30f | 0xb310 | 0xb311 | 0xb312 | 0xb313 | 0xb314 | 0xb315 | 0xb316 | 0xb317 | 0xb318 | 0xb319 | 0xb31a | 0xb31b | 0xb31c | 0xb31d | 0xb31e | 0xb31f | 0xb320 | 0xb321 | 0xb322 | 0xb323 | 0xb324 | 0xb325 | 0xb326 | 0xb327 | 0xb328 | 0xb329 | 0xb32a | 0xb32b | 0xb32c | 0xb32d | 0xb32e | 0xb32f | 0xb330 | 0xb331 | 0xb332 | 0xb333 | 0xb334 | 0xb335 | 0xb336 | 0xb337 | 0xb338 | 0xb339 | 0xb33a | 0xb33b | 0xb33c | 0xb33d | 0xb33e | 0xb33f | 0xb340 | 0xb341 | 0xb342 | 0xb343 | 0xb344 | 0xb345 | 0xb346 | 0xb347 | 0xb348 | 0xb349 | 0xb34a | 0xb34b | 0xb34c | 0xb34d | 0xb34e | 0xb34f | 0xb350 | 0xb351 | 0xb352 | 0xb353 | 0xb354 | 0xb355 | 0xb356 | 0xb357 | 0xb358 | 0xb359 | 0xb35a | 0xb35b | 0xb35c | 0xb35d | 0xb35e | 0xb35f | 0xb360 | 0xb361 | 0xb362 | 0xb363 | 0xb364 | 0xb365 | 0xb366 | 0xb367 | 0xb368 | 0xb369 | 0xb36a | 0xb36b | 0xb36c | 0xb36d | 0xb36e | 0xb36f | 0xb370 | 0xb371 | 0xb372 | 0xb373 | 0xb374 | 0xb375 | 0xb376 | 0xb377 | 0xb378 | 0xb379 | 0xb37a | 0xb37b | 0xb37c | 0xb37d | 0xb37e | 0xb37f | 0xb380 | 0xb381 | 0xb382 | 0xb383 | 0xb384 | 0xb385 | 0xb386 | 0xb387 | 0xb388 | 0xb389 | 0xb38a | 0xb38b | 0xb38c | 0xb38d | 0xb38e | 0xb38f | 0xb390 | 0xb391 | 0xb392 | 0xb393 | 0xb394 | 0xb395 | 0xb396 | 0xb397 | 0xb398 | 0xb399 | 0xb39a | 0xb39b | 0xb39c | 0xb39d | 0xb39e | 0xb39f | 0xb3a0 | 0xb3a1 | 0xb3a2 | 0xb3a3 | 0xb3a4 | 0xb3a5 | 0xb3a6 | 0xb3a7 | 0xb3a8 | 0xb3a9 | 0xb3aa | 0xb3ab | 0xb3ac | 0xb3ad | 0xb3ae | 0xb3af | 0xb3b0 | 0xb3b1 | 0xb3b2 | 0xb3b3 | 0xb3b4 | 0xb3b5 | 0xb3b6 | 0xb3b7 | 0xb3b8 | 0xb3b9 | 0xb3ba | 0xb3bb | 0xb3bc | 0xb3bd | 0xb3be | 0xb3bf | 0xb3c0 | 0xb3c1 | 0xb3c2 | 0xb3c3 | 0xb3c4 | 0xb3c5 | 0xb3c6 | 0xb3c7 | 0xb3c8 | 0xb3c9 | 0xb3ca | 0xb3cb | 0xb3cc | 0xb3cd | 0xb3ce | 0xb3cf | 0xb3d0 | 0xb3d1 | 0xb3d2 | 0xb3d3 | 0xb3d4 | 0xb3d5 | 0xb3d6 | 0xb3d7 | 0xb3d8 | 0xb3d9 | 0xb3da | 0xb3db | 0xb3dc | 0xb3dd | 0xb3de | 0xb3df | 0xb3e0 | 0xb401 | 0xb402 } HashCode\n */\n\n/**\n * @type { Record<HashName,HashCode> }\n */\nconst names = Object.freeze({\n  'identity': 0x00,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'dbl-sha2-256': 0x56,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402\n})\n\nmodule.exports = { names }\n","/**\n * Multihash implementation in JavaScript.\n */\n'use strict'\n\nconst multibase = require('multibase')\nconst varint = require('varint')\nconst { names } = require('./constants')\nconst uint8ArrayToString = require('uint8arrays/to-string')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\nconst codes = /** @type {import('./types').CodeNameMap} */({})\n\n// eslint-disable-next-line guard-for-in\nfor (const key in names) {\n  const name = /** @type {HashName} */(key)\n  codes[names[name]] = name\n}\nObject.freeze(codes)\n\n/**\n * Convert the given multihash to a hex encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toHexString (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(hash, 'base16')\n}\n\n/**\n * Convert the given hex encoded string to a multihash.\n *\n * @param {string} hash\n * @returns {Uint8Array}\n */\nfunction fromHexString (hash) {\n  return uint8ArrayFromString(hash, 'base16')\n}\n\n/**\n * Convert the given multihash to a base58 encoded string.\n *\n * @param {Uint8Array} hash\n * @returns {string}\n */\nfunction toB58String (hash) {\n  if (!(hash instanceof Uint8Array)) {\n    throw new Error('must be passed a Uint8Array')\n  }\n\n  return uint8ArrayToString(multibase.encode('base58btc', hash)).slice(1)\n}\n\n/**\n * Convert the given base58 encoded string to a multihash.\n *\n * @param {string|Uint8Array} hash\n * @returns {Uint8Array}\n */\nfunction fromB58String (hash) {\n  const encoded = hash instanceof Uint8Array\n    ? uint8ArrayToString(hash)\n    : hash\n\n  return multibase.decode('z' + encoded)\n}\n\n/**\n * Decode a hash from the given multihash.\n *\n * @param {Uint8Array} bytes\n * @returns {{code: HashCode, name: HashName, length: number, digest: Uint8Array}} result\n */\nfunction decode (bytes) {\n  if (!(bytes instanceof Uint8Array)) {\n    throw new Error('multihash must be a Uint8Array')\n  }\n\n  if (bytes.length < 2) {\n    throw new Error('multihash too short. must be > 2 bytes.')\n  }\n\n  const code = /** @type {HashCode} */(varint.decode(bytes))\n  if (!isValidCode(code)) {\n    throw new Error(`multihash unknown function code: 0x${code.toString(16)}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  const len = varint.decode(bytes)\n  if (len < 0) {\n    throw new Error(`multihash invalid length: ${len}`)\n  }\n  bytes = bytes.slice(varint.decode.bytes)\n\n  if (bytes.length !== len) {\n    throw new Error(`multihash length inconsistent: 0x${uint8ArrayToString(bytes, 'base16')}`)\n  }\n\n  return {\n    code,\n    name: codes[code],\n    length: len,\n    digest: bytes\n  }\n}\n\n/**\n * Encode a hash digest along with the specified function code.\n *\n * > **Note:** the length is derived from the length of the digest itself.\n *\n * @param {Uint8Array} digest\n * @param {HashName | HashCode} code\n * @param {number} [length]\n * @returns {Uint8Array}\n */\nfunction encode (digest, code, length) {\n  if (!digest || code === undefined) {\n    throw new Error('multihash encode requires at least two args: digest, code')\n  }\n\n  // ensure it's a hashfunction code.\n  const hashfn = coerceCode(code)\n\n  if (!(digest instanceof Uint8Array)) {\n    throw new Error('digest should be a Uint8Array')\n  }\n\n  if (length == null) {\n    length = digest.length\n  }\n\n  if (length && digest.length !== length) {\n    throw new Error('digest length should be equal to specified length.')\n  }\n\n  const hash = varint.encode(hashfn)\n  const len = varint.encode(length)\n  return uint8ArrayConcat([hash, len, digest], hash.length + len.length + digest.length)\n}\n\n/**\n * Converts a hash function name into the matching code.\n * If passed a number it will return the number if it's a valid code.\n *\n * @param {HashName | number} name\n * @returns {number}\n */\nfunction coerceCode (name) {\n  let code = name\n\n  if (typeof name === 'string') {\n    if (names[name] === undefined) {\n      throw new Error(`Unrecognized hash function named: ${name}`)\n    }\n    code = names[name]\n  }\n\n  if (typeof code !== 'number') {\n    throw new Error(`Hash function code should be a number. Got: ${code}`)\n  }\n\n  // @ts-ignore\n  if (codes[code] === undefined && !isAppCode(code)) {\n    throw new Error(`Unrecognized function code: ${code}`)\n  }\n\n  return code\n}\n\n/**\n * Checks if a code is part of the app range\n *\n * @param {number} code\n * @returns {boolean}\n */\nfunction isAppCode (code) {\n  return code > 0 && code < 0x10\n}\n\n/**\n * Checks whether a multihash code is valid.\n *\n * @param {HashCode} code\n * @returns {boolean}\n */\nfunction isValidCode (code) {\n  if (isAppCode(code)) {\n    return true\n  }\n\n  if (codes[code]) {\n    return true\n  }\n\n  return false\n}\n\n/**\n * Check if the given buffer is a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {void}\n * @throws {Error}\n */\nfunction validate (multihash) {\n  decode(multihash) // throws if bad.\n}\n\n/**\n * Returns a prefix from a valid multihash. Throws an error if it is not valid.\n *\n * @param {Uint8Array} multihash\n * @returns {Uint8Array}\n * @throws {Error}\n */\nfunction prefix (multihash) {\n  validate(multihash)\n\n  return multihash.subarray(0, 2)\n}\n\nmodule.exports = {\n  names,\n  codes,\n  toHexString,\n  fromHexString,\n  toB58String,\n  fromB58String,\n  decode,\n  encode,\n  coerceCode,\n  isAppCode,\n  validate,\n  prefix,\n  isValidCode\n}\n\n/**\n * @typedef { import(\"./constants\").HashCode } HashCode\n * @typedef { import(\"./constants\").HashName } HashName\n */\n","'use strict'\n\n// @ts-ignore - no types available\nconst blake = require('blakejs')\n\nconst minB = 0xb201\nconst minS = 0xb241\n\nconst blake2b = {\n  init: blake.blake2bInit,\n  update: blake.blake2bUpdate,\n  digest: blake.blake2bFinal\n}\n\nconst blake2s = {\n  init: blake.blake2sInit,\n  update: blake.blake2sUpdate,\n  digest: blake.blake2sFinal\n}\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n\n/**\n * @param {number} size\n * @param {any} hf\n * @returns {import('./types').Digest}\n */\nconst makeB2Hash = (size, hf) => async (data) => {\n  const ctx = hf.init(size, null)\n  hf.update(ctx, data)\n  return hf.digest(ctx)\n}\n\n/**\n * @param {Record<number, import('./types').Digest>} table\n */\nmodule.exports = (table) => {\n  for (let i = 0; i < 64; i++) {\n    table[minB + i] = makeB2Hash(i + 1, blake2b)\n  }\n  for (let i = 0; i < 32; i++) {\n    table[minS + i] = makeB2Hash(i + 1, blake2s)\n  }\n}\n","'use strict'\n\nconst sha3 = require('js-sha3')\n// @ts-ignore - no types available\nconst mur = require('murmurhash3js-revisited')\nconst { factory: sha } = require('./sha')\nconst { fromNumberTo32BitBuf } = require('./utils')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n// Note that although this function doesn't do any asynchronous work, we mark\n// the function as async because it must return a Promise to match the API\n// for other functions that do perform asynchronous work (see sha.browser.js)\n// eslint-disable-next-line\n/**\n * @param {string} algorithm\n * @returns {import('./types').Digest}\n */\nconst hash = (algorithm) => async (data) => {\n  switch (algorithm) {\n    case 'sha3-224':\n      return new Uint8Array(sha3.sha3_224.arrayBuffer(data))\n    case 'sha3-256':\n      return new Uint8Array(sha3.sha3_256.arrayBuffer(data))\n    case 'sha3-384':\n      return new Uint8Array(sha3.sha3_384.arrayBuffer(data))\n    case 'sha3-512':\n      return new Uint8Array(sha3.sha3_512.arrayBuffer(data))\n    case 'shake-128':\n      return new Uint8Array(sha3.shake128.create(128).update(data).arrayBuffer())\n    case 'shake-256':\n      return new Uint8Array(sha3.shake256.create(256).update(data).arrayBuffer())\n    case 'keccak-224':\n      return new Uint8Array(sha3.keccak224.arrayBuffer(data))\n    case 'keccak-256':\n      return new Uint8Array(sha3.keccak256.arrayBuffer(data))\n    case 'keccak-384':\n      return new Uint8Array(sha3.keccak384.arrayBuffer(data))\n    case 'keccak-512':\n      return new Uint8Array(sha3.keccak512.arrayBuffer(data))\n    case 'murmur3-128':\n      return uint8ArrayFromString(mur.x64.hash128(data), 'base16')\n    case 'murmur3-32':\n      return fromNumberTo32BitBuf(mur.x86.hash32(data))\n\n    default:\n      throw new TypeError(`${algorithm} is not a supported algorithm`)\n  }\n}\n\n/** @type {import('./types').Digest} */\nconst identity = data => data\n\nmodule.exports = {\n  identity,\n  sha1: sha('sha1'),\n  sha2256: sha('sha2-256'),\n  sha2512: sha('sha2-512'),\n  dblSha2256: sha('dbl-sha2-256'),\n  sha3224: hash('sha3-224'),\n  sha3256: hash('sha3-256'),\n  sha3384: hash('sha3-384'),\n  sha3512: hash('sha3-512'),\n  shake128: hash('shake-128'),\n  shake256: hash('shake-256'),\n  keccak224: hash('keccak-224'),\n  keccak256: hash('keccak-256'),\n  keccak384: hash('keccak-384'),\n  keccak512: hash('keccak-512'),\n  murmur3128: hash('murmur3-128'),\n  murmur332: hash('murmur3-32'),\n  addBlake: require('./blake')\n}\n","'use strict'\n\nconst errcode = require('err-code')\nconst multihash = require('multihashes')\nconst crypto = require('./crypto')\nconst equals = require('uint8arrays/equals')\n\n/**\n * @typedef {import(\"./types\").Digest} Digest\n * @typedef {import(\"multihashes\").HashName} HashName\n */\n\n/**\n * Hash the given `bytes` using the algorithm specified by `alg`.\n *\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nasync function Multihashing (bytes, alg, length) {\n  const digest = await Multihashing.digest(bytes, alg, length)\n  return multihash.encode(digest, alg, length)\n}\n\n/**\n * Expose multihash itself, to avoid silly double requires.\n */\nMultihashing.multihash = multihash\n\n/**\n * @param {Uint8Array} bytes - The value to hash.\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @param {number} [length] - Optionally trim the result to this length.\n * @returns {Promise<Uint8Array>}\n */\nMultihashing.digest = async (bytes, alg, length) => {\n  const hash = Multihashing.createHash(alg)\n  const digest = await hash(bytes)\n  return length ? digest.slice(0, length) : digest\n}\n\n/**\n * Creates a function that hashes with the given algorithm\n *\n * @param {HashName} alg - The algorithm to use eg 'sha1'\n * @returns {Digest} - The hash function corresponding to `alg`\n */\nMultihashing.createHash = function (alg) {\n  if (!alg) {\n    const e = errcode(new Error('hash algorithm must be specified'), 'ERR_HASH_ALGORITHM_NOT_SPECIFIED')\n    throw e\n  }\n\n  const code = multihash.coerceCode(alg)\n  if (!Multihashing.functions[code]) {\n    throw errcode(new Error(`multihash function '${alg}' not yet supported`), 'ERR_HASH_ALGORITHM_NOT_SUPPORTED')\n  }\n\n  return Multihashing.functions[code]\n}\n\n/**\n * Mapping of multihash codes to their hashing functions.\n *\n * @type {Record<number, Digest>}\n */\n// @ts-ignore - most of those functions aren't typed\nMultihashing.functions = {\n  // identity\n  0x00: crypto.identity,\n  // sha1\n  0x11: crypto.sha1,\n  // sha2-256\n  0x12: crypto.sha2256,\n  // sha2-512\n  0x13: crypto.sha2512,\n  // sha3-512\n  0x14: crypto.sha3512,\n  // sha3-384\n  0x15: crypto.sha3384,\n  // sha3-256\n  0x16: crypto.sha3256,\n  // sha3-224\n  0x17: crypto.sha3224,\n  // shake-128\n  0x18: crypto.shake128,\n  // shake-256\n  0x19: crypto.shake256,\n  // keccak-224\n  0x1A: crypto.keccak224,\n  // keccak-256\n  0x1B: crypto.keccak256,\n  // keccak-384\n  0x1C: crypto.keccak384,\n  // keccak-512\n  0x1D: crypto.keccak512,\n  // murmur3-128\n  0x22: crypto.murmur3128,\n  // murmur3-32\n  0x23: crypto.murmur332,\n  // dbl-sha2-256\n  0x56: crypto.dblSha2256\n}\n\n// add blake functions\ncrypto.addBlake(Multihashing.functions)\n\n/**\n * @param {Uint8Array} bytes\n * @param {Uint8Array} hash\n * @returns {Promise<boolean>}\n */\nMultihashing.validate = async (bytes, hash) => {\n  const newHash = await Multihashing(bytes, multihash.decode(hash).name)\n\n  return equals(hash, newHash)\n}\n\nmodule.exports = Multihashing\n","/* eslint-disable require-await */\n'use strict'\n\nconst multihash = require('multihashes')\n/**\n * @typedef {import('multihashes').HashName} HashName\n * @typedef {import('./types').Digest} Digest\n */\n\n/**\n * @type {Crypto}\n */\nconst crypto =\n  self.crypto ||\n  /** @type {typeof window.crypto} */\n  // @ts-ignore - unknown property\n  (self.msCrypto)\n\n/**\n *\n * @param {Uint8Array} data\n * @param {HashName} alg\n * @returns {Promise<Uint8Array>}\n */\nconst digest = async (data, alg) => {\n  if (typeof self === 'undefined' || !crypto) {\n    throw new Error(\n      'Please use a browser with webcrypto support and ensure the code has been delivered securely via HTTPS/TLS and run within a Secure Context'\n    )\n  }\n  switch (alg) {\n    case 'sha1':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-1' }, data))\n    case 'sha2-256':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, data))\n    case 'sha2-512':\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-512' }, data))\n    case 'dbl-sha2-256': {\n      const d = await crypto.subtle.digest({ name: 'SHA-256' }, data)\n      return new Uint8Array(await crypto.subtle.digest({ name: 'SHA-256' }, d))\n    }\n    default:\n      throw new Error(`${alg} is not a supported algorithm`)\n  }\n}\n\nmodule.exports = {\n  /**\n   * @param {HashName} alg\n   * @returns {Digest}\n   */\n  factory: (alg) => async (data) => {\n    return digest(data, alg)\n  },\n  digest,\n  /**\n   * @param {Uint8Array} buf\n   * @param {HashName} alg\n   * @param {number} [length]\n   */\n  multihashing: async (buf, alg, length) => {\n    const h = await digest(buf, alg)\n    return multihash.encode(h, alg, length)\n  }\n}\n","'use strict'\n\n/**\n * @param {number} number\n * @returns {Uint8Array}\n */\nconst fromNumberTo32BitBuf = (number) => {\n  const bytes = new Uint8Array(4)\n\n  for (let i = 0; i < 4; i++) {\n    bytes[i] = number & 0xff\n    number = number >> 8\n  }\n\n  return bytes\n}\n\nmodule.exports = {\n  fromNumberTo32BitBuf\n}\n","'use strict'\n\n/**\n * Returns a new Uint8Array created by concatenating the passed ArrayLikes\n *\n * @param {Array<ArrayLike<number>>} arrays\n * @param {number} [length]\n */\nfunction concat (arrays, length) {\n  if (!length) {\n    length = arrays.reduce((acc, curr) => acc + curr.length, 0)\n  }\n\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrays) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = concat\n","'use strict'\n\n/**\n * Returns true if the two passed Uint8Arrays have the same content\n *\n * @param {Uint8Array} a\n * @param {Uint8Array} b\n */\nfunction equals (a, b) {\n  if (a === b) {\n    return true\n  }\n\n  if (a.byteLength !== b.byteLength) {\n    return false\n  }\n\n  for (let i = 0; i < a.byteLength; i++) {\n    if (a[i] !== b[i]) {\n      return false\n    }\n  }\n\n  return true\n}\n\nmodule.exports = equals\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextEncoder } = require('web-encoding')\nconst utf8Encoder = new TextEncoder()\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Interprets each character in a string as a byte and\n * returns a Uint8Array of those bytes.\n *\n * @param {string} string - The string to turn into an array\n */\nfunction asciiStringToUint8Array (string) {\n  const array = new Uint8Array(string.length)\n\n  for (let i = 0; i < string.length; i++) {\n    array[i] = string.charCodeAt(i)\n  }\n\n  return array\n}\n\n/**\n * Create a `Uint8Array` from the passed string\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {string} string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - utf8, base16, base64, base64urlpad, etc\n * @returns {Uint8Array}\n */\nfunction fromString (string, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Encoder.encode(string)\n  }\n\n  if (encoding === 'ascii') {\n    return asciiStringToUint8Array(string)\n  }\n\n  return getCodec(encoding).decode(string)\n}\n\nmodule.exports = fromString\n","'use strict'\n\nconst { encoding: getCodec } = require('multibase')\nconst { TextDecoder } = require('web-encoding')\nconst utf8Decoder = new TextDecoder('utf8')\n\n/**\n * @typedef {import('multibase/src/types').BaseName} BaseName\n */\n\n/**\n * Turns a Uint8Array of bytes into a string with each\n * character being the char code of the corresponding byte\n *\n * @param {Uint8Array} array - The array to turn into a string\n */\nfunction uint8ArrayToAsciiString (array) {\n  let string = ''\n\n  for (let i = 0; i < array.length; i++) {\n    string += String.fromCharCode(array[i])\n  }\n  return string\n}\n\n/**\n * Turns a `Uint8Array` into a string.\n *\n * Supports `utf8`, `utf-8` and any encoding supported by the multibase module.\n *\n * Also `ascii` which is similar to node's 'binary' encoding.\n *\n * @param {Uint8Array} array - The array to turn into a string\n * @param {BaseName | 'utf8' | 'utf-8' | 'ascii'} [encoding=utf8] - The encoding to use\n * @returns {string}\n */\nfunction toString (array, encoding = 'utf8') {\n  if (encoding === 'utf8' || encoding === 'utf-8') {\n    return utf8Decoder.decode(array)\n  }\n\n  if (encoding === 'ascii') {\n    return uint8ArrayToAsciiString(array)\n  }\n\n  return getCodec(encoding).encode(array)\n}\n\nmodule.exports = toString\n","'use strict'\n\nexports.util = require('./util.js')\nexports.resolver = require('./resolver.js')\nexports.codec = exports.util.codec\nexports.defaultHashAlg = exports.util.defaultHashAlg\n","'use strict'\n\nconst CID = require('cids')\nconst util = require('./util')\n\n/**\n * Resolves a path within a CBOR block.\n *\n * Returns the value or a link and the partial mising path. This way the\n * IPLD Resolver can fetch the link and continue to resolve.\n *\n * @param {Uint8Array} binaryBlob - Binary representation of a CBOR block\n * @param {string} [path='/'] - Path that should be resolved\n */\nexports.resolve = (binaryBlob, path) => {\n  let node = util.deserialize(binaryBlob)\n\n  const parts = path.split('/').filter(Boolean)\n  while (parts.length) {\n    const key = parts.shift()\n    if (node[key] === undefined) {\n      throw new Error(`Object has no property '${key}'`)\n    }\n\n    node = node[key]\n    if (CID.isCID(node)) {\n      return {\n        value: node,\n        remainderPath: parts.join('/')\n      }\n    }\n  }\n\n  return {\n    value: node,\n    remainderPath: ''\n  }\n}\n\nconst traverse = function * (node, path) {\n  // Traverse only objects and arrays\n  if (node instanceof Uint8Array || CID.isCID(node) || typeof node === 'string' ||\n      node === null) {\n    return\n  }\n  for (const item of Object.keys(node)) {\n    const nextpath = path === undefined ? item : path + '/' + item\n    yield nextpath\n    yield * traverse(node[item], nextpath)\n  }\n}\n\n/**\n * Return all available paths of a block.\n *\n * @generator\n * @param {Uint8Array} binaryBlob - Binary representation of a CBOR block\n * @yields {string} - A single path\n */\nexports.tree = function * (binaryBlob) {\n  const node = util.deserialize(binaryBlob)\n\n  yield * traverse(node)\n}\n","'use strict'\n\nconst cbor = require('borc')\nconst multicodec = require('multicodec')\nconst multihashing = require('multihashing-async')\nconst CID = require('cids')\nconst isCircular = require('is-circular')\nconst uint8ArrayConcat = require('uint8arrays/concat')\nconst uint8ArrayFromString = require('uint8arrays/from-string')\n\n// https://github.com/ipfs/go-ipfs/issues/3570#issuecomment-273931692\nconst CID_CBOR_TAG = 42\n\nfunction tagCID (cid) {\n  if (typeof cid === 'string') {\n    cid = new CID(cid).bytes\n  } else if (CID.isCID(cid)) {\n    cid = cid.bytes\n  }\n\n  return new cbor.Tagged(CID_CBOR_TAG, uint8ArrayConcat([\n    uint8ArrayFromString('00', 'base16'), // thanks jdag\n    cid\n  ], 1 + cid.length))\n}\n\nfunction replaceCIDbyTAG (dagNode) {\n  let circular\n  try {\n    circular = isCircular(dagNode)\n  } catch (e) {\n    circular = false\n  }\n  if (circular) {\n    throw new Error('The object passed has circular references')\n  }\n\n  function transform (obj) {\n    if (!obj || obj instanceof Uint8Array || typeof obj === 'string') {\n      return obj\n    }\n\n    if (Array.isArray(obj)) {\n      return obj.map(transform)\n    }\n\n    if (CID.isCID(obj)) {\n      return tagCID(obj)\n    }\n\n    const keys = Object.keys(obj)\n\n    if (keys.length > 0) {\n      // Recursive transform\n      const out = {}\n      keys.forEach((key) => {\n        if (typeof obj[key] === 'object') {\n          out[key] = transform(obj[key])\n        } else {\n          out[key] = obj[key]\n        }\n      })\n      return out\n    } else {\n      return obj\n    }\n  }\n\n  return transform(dagNode)\n}\n\nconst codec = multicodec.DAG_CBOR\nconst defaultHashAlg = multicodec.SHA2_256\n\nconst defaultTags = {\n  [CID_CBOR_TAG]: (val) => {\n    // remove that 0\n    val = val.slice(1)\n    return new CID(val)\n  }\n}\nconst defaultSize = 64 * 1024 // current decoder heap size, 64 Kb\nlet currentSize = defaultSize\nconst defaultMaxSize = 64 * 1024 * 1024 // max heap size when auto-growing, 64 Mb\nlet maxSize = defaultMaxSize\nlet decoder = null\n\n/**\n * Configure the underlying CBOR decoder.\n *\n * @param {Object} [options] - The options the decoder takes. The decoder will reset to the defaul values if no options are given.\n * @param {number} [options.size=65536] - The current heap size used in CBOR parsing, this may grow automatically as larger blocks are encountered up to `maxSize`\n * @param {number} [options.maxSize=67108864] - The maximum size the CBOR parsing heap is allowed to grow to before `dagCBOR.util.deserialize()` returns an error\n * @param {Object} [options.tags] - An object whose keys are CBOR tag numbers and values are transform functions that accept a `value` and return a decoded representation of that `value`\n */\nfunction configureDecoder (options) {\n  let tags = defaultTags\n\n  if (options) {\n    if (typeof options.size === 'number') {\n      currentSize = options.size\n    }\n    if (typeof options.maxSize === 'number') {\n      maxSize = options.maxSize\n    }\n    if (options.tags) {\n      tags = Object.assign({}, defaultTags, options && options.tags)\n    }\n  } else {\n    // no options, reset to defaults\n    currentSize = defaultSize\n    maxSize = defaultMaxSize\n  }\n\n  const decoderOptions = {\n    tags,\n    size: currentSize\n  }\n\n  decoder = new cbor.Decoder(decoderOptions)\n  // borc edits opts.size in-place so we can capture _actual_ size\n  currentSize = decoderOptions.size\n}\n\nconfigureDecoder() // Setup default cbor.Decoder\n\n/**\n * Serialize internal representation into a binary CBOR block.\n *\n * @param {Object} node - Internal representation of a CBOR block\n * @returns {Uint8Array} - The encoded binary representation\n */\nfunction serialize (node) {\n  const nodeTagged = replaceCIDbyTAG(node)\n  const serialized = cbor.encode(nodeTagged)\n\n  return serialized\n}\n\n/**\n * Deserialize CBOR block into the internal representation.\n *\n * @param {Uint8Array} data - Binary representation of a CBOR block\n * @returns {Object} - An object that conforms to the IPLD Data Model\n */\nfunction deserialize (data) {\n  if (data.length > currentSize && data.length <= maxSize) {\n    configureDecoder({ size: data.length })\n  }\n\n  if (data.length > currentSize) {\n    throw new Error('Data is too large to deserialize with current decoder')\n  }\n\n  // borc will decode back-to-back objects into an implicit top-level array, we\n  // strictly want to only see a single explicit top-level object\n  const all = decoder.decodeAll(data)\n  if (all.length !== 1) {\n    throw new Error('Extraneous CBOR data found beyond initial top-level object')\n  }\n\n  return all[0]\n}\n\n/**\n * Calculate the CID of the binary blob.\n *\n * @param {Object} binaryBlob - Encoded IPLD Node\n * @param {Object} [userOptions] - Options to create the CID\n * @param {number} [userOptions.cidVersion=1] - CID version number\n * @param {string} [userOptions.hashAlg] - Defaults to the defaultHashAlg of the format\n * @returns {Promise.<CID>}\n */\nasync function cid (binaryBlob, userOptions) {\n  const defaultOptions = { cidVersion: 1, hashAlg: defaultHashAlg }\n  const options = Object.assign(defaultOptions, userOptions)\n\n  const multihash = await multihashing(binaryBlob, options.hashAlg)\n  const codecName = multicodec.getNameFromCode(codec)\n  const cid = new CID(options.cidVersion, codecName, multihash)\n\n  return cid\n}\n\nmodule.exports = {\n  codec,\n  defaultHashAlg,\n  configureDecoder,\n  serialize,\n  deserialize,\n  cid\n}\n","'use strict';\n\n/**\n * @typedef {{ [key: string]: any }} Extensions\n * @typedef {Error} Err\n * @property {string} message\n */\n\n/**\n *\n * @param {Error} obj\n * @param {Extensions} props\n * @returns {Error & Extensions}\n */\nfunction assign(obj, props) {\n    for (const key in props) {\n        Object.defineProperty(obj, key, {\n            value: props[key],\n            enumerable: true,\n            configurable: true,\n        });\n    }\n\n    return obj;\n}\n\n/**\n *\n * @param {any} err - An Error\n * @param {string|Extensions} code - A string code or props to set on the error\n * @param {Extensions} [props] - Props to set on the error\n * @returns {Error & Extensions}\n */\nfunction createError(err, code, props) {\n    if (!err || typeof err === 'string') {\n        throw new TypeError('Please pass an Error to err-code');\n    }\n\n    if (!props) {\n        props = {};\n    }\n\n    if (typeof code === 'object') {\n        props = code;\n        code = '';\n    }\n\n    if (code) {\n        props.code = code;\n    }\n\n    try {\n        return assign(err, props);\n    } catch (_) {\n        props.message = err.message;\n        props.stack = err.stack;\n\n        const ErrClass = function () {};\n\n        ErrClass.prototype = Object.create(Object.getPrototypeOf(err));\n\n        // @ts-ignore\n        const output = assign(new ErrClass(), props);\n\n        return output;\n    }\n}\n\nmodule.exports = createError;\n","'use strict'\n\nconst { encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import(\"./types\").BaseName} BaseName */\n/** @typedef {import(\"./types\").BaseCode} BaseCode */\n\n/**\n * Class to encode/decode in the supported Bases\n *\n */\nclass Base {\n  /**\n   * @param {BaseName} name\n   * @param {BaseCode} code\n   * @param {CodecFactory} factory\n   * @param {string} alphabet\n   */\n  constructor (name, code, factory, alphabet) {\n    this.name = name\n    this.code = code\n    this.codeBuf = encodeText(this.code)\n    this.alphabet = alphabet\n    this.codec = factory(alphabet)\n  }\n\n  /**\n   * @param {Uint8Array} buf\n   * @returns {string}\n   */\n  encode (buf) {\n    return this.codec.encode(buf)\n  }\n\n  /**\n   * @param {string} string\n   * @returns {Uint8Array}\n   */\n  decode (string) {\n    for (const char of string) {\n      if (this.alphabet && this.alphabet.indexOf(char) < 0) {\n        throw new Error(`invalid character '${char}' in '${string}'`)\n      }\n    }\n    return this.codec.decode(string)\n  }\n}\n\nmodule.exports = Base\n","'use strict'\n\nconst baseX = require('@multiformats/base-x')\nconst Base = require('./base.js')\nconst { rfc4648 } = require('./rfc4648')\nconst { decodeText, encodeText } = require('./util')\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n/** @typedef {import('./types').Codec} Codec */\n/** @typedef {import('./types').BaseName} BaseName */\n/** @typedef {import('./types').BaseCode} BaseCode */\n\n/** @type {CodecFactory} */\nconst identity = () => {\n  return {\n    encode: decodeText,\n    decode: encodeText\n  }\n}\n\n/**\n *\n * name, code, implementation, alphabet\n *\n * @type {Array<[BaseName, BaseCode, CodecFactory, string]>}\n */\nconst constants = [\n  ['identity', '\\x00', identity, ''],\n  ['base2', '0', rfc4648(1), '01'],\n  ['base8', '7', rfc4648(3), '01234567'],\n  ['base10', '9', baseX, '0123456789'],\n  ['base16', 'f', rfc4648(4), '0123456789abcdef'],\n  ['base16upper', 'F', rfc4648(4), '0123456789ABCDEF'],\n  ['base32hex', 'v', rfc4648(5), '0123456789abcdefghijklmnopqrstuv'],\n  ['base32hexupper', 'V', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV'],\n  ['base32hexpad', 't', rfc4648(5), '0123456789abcdefghijklmnopqrstuv='],\n  ['base32hexpadupper', 'T', rfc4648(5), '0123456789ABCDEFGHIJKLMNOPQRSTUV='],\n  ['base32', 'b', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567'],\n  ['base32upper', 'B', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'],\n  ['base32pad', 'c', rfc4648(5), 'abcdefghijklmnopqrstuvwxyz234567='],\n  ['base32padupper', 'C', rfc4648(5), 'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567='],\n  ['base32z', 'h', rfc4648(5), 'ybndrfg8ejkmcpqxot1uwisza345h769'],\n  ['base36', 'k', baseX, '0123456789abcdefghijklmnopqrstuvwxyz'],\n  ['base36upper', 'K', baseX, '0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ'],\n  ['base58btc', 'z', baseX, '123456789ABCDEFGHJKLMNPQRSTUVWXYZabcdefghijkmnopqrstuvwxyz'],\n  ['base58flickr', 'Z', baseX, '123456789abcdefghijkmnopqrstuvwxyzABCDEFGHJKLMNPQRSTUVWXYZ'],\n  ['base64', 'm', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'],\n  ['base64pad', 'M', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/='],\n  ['base64url', 'u', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_'],\n  ['base64urlpad', 'U', rfc4648(6), 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789-_=']\n]\n\n/** @type {Record<BaseName,Base>} */\nconst names = constants.reduce((prev, tupple) => {\n  prev[tupple[0]] = new Base(tupple[0], tupple[1], tupple[2], tupple[3])\n  return prev\n}, /** @type {Record<BaseName,Base>} */({}))\n\n/** @type {Record<BaseCode,Base>} */\nconst codes = constants.reduce((prev, tupple) => {\n  prev[tupple[1]] = names[tupple[0]]\n  return prev\n}, /** @type {Record<BaseCode,Base>} */({}))\n\nmodule.exports = {\n  names,\n  codes\n}\n","'use strict'\n\n/** @typedef {import('./types').CodecFactory} CodecFactory */\n\n/**\n * @param {string} string\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {Uint8Array}\n */\nconst decode = (string, alphabet, bitsPerChar) => {\n  // Build the character lookup table:\n  /** @type {Record<string, number>} */\n  const codes = {}\n  for (let i = 0; i < alphabet.length; ++i) {\n    codes[alphabet[i]] = i\n  }\n\n  // Count the padding bytes:\n  let end = string.length\n  while (string[end - 1] === '=') {\n    --end\n  }\n\n  // Allocate the output:\n  const out = new Uint8Array((end * bitsPerChar / 8) | 0)\n\n  // Parse the data:\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  let written = 0 // Next byte to write\n  for (let i = 0; i < end; ++i) {\n    // Read one character from the string:\n    const value = codes[string[i]]\n    if (value === undefined) {\n      throw new SyntaxError('Invalid character ' + string[i])\n    }\n\n    // Append the bits to the buffer:\n    buffer = (buffer << bitsPerChar) | value\n    bits += bitsPerChar\n\n    // Write out some bits if the buffer has a byte's worth:\n    if (bits >= 8) {\n      bits -= 8\n      out[written++] = 0xff & (buffer >> bits)\n    }\n  }\n\n  // Verify that we have received just enough bits:\n  if (bits >= bitsPerChar || 0xff & (buffer << (8 - bits))) {\n    throw new SyntaxError('Unexpected end of data')\n  }\n\n  return out\n}\n\n/**\n * @param {Uint8Array} data\n * @param {string} alphabet\n * @param {number} bitsPerChar\n * @returns {string}\n */\nconst encode = (data, alphabet, bitsPerChar) => {\n  const pad = alphabet[alphabet.length - 1] === '='\n  const mask = (1 << bitsPerChar) - 1\n  let out = ''\n\n  let bits = 0 // Number of bits currently in the buffer\n  let buffer = 0 // Bits waiting to be written out, MSB first\n  for (let i = 0; i < data.length; ++i) {\n    // Slurp data into the buffer:\n    buffer = (buffer << 8) | data[i]\n    bits += 8\n\n    // Write out as much as we can:\n    while (bits > bitsPerChar) {\n      bits -= bitsPerChar\n      out += alphabet[mask & (buffer >> bits)]\n    }\n  }\n\n  // Partial character:\n  if (bits) {\n    out += alphabet[mask & (buffer << (bitsPerChar - bits))]\n  }\n\n  // Add padding characters until we hit a byte boundary:\n  if (pad) {\n    while ((out.length * bitsPerChar) & 7) {\n      out += '='\n    }\n  }\n\n  return out\n}\n\n/**\n * RFC4648 Factory\n *\n * @param {number} bitsPerChar\n * @returns {CodecFactory}\n */\nconst rfc4648 = (bitsPerChar) => (alphabet) => {\n  return {\n    /**\n     * @param {Uint8Array} input\n     * @returns {string}\n     */\n    encode (input) {\n      return encode(input, alphabet, bitsPerChar)\n    },\n    /**\n     * @param {string} input\n     * @returns {Uint8Array}\n     */\n    decode (input) {\n      return decode(input, alphabet, bitsPerChar)\n    }\n  }\n}\n\nmodule.exports = { rfc4648 }\n","'use strict'\n\n// @ts-ignore\nconst { TextEncoder, TextDecoder } = require('web-encoding')\n\nconst textDecoder = new TextDecoder()\n/**\n * @param {ArrayBufferView|ArrayBuffer} bytes\n * @returns {string}\n */\nconst decodeText = (bytes) => textDecoder.decode(bytes)\n\nconst textEncoder = new TextEncoder()\n/**\n * @param {string} text\n * @returns {Uint8Array}\n */\nconst encodeText = (text) => textEncoder.encode(text)\n\n/**\n * Returns a new Uint8Array created by concatenating the passed Arrays\n *\n * @param {Array<ArrayLike<number>>} arrs\n * @param {number} length\n * @returns {Uint8Array}\n */\nfunction concat (arrs, length) {\n  const output = new Uint8Array(length)\n  let offset = 0\n\n  for (const arr of arrs) {\n    output.set(arr, offset)\n    offset += arr.length\n  }\n\n  return output\n}\n\nmodule.exports = { decodeText, encodeText, concat }\n","// DO NOT CHANGE THIS FILE. IT IS GENERATED BY tools/update-table.js\n/* eslint quote-props: off */\n'use strict'\n\n/**\n * @type {import('./generated-types').NameNumberMap}\n */\nconst baseTable = Object.freeze({\n  'identity': 0x00,\n  'cidv1': 0x01,\n  'cidv2': 0x02,\n  'cidv3': 0x03,\n  'ip4': 0x04,\n  'tcp': 0x06,\n  'sha1': 0x11,\n  'sha2-256': 0x12,\n  'sha2-512': 0x13,\n  'sha3-512': 0x14,\n  'sha3-384': 0x15,\n  'sha3-256': 0x16,\n  'sha3-224': 0x17,\n  'shake-128': 0x18,\n  'shake-256': 0x19,\n  'keccak-224': 0x1a,\n  'keccak-256': 0x1b,\n  'keccak-384': 0x1c,\n  'keccak-512': 0x1d,\n  'blake3': 0x1e,\n  'dccp': 0x21,\n  'murmur3-128': 0x22,\n  'murmur3-32': 0x23,\n  'ip6': 0x29,\n  'ip6zone': 0x2a,\n  'path': 0x2f,\n  'multicodec': 0x30,\n  'multihash': 0x31,\n  'multiaddr': 0x32,\n  'multibase': 0x33,\n  'dns': 0x35,\n  'dns4': 0x36,\n  'dns6': 0x37,\n  'dnsaddr': 0x38,\n  'protobuf': 0x50,\n  'cbor': 0x51,\n  'raw': 0x55,\n  'dbl-sha2-256': 0x56,\n  'rlp': 0x60,\n  'bencode': 0x63,\n  'dag-pb': 0x70,\n  'dag-cbor': 0x71,\n  'libp2p-key': 0x72,\n  'git-raw': 0x78,\n  'torrent-info': 0x7b,\n  'torrent-file': 0x7c,\n  'leofcoin-block': 0x81,\n  'leofcoin-tx': 0x82,\n  'leofcoin-pr': 0x83,\n  'sctp': 0x84,\n  'dag-jose': 0x85,\n  'dag-cose': 0x86,\n  'eth-block': 0x90,\n  'eth-block-list': 0x91,\n  'eth-tx-trie': 0x92,\n  'eth-tx': 0x93,\n  'eth-tx-receipt-trie': 0x94,\n  'eth-tx-receipt': 0x95,\n  'eth-state-trie': 0x96,\n  'eth-account-snapshot': 0x97,\n  'eth-storage-trie': 0x98,\n  'bitcoin-block': 0xb0,\n  'bitcoin-tx': 0xb1,\n  'bitcoin-witness-commitment': 0xb2,\n  'zcash-block': 0xc0,\n  'zcash-tx': 0xc1,\n  'docid': 0xce,\n  'stellar-block': 0xd0,\n  'stellar-tx': 0xd1,\n  'md4': 0xd4,\n  'md5': 0xd5,\n  'bmt': 0xd6,\n  'decred-block': 0xe0,\n  'decred-tx': 0xe1,\n  'ipld-ns': 0xe2,\n  'ipfs-ns': 0xe3,\n  'swarm-ns': 0xe4,\n  'ipns-ns': 0xe5,\n  'zeronet': 0xe6,\n  'secp256k1-pub': 0xe7,\n  'bls12_381-g1-pub': 0xea,\n  'bls12_381-g2-pub': 0xeb,\n  'x25519-pub': 0xec,\n  'ed25519-pub': 0xed,\n  'bls12_381-g1g2-pub': 0xee,\n  'dash-block': 0xf0,\n  'dash-tx': 0xf1,\n  'swarm-manifest': 0xfa,\n  'swarm-feed': 0xfb,\n  'udp': 0x0111,\n  'p2p-webrtc-star': 0x0113,\n  'p2p-webrtc-direct': 0x0114,\n  'p2p-stardust': 0x0115,\n  'p2p-circuit': 0x0122,\n  'dag-json': 0x0129,\n  'udt': 0x012d,\n  'utp': 0x012e,\n  'unix': 0x0190,\n  'p2p': 0x01a5,\n  'ipfs': 0x01a5,\n  'https': 0x01bb,\n  'onion': 0x01bc,\n  'onion3': 0x01bd,\n  'garlic64': 0x01be,\n  'garlic32': 0x01bf,\n  'tls': 0x01c0,\n  'quic': 0x01cc,\n  'ws': 0x01dd,\n  'wss': 0x01de,\n  'p2p-websocket-star': 0x01df,\n  'http': 0x01e0,\n  'json': 0x0200,\n  'messagepack': 0x0201,\n  'libp2p-peer-record': 0x0301,\n  'sha2-256-trunc254-padded': 0x1012,\n  'ripemd-128': 0x1052,\n  'ripemd-160': 0x1053,\n  'ripemd-256': 0x1054,\n  'ripemd-320': 0x1055,\n  'x11': 0x1100,\n  'p256-pub': 0x1200,\n  'p384-pub': 0x1201,\n  'p521-pub': 0x1202,\n  'ed448-pub': 0x1203,\n  'x448-pub': 0x1204,\n  'ed25519-priv': 0x1300,\n  'kangarootwelve': 0x1d01,\n  'sm3-256': 0x534d,\n  'blake2b-8': 0xb201,\n  'blake2b-16': 0xb202,\n  'blake2b-24': 0xb203,\n  'blake2b-32': 0xb204,\n  'blake2b-40': 0xb205,\n  'blake2b-48': 0xb206,\n  'blake2b-56': 0xb207,\n  'blake2b-64': 0xb208,\n  'blake2b-72': 0xb209,\n  'blake2b-80': 0xb20a,\n  'blake2b-88': 0xb20b,\n  'blake2b-96': 0xb20c,\n  'blake2b-104': 0xb20d,\n  'blake2b-112': 0xb20e,\n  'blake2b-120': 0xb20f,\n  'blake2b-128': 0xb210,\n  'blake2b-136': 0xb211,\n  'blake2b-144': 0xb212,\n  'blake2b-152': 0xb213,\n  'blake2b-160': 0xb214,\n  'blake2b-168': 0xb215,\n  'blake2b-176': 0xb216,\n  'blake2b-184': 0xb217,\n  'blake2b-192': 0xb218,\n  'blake2b-200': 0xb219,\n  'blake2b-208': 0xb21a,\n  'blake2b-216': 0xb21b,\n  'blake2b-224': 0xb21c,\n  'blake2b-232': 0xb21d,\n  'blake2b-240': 0xb21e,\n  'blake2b-248': 0xb21f,\n  'blake2b-256': 0xb220,\n  'blake2b-264': 0xb221,\n  'blake2b-272': 0xb222,\n  'blake2b-280': 0xb223,\n  'blake2b-288': 0xb224,\n  'blake2b-296': 0xb225,\n  'blake2b-304': 0xb226,\n  'blake2b-312': 0xb227,\n  'blake2b-320': 0xb228,\n  'blake2b-328': 0xb229,\n  'blake2b-336': 0xb22a,\n  'blake2b-344': 0xb22b,\n  'blake2b-352': 0xb22c,\n  'blake2b-360': 0xb22d,\n  'blake2b-368': 0xb22e,\n  'blake2b-376': 0xb22f,\n  'blake2b-384': 0xb230,\n  'blake2b-392': 0xb231,\n  'blake2b-400': 0xb232,\n  'blake2b-408': 0xb233,\n  'blake2b-416': 0xb234,\n  'blake2b-424': 0xb235,\n  'blake2b-432': 0xb236,\n  'blake2b-440': 0xb237,\n  'blake2b-448': 0xb238,\n  'blake2b-456': 0xb239,\n  'blake2b-464': 0xb23a,\n  'blake2b-472': 0xb23b,\n  'blake2b-480': 0xb23c,\n  'blake2b-488': 0xb23d,\n  'blake2b-496': 0xb23e,\n  'blake2b-504': 0xb23f,\n  'blake2b-512': 0xb240,\n  'blake2s-8': 0xb241,\n  'blake2s-16': 0xb242,\n  'blake2s-24': 0xb243,\n  'blake2s-32': 0xb244,\n  'blake2s-40': 0xb245,\n  'blake2s-48': 0xb246,\n  'blake2s-56': 0xb247,\n  'blake2s-64': 0xb248,\n  'blake2s-72': 0xb249,\n  'blake2s-80': 0xb24a,\n  'blake2s-88': 0xb24b,\n  'blake2s-96': 0xb24c,\n  'blake2s-104': 0xb24d,\n  'blake2s-112': 0xb24e,\n  'blake2s-120': 0xb24f,\n  'blake2s-128': 0xb250,\n  'blake2s-136': 0xb251,\n  'blake2s-144': 0xb252,\n  'blake2s-152': 0xb253,\n  'blake2s-160': 0xb254,\n  'blake2s-168': 0xb255,\n  'blake2s-176': 0xb256,\n  'blake2s-184': 0xb257,\n  'blake2s-192': 0xb258,\n  'blake2s-200': 0xb259,\n  'blake2s-208': 0xb25a,\n  'blake2s-216': 0xb25b,\n  'blake2s-224': 0xb25c,\n  'blake2s-232': 0xb25d,\n  'blake2s-240': 0xb25e,\n  'blake2s-248': 0xb25f,\n  'blake2s-256': 0xb260,\n  'skein256-8': 0xb301,\n  'skein256-16': 0xb302,\n  'skein256-24': 0xb303,\n  'skein256-32': 0xb304,\n  'skein256-40': 0xb305,\n  'skein256-48': 0xb306,\n  'skein256-56': 0xb307,\n  'skein256-64': 0xb308,\n  'skein256-72': 0xb309,\n  'skein256-80': 0xb30a,\n  'skein256-88': 0xb30b,\n  'skein256-96': 0xb30c,\n  'skein256-104': 0xb30d,\n  'skein256-112': 0xb30e,\n  'skein256-120': 0xb30f,\n  'skein256-128': 0xb310,\n  'skein256-136': 0xb311,\n  'skein256-144': 0xb312,\n  'skein256-152': 0xb313,\n  'skein256-160': 0xb314,\n  'skein256-168': 0xb315,\n  'skein256-176': 0xb316,\n  'skein256-184': 0xb317,\n  'skein256-192': 0xb318,\n  'skein256-200': 0xb319,\n  'skein256-208': 0xb31a,\n  'skein256-216': 0xb31b,\n  'skein256-224': 0xb31c,\n  'skein256-232': 0xb31d,\n  'skein256-240': 0xb31e,\n  'skein256-248': 0xb31f,\n  'skein256-256': 0xb320,\n  'skein512-8': 0xb321,\n  'skein512-16': 0xb322,\n  'skein512-24': 0xb323,\n  'skein512-32': 0xb324,\n  'skein512-40': 0xb325,\n  'skein512-48': 0xb326,\n  'skein512-56': 0xb327,\n  'skein512-64': 0xb328,\n  'skein512-72': 0xb329,\n  'skein512-80': 0xb32a,\n  'skein512-88': 0xb32b,\n  'skein512-96': 0xb32c,\n  'skein512-104': 0xb32d,\n  'skein512-112': 0xb32e,\n  'skein512-120': 0xb32f,\n  'skein512-128': 0xb330,\n  'skein512-136': 0xb331,\n  'skein512-144': 0xb332,\n  'skein512-152': 0xb333,\n  'skein512-160': 0xb334,\n  'skein512-168': 0xb335,\n  'skein512-176': 0xb336,\n  'skein512-184': 0xb337,\n  'skein512-192': 0xb338,\n  'skein512-200': 0xb339,\n  'skein512-208': 0xb33a,\n  'skein512-216': 0xb33b,\n  'skein512-224': 0xb33c,\n  'skein512-232': 0xb33d,\n  'skein512-240': 0xb33e,\n  'skein512-248': 0xb33f,\n  'skein512-256': 0xb340,\n  'skein512-264': 0xb341,\n  'skein512-272': 0xb342,\n  'skein512-280': 0xb343,\n  'skein512-288': 0xb344,\n  'skein512-296': 0xb345,\n  'skein512-304': 0xb346,\n  'skein512-312': 0xb347,\n  'skein512-320': 0xb348,\n  'skein512-328': 0xb349,\n  'skein512-336': 0xb34a,\n  'skein512-344': 0xb34b,\n  'skein512-352': 0xb34c,\n  'skein512-360': 0xb34d,\n  'skein512-368': 0xb34e,\n  'skein512-376': 0xb34f,\n  'skein512-384': 0xb350,\n  'skein512-392': 0xb351,\n  'skein512-400': 0xb352,\n  'skein512-408': 0xb353,\n  'skein512-416': 0xb354,\n  'skein512-424': 0xb355,\n  'skein512-432': 0xb356,\n  'skein512-440': 0xb357,\n  'skein512-448': 0xb358,\n  'skein512-456': 0xb359,\n  'skein512-464': 0xb35a,\n  'skein512-472': 0xb35b,\n  'skein512-480': 0xb35c,\n  'skein512-488': 0xb35d,\n  'skein512-496': 0xb35e,\n  'skein512-504': 0xb35f,\n  'skein512-512': 0xb360,\n  'skein1024-8': 0xb361,\n  'skein1024-16': 0xb362,\n  'skein1024-24': 0xb363,\n  'skein1024-32': 0xb364,\n  'skein1024-40': 0xb365,\n  'skein1024-48': 0xb366,\n  'skein1024-56': 0xb367,\n  'skein1024-64': 0xb368,\n  'skein1024-72': 0xb369,\n  'skein1024-80': 0xb36a,\n  'skein1024-88': 0xb36b,\n  'skein1024-96': 0xb36c,\n  'skein1024-104': 0xb36d,\n  'skein1024-112': 0xb36e,\n  'skein1024-120': 0xb36f,\n  'skein1024-128': 0xb370,\n  'skein1024-136': 0xb371,\n  'skein1024-144': 0xb372,\n  'skein1024-152': 0xb373,\n  'skein1024-160': 0xb374,\n  'skein1024-168': 0xb375,\n  'skein1024-176': 0xb376,\n  'skein1024-184': 0xb377,\n  'skein1024-192': 0xb378,\n  'skein1024-200': 0xb379,\n  'skein1024-208': 0xb37a,\n  'skein1024-216': 0xb37b,\n  'skein1024-224': 0xb37c,\n  'skein1024-232': 0xb37d,\n  'skein1024-240': 0xb37e,\n  'skein1024-248': 0xb37f,\n  'skein1024-256': 0xb380,\n  'skein1024-264': 0xb381,\n  'skein1024-272': 0xb382,\n  'skein1024-280': 0xb383,\n  'skein1024-288': 0xb384,\n  'skein1024-296': 0xb385,\n  'skein1024-304': 0xb386,\n  'skein1024-312': 0xb387,\n  'skein1024-320': 0xb388,\n  'skein1024-328': 0xb389,\n  'skein1024-336': 0xb38a,\n  'skein1024-344': 0xb38b,\n  'skein1024-352': 0xb38c,\n  'skein1024-360': 0xb38d,\n  'skein1024-368': 0xb38e,\n  'skein1024-376': 0xb38f,\n  'skein1024-384': 0xb390,\n  'skein1024-392': 0xb391,\n  'skein1024-400': 0xb392,\n  'skein1024-408': 0xb393,\n  'skein1024-416': 0xb394,\n  'skein1024-424': 0xb395,\n  'skein1024-432': 0xb396,\n  'skein1024-440': 0xb397,\n  'skein1024-448': 0xb398,\n  'skein1024-456': 0xb399,\n  'skein1024-464': 0xb39a,\n  'skein1024-472': 0xb39b,\n  'skein1024-480': 0xb39c,\n  'skein1024-488': 0xb39d,\n  'skein1024-496': 0xb39e,\n  'skein1024-504': 0xb39f,\n  'skein1024-512': 0xb3a0,\n  'skein1024-520': 0xb3a1,\n  'skein1024-528': 0xb3a2,\n  'skein1024-536': 0xb3a3,\n  'skein1024-544': 0xb3a4,\n  'skein1024-552': 0xb3a5,\n  'skein1024-560': 0xb3a6,\n  'skein1024-568': 0xb3a7,\n  'skein1024-576': 0xb3a8,\n  'skein1024-584': 0xb3a9,\n  'skein1024-592': 0xb3aa,\n  'skein1024-600': 0xb3ab,\n  'skein1024-608': 0xb3ac,\n  'skein1024-616': 0xb3ad,\n  'skein1024-624': 0xb3ae,\n  'skein1024-632': 0xb3af,\n  'skein1024-640': 0xb3b0,\n  'skein1024-648': 0xb3b1,\n  'skein1024-656': 0xb3b2,\n  'skein1024-664': 0xb3b3,\n  'skein1024-672': 0xb3b4,\n  'skein1024-680': 0xb3b5,\n  'skein1024-688': 0xb3b6,\n  'skein1024-696': 0xb3b7,\n  'skein1024-704': 0xb3b8,\n  'skein1024-712': 0xb3b9,\n  'skein1024-720': 0xb3ba,\n  'skein1024-728': 0xb3bb,\n  'skein1024-736': 0xb3bc,\n  'skein1024-744': 0xb3bd,\n  'skein1024-752': 0xb3be,\n  'skein1024-760': 0xb3bf,\n  'skein1024-768': 0xb3c0,\n  'skein1024-776': 0xb3c1,\n  'skein1024-784': 0xb3c2,\n  'skein1024-792': 0xb3c3,\n  'skein1024-800': 0xb3c4,\n  'skein1024-808': 0xb3c5,\n  'skein1024-816': 0xb3c6,\n  'skein1024-824': 0xb3c7,\n  'skein1024-832': 0xb3c8,\n  'skein1024-840': 0xb3c9,\n  'skein1024-848': 0xb3ca,\n  'skein1024-856': 0xb3cb,\n  'skein1024-864': 0xb3cc,\n  'skein1024-872': 0xb3cd,\n  'skein1024-880': 0xb3ce,\n  'skein1024-888': 0xb3cf,\n  'skein1024-896': 0xb3d0,\n  'skein1024-904': 0xb3d1,\n  'skein1024-912': 0xb3d2,\n  'skein1024-920': 0xb3d3,\n  'skein1024-928': 0xb3d4,\n  'skein1024-936': 0xb3d5,\n  'skein1024-944': 0xb3d6,\n  'skein1024-952': 0xb3d7,\n  'skein1024-960': 0xb3d8,\n  'skein1024-968': 0xb3d9,\n  'skein1024-976': 0xb3da,\n  'skein1024-984': 0xb3db,\n  'skein1024-992': 0xb3dc,\n  'skein1024-1000': 0xb3dd,\n  'skein1024-1008': 0xb3de,\n  'skein1024-1016': 0xb3df,\n  'skein1024-1024': 0xb3e0,\n  'poseidon-bls12_381-a2-fc1': 0xb401,\n  'poseidon-bls12_381-a2-fc1-sc': 0xb402,\n  'zeroxcert-imprint-256': 0xce11,\n  'fil-commitment-unsealed': 0xf101,\n  'fil-commitment-sealed': 0xf102,\n  'holochain-adr-v0': 0x807124,\n  'holochain-adr-v1': 0x817124,\n  'holochain-key-v0': 0x947124,\n  'holochain-key-v1': 0x957124,\n  'holochain-sig-v0': 0xa27124,\n  'holochain-sig-v1': 0xa37124,\n  'skynet-ns': 0xb19910\n})\n\nmodule.exports = { baseTable }\n","'use strict'\n\n/** @typedef {import('./generated-types').ConstantNumberMap} ConstantNumberMap */\n\nconst { baseTable } = require('./base-table')\n\nconst constants = /** @type {ConstantNumberMap} */({})\n\nfor (const [name, code] of Object.entries(baseTable)) {\n  const constant = name.toUpperCase().replace(/-/g, '_')\n  constants[constant] = code\n}\n\nmodule.exports = Object.freeze(constants)\n","/**\n * Implementation of the multicodec specification.\n *\n * @module multicodec\n * @example\n * const multicodec = require('multicodec')\n *\n * const prefixedProtobuf = multicodec.addPrefix('protobuf', protobufBuffer)\n * // prefixedProtobuf 0x50...\n *\n */\n'use strict'\n\n/** @typedef {import('./generated-types').CodecName} CodecName */\n/** @typedef {import('./generated-types').CodecNumber} CodecNumber */\n\nconst varint = require('varint')\nconst intTable = require('./int-table')\nconst codecNameToCodeVarint = require('./varint-table')\nconst util = require('./util')\nconst uint8ArrayConcat = require('uint8arrays/concat')\n\n/**\n * Prefix a buffer with a multicodec-packed.\n *\n * @param {CodecName|Uint8Array} multicodecStrOrCode\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction addPrefix (multicodecStrOrCode, data) {\n  let prefix\n\n  if (multicodecStrOrCode instanceof Uint8Array) {\n    prefix = util.varintUint8ArrayEncode(multicodecStrOrCode)\n  } else {\n    if (codecNameToCodeVarint[multicodecStrOrCode]) {\n      prefix = codecNameToCodeVarint[multicodecStrOrCode]\n    } else {\n      throw new Error('multicodec not recognized')\n    }\n  }\n  return uint8ArrayConcat([prefix, data], prefix.length + data.length)\n}\n\n/**\n * Decapsulate the multicodec-packed prefix from the data.\n *\n * @param {Uint8Array} data\n * @returns {Uint8Array}\n */\nfunction rmPrefix (data) {\n  varint.decode(data)\n  return data.slice(varint.decode.bytes)\n}\n\n/**\n * Get the codec of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecName}\n */\nfunction getCodec (prefixedData) {\n  const code = varint.decode(prefixedData)\n  const codecName = intTable.get(code)\n  if (codecName === undefined) {\n    throw new Error(`Code ${code} not found`)\n  }\n  return codecName\n}\n\n/**\n * Get the name of the codec.\n *\n * @param {CodecNumber} codec\n * @returns {CodecName|undefined}\n */\nfunction getName (codec) {\n  return intTable.get(codec)\n}\n\n/**\n * Get the code of the codec\n *\n * @param {CodecName} name\n * @returns {CodecNumber}\n */\nfunction getNumber (name) {\n  const code = codecNameToCodeVarint[name]\n  if (code === undefined) {\n    throw new Error('Codec `' + name + '` not found')\n  }\n  return varint.decode(code)\n}\n\n/**\n * Get the code of the prefixed data.\n *\n * @param {Uint8Array} prefixedData\n * @returns {CodecNumber}\n */\nfunction getCode (prefixedData) {\n  return varint.decode(prefixedData)\n}\n\n/**\n * Get the code as varint of a codec name.\n *\n * @param {CodecName} codecName\n * @returns {Uint8Array}\n */\nfunction getCodeVarint (codecName) {\n  const code = codecNameToCodeVarint[codecName]\n  if (code === undefined) {\n    throw new Error('Codec `' + codecName + '` not found')\n  }\n  return code\n}\n\n/**\n * Get the varint of a code.\n *\n * @param {CodecNumber} code\n * @returns {Array.<number>}\n */\nfunction getVarint (code) {\n  return varint.encode(code)\n}\n\n// Make the constants top-level constants\nconst constants = require('./constants')\n\n// Human friendly names for printing, e.g. in error messages\nconst print = require('./print')\n\nmodule.exports = {\n  addPrefix,\n  rmPrefix,\n  getCodec,\n  getName,\n  getNumber,\n  getCode,\