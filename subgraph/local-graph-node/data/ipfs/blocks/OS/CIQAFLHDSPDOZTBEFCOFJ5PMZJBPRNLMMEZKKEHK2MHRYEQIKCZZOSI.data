n\n  /**\n   * Returns all the paths that can be resolved into.\n   *\n   * @param {CID} cid - The ID to get the paths from\n   * @param {string} [offsetPath=''] - the path to start to retrieve the other paths from.\n   * @param {TreeOptions} [userOptions]\n   */\n  tree (cid, offsetPath, userOptions) {\n    if (typeof offsetPath === 'object') {\n      userOptions = offsetPath\n      offsetPath = undefined\n    }\n    offsetPath = offsetPath || ''\n\n    const defaultOptions = {\n      recursive: false\n    }\n    const options = mergeOptions(defaultOptions, userOptions)\n\n    /**\n     * If a path is a link then follow it and return its CID\n     *\n     * @param {Block} block\n     * @param {string} treePath\n     */\n    const maybeRecurse = async (block, treePath) => {\n      // A treepath we might want to follow recursively\n      const format = await this.getFormat(multicodec.getCodeFromName(block.cid.codec))\n      const result = format.resolver.resolve(block.data, treePath)\n      // Something to follow recursively, hence push it into the queue\n      if (CID.isCID(result.value)) {\n        return result.value\n      }\n    }\n\n    const ipld = this\n\n    const generator = async function * () {\n      // The list of paths that will get returned\n      const treePaths = []\n      // The current block, needed to call `isLink()` on every iteration\n      let block\n      // The list of items we want to follow recursively. The items are\n      // an object consisting of the CID and the currently already resolved\n      // path\n      const queue = [{ cid, basePath: '' }]\n      // The path that was already traversed\n      let basePath\n\n      // End of iteration if there aren't any paths left to return or\n      // if we don't want to traverse recursively and have already\n      // returns the first level\n      while (treePaths.length > 0 || queue.length > 0) {\n        // There aren't any paths left, get them from the given CID\n        if (treePaths.length === 0 && queue.length > 0) {\n          const next = queue.shift()\n\n          if (next) {\n            ({ cid, basePath } = next)\n            const format = await ipld.getFormat(multicodec.getCodeFromName(cid.codec))\n            block = await ipld.bs.get(cid, options)\n\n            const paths = format.resolver.tree(block.data)\n            treePaths.push(...paths)\n          }\n        }\n\n        const treePath = treePaths.shift() || ''\n        let fullPath = basePath + treePath\n\n        // Only follow links if recursion is intended\n        if (options.recursive) {\n          const cid = await maybeRecurse(block, treePath)\n\n          if (cid != null) {\n            queue.push({ cid, basePath: fullPath + '/' })\n          }\n        }\n\n        // Return it if it matches the given offset path, but is not the\n        // offset path itself\n        if (offsetPath !== undefined && fullPath.startsWith(offsetPath) &&\n            fullPath.length > offsetPath.length) {\n          if (offsetPath.length > 0) {\n            fullPath = fullPath.slice(offsetPath.length + 1)\n          }\n\n          yield fullPath\n        }\n      }\n    }\n\n    return extendIterator(generator())\n  }\n\n  /**\n   * @param {CodecCode} codec\n   */\n  async getFormat (codec) {\n    // TODO vmx 2019-01-24: Once all CIDs support accessing the codec code\n    // instead of the name, remove this part\n    if (typeof codec === 'string') {\n      codec = multicodec.getCodeFromName(codec)\n    }\n\n    if (this.resolvers[codec]) {\n      return this.resolvers[codec]\n    }\n\n    // If not supported, attempt to dynamically load this format\n    const format = await this.loadFormat(codec)\n    this.addFormat(format)\n    return format\n  }\n}\n\n/**\n * Default options for IPLD.\n */\nIPLDResolver.defaultOptions = {\n  /** @type {IPLDFormat[]} */\n  formats: [ipldDagCbor, ipldDagPb, ipldRaw]\n}\n\nmodule.exports = IPLDResolver\n","'use strict'\n\n/**\n * @template T\n *\n * @param {AsyncIterable<T>} iterator\n */\nexports.first = async (iterator) => {\n  for await (const value of iterator) { // eslint-disable-line no-unreachable-loop\n    return value\n  }\n}\n\n/**\n * @template T\n *\n * @param {AsyncIterable<T>} iterator\n */\nexports.last = async (iterator) => {\n  let value\n  for await (value of iterator) {\n    // Intentionally empty\n  }\n  return value\n}\n\n/**\n * @template T\n *\n * @param {AsyncIterable<T>} iterator\n */\nexports.all = async (iterator) => {\n  const values = []\n  for await (const value of iterator) {\n    values.push(value)\n  }\n  return values\n}\n\n/**\n * @template T\n *\n * @typedef {object} Extensions\n * @property {() => Promise<T | undefined>} first\n * @property {() => Promise<T | undefined>} last\n * @property {() => Promise<T[]>} all\n */\n\n/**\n * @template T\n *\n * @param {any} iterator\n * @returns {AsyncIterable<T> & Extensions<T> }\n */\nexports.extendIterator = (iterator) => {\n  iterator.first = () => exports.first(iterator)\n  iterator.last = () => exports.last(iterator)\n  iterator.all = () => exports.all(iterator)\n  return iterator\n}\n","/**\n * Returns a `Boolean` on whether or not the a `String` starts with '0x'\n * @param {String} str the string input value\n * @return {Boolean} a boolean if it is or is not hex prefixed\n * @throws if the str input is not a string\n */\nmodule.exports = function isHexPrefixed(str) {\n  if (typeof str !== 'string') {\n    throw new Error(\"[is-hex-prefixed] value must be type 'string', is currently type \" + (typeof str) + \", while checking isHexPrefixed.\");\n  }\n\n  return str.slice(0, 2) === '0x';\n}\n","'use strict';\n\n/* http://www.ecma-international.org/ecma-262/6.0/#sec-number.isnan */\n\nmodule.exports = function isNaN(value) {\n\treturn value !== value;\n};\n","'use strict';\n\nvar callBind = require('call-bind');\nvar define = require('define-properties');\n\nvar implementation = require('./implementation');\nvar getPolyfill = require('./polyfill');\nvar shim = require('./shim');\n\nvar polyfill = callBind(getPolyfill(), Number);\n\n/* http://www.ecma-international.org/ecma-262/6.0/#sec-number.isnan */\n\ndefine(polyfill, {\n\tgetPolyfill: getPolyfill,\n\timplementation: implementation,\n\tshim: shim\n});\n\nmodule.exports = polyfill;\n","'use strict';\n\nvar implementation = require('./implementation');\n\nmodule.exports = function getPolyfill() {\n\tif (Number.isNaN && Number.isNaN(NaN) && !Number.isNaN('a')) {\n\t\treturn Number.isNaN;\n\t}\n\treturn implementation;\n};\n","'use strict';\n\nvar define = require('define-properties');\nvar getPolyfill = require('./polyfill');\n\n/* http://www.ecma-international.org/ecma-262/6.0/#sec-number.isnan */\n\nmodule.exports = function shimNumberIsNaN() {\n\tvar polyfill = getPolyfill();\n\tdefine(Number, { isNaN: polyfill }, {\n\t\tisNaN: function testIsNaN() {\n\t\t\treturn Number.isNaN !== polyfill;\n\t\t}\n\t});\n\treturn polyfill;\n};\n","module.exports = require('./lib/api')(require('./lib/keccak'))\n","const createKeccak = require('./keccak')\nconst createShake = require('./shake')\n\nmodule.exports = function (KeccakState) {\n  const Keccak = createKeccak(KeccakState)\n  const Shake = createShake(KeccakState)\n\n  return function (algorithm, options) {\n    const hash = typeof algorithm === 'string' ? algorithm.toLowerCase() : algorithm\n    switch (hash) {\n      case 'keccak224': return new Keccak(1152, 448, null, 224, options)\n      case 'keccak256': return new Keccak(1088, 512, null, 256, options)\n      case 'keccak384': return new Keccak(832, 768, null, 384, options)\n      case 'keccak512': return new Keccak(576, 1024, null, 512, options)\n\n      case 'sha3-224': return new Keccak(1152, 448, 0x06, 224, options)\n      case 'sha3-256': return new Keccak(1088, 512, 0x06, 256, options)\n      case 'sha3-384': return new Keccak(832, 768, 0x06, 384, options)\n      case 'sha3-512': return new Keccak(576, 1024, 0x06, 512, options)\n\n      case 'shake128': return new Shake(1344, 256, 0x1f, options)\n      case 'shake256': return new Shake(1088, 512, 0x1f, options)\n\n      default: throw new Error('Invald algorithm: ' + algorithm)\n    }\n  }\n}\n","const { Transform } = require('stream')\n\nmodule.exports = (KeccakState) => class Keccak extends Transform {\n  constructor (rate, capacity, delimitedSuffix, hashBitLength, options) {\n    super(options)\n\n    this._rate = rate\n    this._capacity = capacity\n    this._delimitedSuffix = delimitedSuffix\n    this._hashBitLength = hashBitLength\n    this._options = options\n\n    this._state = new KeccakState()\n    this._state.initialize(rate, capacity)\n    this._finalized = false\n  }\n\n  _transform (chunk, encoding, callback) {\n    let error = null\n    try {\n      this.update(chunk, encoding)\n    } catch (err) {\n      error = err\n    }\n\n    callback(error)\n  }\n\n  _flush (callback) {\n    let error = null\n    try {\n      this.push(this.digest())\n    } catch (err) {\n      error = err\n    }\n\n    callback(error)\n  }\n\n  update (data, encoding) {\n    if (!Buffer.isBuffer(data) && typeof data !== 'string') throw new TypeError('Data must be a string or a buffer')\n    if (this._finalized) throw new Error('Digest already called')\n    if (!Buffer.isBuffer(data)) data = Buffer.from(data, encoding)\n\n    this._state.absorb(data)\n\n    return this\n  }\n\n  digest (encoding) {\n    if (this._finalized) throw new Error('Digest already called')\n    this._finalized = true\n\n    if (this._delimitedSuffix) this._state.absorbLastFewBits(this._delimitedSuffix)\n    let digest = this._state.squeeze(this._hashBitLength / 8)\n    if (encoding !== undefined) digest = digest.toString(encoding)\n\n    this._resetState()\n\n    return digest\n  }\n\n  // remove result from memory\n  _resetState () {\n    this._state.initialize(this._rate, this._capacity)\n    return this\n  }\n\n  // because sometimes we need hash right now and little later\n  _clone () {\n    const clone = new Keccak(this._rate, this._capacity, this._delimitedSuffix, this._hashBitLength, this._options)\n    this._state.copy(clone._state)\n    clone._finalized = this._finalized\n\n    return clone\n  }\n}\n","const { Transform } = require('stream')\n\nmodule.exports = (KeccakState) => class Shake extends Transform {\n  constructor (rate, capacity, delimitedSuffix, options) {\n    super(options)\n\n    this._rate = rate\n    this._capacity = capacity\n    this._delimitedSuffix = delimitedSuffix\n    this._options = options\n\n    this._state = new KeccakState()\n    this._state.initialize(rate, capacity)\n    this._finalized = false\n  }\n\n  _transform (chunk, encoding, callback) {\n    let error = null\n    try {\n      this.update(chunk, encoding)\n    } catch (err) {\n      error = err\n    }\n\n    callback(error)\n  }\n\n  _flush () {}\n\n  _read (size) {\n    this.push(this.squeeze(size))\n  }\n\n  update (data, encoding) {\n    if (!Buffer.isBuffer(data) && typeof data !== 'string') throw new TypeError('Data must be a string or a buffer')\n    if (this._finalized) throw new Error('Squeeze already called')\n    if (!Buffer.isBuffer(data)) data = Buffer.from(data, encoding)\n\n    this._state.absorb(data)\n\n    return this\n  }\n\n  squeeze (dataByteLength, encoding) {\n    if (!this._finalized) {\n      this._finalized = true\n      this._state.absorbLastFewBits(this._delimitedSuffix)\n    }\n\n    let data = this._state.squeeze(dataByteLength)\n    if (encoding !== undefined) data = data.toString(encoding)\n\n    return data\n  }\n\n  _resetState () {\n    this._state.initialize(this._rate, this._capacity)\n    return this\n  }\n\n  _clone () {\n    const clone = new Shake(this._rate, this._capacity, this._delimitedSuffix, this._options)\n    this._state.copy(clone._state)\n    clone._finalized = this._finalized\n\n    return clone\n  }\n}\n","const P1600_ROUND_CONSTANTS = [1, 0, 32898, 0, 32906, 2147483648, 2147516416, 2147483648, 32907, 0, 2147483649, 0, 2147516545, 2147483648, 32777, 2147483648, 138, 0, 136, 0, 2147516425, 0, 2147483658, 0, 2147516555, 0, 139, 2147483648, 32905, 2147483648, 32771, 2147483648, 32770, 2147483648, 128, 2147483648, 32778, 0, 2147483658, 2147483648, 2147516545, 2147483648, 32896, 2147483648, 2147483649, 0, 2147516424, 2147483648]\n\nexports.p1600 = function (s) {\n  for (let round = 0; round < 24; ++round) {\n    // theta\n    const lo0 = s[0] ^ s[10] ^ s[20] ^ s[30] ^ s[40]\n    const hi0 = s[1] ^ s[11] ^ s[21] ^ s[31] ^ s[41]\n    const lo1 = s[2] ^ s[12] ^ s[22] ^ s[32] ^ s[42]\n    const hi1 = s[3] ^ s[13] ^ s[23] ^ s[33] ^ s[43]\n    const lo2 = s[4] ^ s[14] ^ s[24] ^ s[34] ^ s[44]\n    const hi2 = s[5] ^ s[15] ^ s[25] ^ s[35] ^ s[45]\n    const lo3 = s[6] ^ s[16] ^ s[26] ^ s[36] ^ s[46]\n    const hi3 = s[7] ^ s[17] ^ s[27] ^ s[37] ^ s[47]\n    const lo4 = s[8] ^ s[18] ^ s[28] ^ s[38] ^ s[48]\n    const hi4 = s[9] ^ s[19] ^ s[29] ^ s[39] ^ s[49]\n\n    let lo = lo4 ^ (lo1 << 1 | hi1 >>> 31)\n    let hi = hi4 ^ (hi1 << 1 | lo1 >>> 31)\n    const t1slo0 = s[0] ^ lo\n    const t1shi0 = s[1] ^ hi\n    const t1slo5 = s[10] ^ lo\n    const t1shi5 = s[11] ^ hi\n    const t1slo10 = s[20] ^ lo\n    const t1shi10 = s[21] ^ hi\n    const t1slo15 = s[30] ^ lo\n    const t1shi15 = s[31] ^ hi\n    const t1slo20 = s[40] ^ lo\n    const t1shi20 = s[41] ^ hi\n    lo = lo0 ^ (lo2 << 1 | hi2 >>> 31)\n    hi = hi0 ^ (hi2 << 1 | lo2 >>> 31)\n    const t1slo1 = s[2] ^ lo\n    const t1shi1 = s[3] ^ hi\n    const t1slo6 = s[12] ^ lo\n    const t1shi6 = s[13] ^ hi\n    const t1slo11 = s[22] ^ lo\n    const t1shi11 = s[23] ^ hi\n    const t1slo16 = s[32] ^ lo\n    const t1shi16 = s[33] ^ hi\n    const t1slo21 = s[42] ^ lo\n    const t1shi21 = s[43] ^ hi\n    lo = lo1 ^ (lo3 << 1 | hi3 >>> 31)\n    hi = hi1 ^ (hi3 << 1 | lo3 >>> 31)\n    const t1slo2 = s[4] ^ lo\n    const t1shi2 = s[5] ^ hi\n    const t1slo7 = s[14] ^ lo\n    const t1shi7 = s[15] ^ hi\n    const t1slo12 = s[24] ^ lo\n    const t1shi12 = s[25] ^ hi\n    const t1slo17 = s[34] ^ lo\n    const t1shi17 = s[35] ^ hi\n    const t1slo22 = s[44] ^ lo\n    const t1shi22 = s[45] ^ hi\n    lo = lo2 ^ (lo4 << 1 | hi4 >>> 31)\n    hi = hi2 ^ (hi4 << 1 | lo4 >>> 31)\n    const t1slo3 = s[6] ^ lo\n    const t1shi3 = s[7] ^ hi\n    const t1slo8 = s[16] ^ lo\n    const t1shi8 = s[17] ^ hi\n    const t1slo13 = s[26] ^ lo\n    const t1shi13 = s[27] ^ hi\n    const t1slo18 = s[36] ^ lo\n    const t1shi18 = s[37] ^ hi\n    const t1slo23 = s[46] ^ lo\n    const t1shi23 = s[47] ^ hi\n    lo = lo3 ^ (lo0 << 1 | hi0 >>> 31)\n    hi = hi3 ^ (hi0 << 1 | lo0 >>> 31)\n    const t1slo4 = s[8] ^ lo\n    const t1shi4 = s[9] ^ hi\n    const t1slo9 = s[18] ^ lo\n    const t1shi9 = s[19] ^ hi\n    const t1slo14 = s[28] ^ lo\n    const t1shi14 = s[29] ^ hi\n    const t1slo19 = s[38] ^ lo\n    const t1shi19 = s[39] ^ hi\n    const t1slo24 = s[48] ^ lo\n    const t1shi24 = s[49] ^ hi\n\n    // rho & pi\n    const t2slo0 = t1slo0\n    const t2shi0 = t1shi0\n    const t2slo16 = (t1shi5 << 4 | t1slo5 >>> 28)\n    const t2shi16 = (t1slo5 << 4 | t1shi5 >>> 28)\n    const t2slo7 = (t1slo10 << 3 | t1shi10 >>> 29)\n    const t2shi7 = (t1shi10 << 3 | t1slo10 >>> 29)\n    const t2slo23 = (t1shi15 << 9 | t1slo15 >>> 23)\n    const t2shi23 = (t1slo15 << 9 | t1shi15 >>> 23)\n    const t2slo14 = (t1slo20 << 18 | t1shi20 >>> 14)\n    const t2shi14 = (t1shi20 << 18 | t1slo20 >>> 14)\n    const t2slo10 = (t1slo1 << 1 | t1shi1 >>> 31)\n    const t2shi10 = (t1shi1 << 1 | t1slo1 >>> 31)\n    const t2slo1 = (t1shi6 << 12 | t1slo6 >>> 20)\n    const t2shi1 = (t1slo6 << 12 | t1shi6 >>> 20)\n    const t2slo17 = (t1slo11 << 10 | t1shi11 >>> 22)\n    const t2shi17 = (t1shi11 << 10 | t1slo11 >>> 22)\n    const t2slo8 = (t1shi16 << 13 | t1slo16 >>> 19)\n    const t2shi8 = (t1slo16 << 13 | t1shi16 >>> 19)\n    const t2slo24 = (t1slo21 << 2 | t1shi21 >>> 30)\n    const t2shi24 = (t1shi21 << 2 | t1slo21 >>> 30)\n    const t2slo20 = (t1shi2 << 30 | t1slo2 >>> 2)\n    const t2shi20 = (t1slo2 << 30 | t1shi2 >>> 2)\n    const t2slo11 = (t1slo7 << 6 | t1shi7 >>> 26)\n    const t2shi11 = (t1shi7 << 6 | t1slo7 >>> 26)\n    const t2slo2 = (t1shi12 << 11 | t1slo12 >>> 21)\n    const t2shi2 = (t1slo12 << 11 | t1shi12 >>> 21)\n    const t2slo18 = (t1slo17 << 15 | t1shi17 >>> 17)\n    const t2shi18 = (t1shi17 << 15 | t1slo17 >>> 17)\n    const t2slo9 = (t1shi22 << 29 | t1slo22 >>> 3)\n    const t2shi9 = (t1slo22 << 29 | t1shi22 >>> 3)\n    const t2slo5 = (t1slo3 << 28 | t1shi3 >>> 4)\n    const t2shi5 = (t1shi3 << 28 | t1slo3 >>> 4)\n    const t2slo21 = (t1shi8 << 23 | t1slo8 >>> 9)\n    const t2shi21 = (t1slo8 << 23 | t1shi8 >>> 9)\n    const t2slo12 = (t1slo13 << 25 | t1shi13 >>> 7)\n    const t2shi12 = (t1shi13 << 25 | t1slo13 >>> 7)\n    const t2slo3 = (t1slo18 << 21 | t1shi18 >>> 11)\n    const t2shi3 = (t1shi18 << 21 | t1slo18 >>> 11)\n    const t2slo19 = (t1shi23 << 24 | t1slo23 >>> 8)\n    const t2shi19 = (t1slo23 << 24 | t1shi23 >>> 8)\n    const t2slo15 = (t1slo4 << 27 | t1shi4 >>> 5)\n    const t2shi15 = (t1shi4 << 27 | t1slo4 >>> 5)\n    const t2slo6 = (t1slo9 << 20 | t1shi9 >>> 12)\n    const t2shi6 = (t1shi9 << 20 | t1slo9 >>> 12)\n    const t2slo22 = (t1shi14 << 7 | t1slo14 >>> 25)\n    const t2shi22 = (t1slo14 << 7 | t1shi14 >>> 25)\n    const t2slo13 = (t1slo19 << 8 | t1shi19 >>> 24)\n    const t2shi13 = (t1shi19 << 8 | t1slo19 >>> 24)\n    const t2slo4 = (t1slo24 << 14 | t1shi24 >>> 18)\n    const t2shi4 = (t1shi24 << 14 | t1slo24 >>> 18)\n\n    // chi\n    s[0] = t2slo0 ^ (~t2slo1 & t2slo2)\n    s[1] = t2shi0 ^ (~t2shi1 & t2shi2)\n    s[10] = t2slo5 ^ (~t2slo6 & t2slo7)\n    s[11] = t2shi5 ^ (~t2shi6 & t2shi7)\n    s[20] = t2slo10 ^ (~t2slo11 & t2slo12)\n    s[21] = t2shi10 ^ (~t2shi11 & t2shi12)\n    s[30] = t2slo15 ^ (~t2slo16 & t2slo17)\n    s[31] = t2shi15 ^ (~t2shi16 & t2shi17)\n    s[40] = t2slo20 ^ (~t2slo21 & t2slo22)\n    s[41] = t2shi20 ^ (~t2shi21 & t2shi22)\n    s[2] = t2slo1 ^ (~t2slo2 & t2slo3)\n    s[3] = t2shi1 ^ (~t2shi2 & t2shi3)\n    s[12] = t2slo6 ^ (~t2slo7 & t2slo8)\n    s[13] = t2shi6 ^ (~t2shi7 & t2shi8)\n    s[22] = t2slo11 ^ (~t2slo12 & t2slo13)\n    s[23] = t2shi11 ^ (~t2shi12 & t2shi13)\n    s[32] = t2slo16 ^ (~t2slo17 & t2slo18)\n    s[33] = t2shi16 ^ (~t2shi17 & t2shi18)\n    s[42] = t2slo21 ^ (~t2slo22 & t2slo23)\n    s[43] = t2shi21 ^ (~t2shi22 & t2shi23)\n    s[4] = t2slo2 ^ (~t2slo3 & t2slo4)\n    s[5] = t2shi2 ^ (~t2shi3 & t2shi4)\n    s[14] = t2slo7 ^ (~t2slo8 & t2slo9)\n    s[15] = t2shi7 ^ (~t2shi8 & t2shi9)\n    s[24] = t2slo12 ^ (~t2slo13 & t2slo14)\n    s[25] = t2shi12 ^ (~t2shi13 & t2shi14)\n    s[34] = t2slo17 ^ (~t2slo18 & t2slo19)\n    s[35] = t2shi17 ^ (~t2shi18 & t2shi19)\n    s[44] = t2slo22 ^ (~t2slo23 & t2slo24)\n    s[45] = t2shi22 ^ (~t2shi23 & t2shi24)\n    s[6] = t2slo3 ^ (~t2slo4 & t2slo0)\n    s[7] = t2shi3 ^ (~t2shi4 & t2shi0)\n    s[16] = t2slo8 ^ (~t2slo9 & t2slo5)\n    s[17] = t2shi8 ^ (~t2shi9 & t2shi5)\n    s[26] = t2slo13 ^ (~t2slo14 & t2slo10)\n    s[27] = t2shi13 ^ (~t2shi14 & t2shi10)\n    s[36] = t2slo18 ^ (~t2slo19 & t2slo15)\n    s[37] = t2shi18 ^ (~t2shi19 & t2shi15)\n    s[46] = t2slo23 ^ (~t2slo24 & t2slo20)\n    s[47] = t2shi23 ^ (~t2shi24 & t2shi20)\n    s[8] = t2slo4 ^ (~t2slo0 & t2slo1)\n    s[9] = t2shi4 ^ (~t2shi0 & t2shi1)\n    s[18] = t2slo9 ^ (~t2slo5 & t2slo6)\n    s[19] = t2shi9 ^ (~t2shi5 & t2shi6)\n    s[28] = t2slo14 ^ (~t2slo10 & t2slo11)\n    s[29] = t2shi14 ^ (~t2shi10 & t2shi11)\n    s[38] = t2slo19 ^ (~t2slo15 & t2slo16)\n    s[39] = t2shi19 ^ (~t2shi15 & t2shi16)\n    s[48] = t2slo24 ^ (~t2slo20 & t2slo21)\n    s[49] = t2shi24 ^ (~t2shi20 & t2shi21)\n\n    // iota\n    s[0] ^= P1600_ROUND_CONSTANTS[round * 2]\n    s[1] ^= P1600_ROUND_CONSTANTS[round * 2 + 1]\n  }\n}\n","const keccakState = require('./keccak-state-unroll')\n\nfunction Keccak () {\n  // much faster than `new Array(50)`\n  this.state = [\n    0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0,\n    0, 0, 0, 0, 0\n  ]\n\n  this.blockSize = null\n  this.count = 0\n  this.squeezing = false\n}\n\nKeccak.prototype.initialize = function (rate, capacity) {\n  for (let i = 0; i < 50; ++i) this.state[i] = 0\n  this.blockSize = rate / 8\n  this.count = 0\n  this.squeezing = false\n}\n\nKeccak.prototype.absorb = function (data) {\n  for (let i = 0; i < data.length; ++i) {\n    this.state[~~(this.count / 4)] ^= data[i] << (8 * (this.count % 4))\n    this.count += 1\n    if (this.count === this.blockSize) {\n      keccakState.p1600(this.state)\n      this.count = 0\n    }\n  }\n}\n\nKeccak.prototype.absorbLastFewBits = function (bits) {\n  this.state[~~(this.count / 4)] ^= bits << (8 * (this.count % 4))\n  if ((bits & 0x80) !== 0 && this.count === (this.blockSize - 1)) keccakState.p1600(this.state)\n  this.state[~~((this.blockSize - 1) / 4)] ^= 0x80 << (8 * ((this.blockSize - 1) % 4))\n  keccakState.p1600(this.state)\n  this.count = 0\n  this.squeezing = true\n}\n\nKeccak.prototype.squeeze = function (length) {\n  if (!this.squeezing) this.absorbLastFewBits(0x01)\n\n  const output = Buffer.alloc(length)\n  for (let i = 0; i < length; ++i) {\n    output[i] = (this.state[~~(this.count / 4)] >>> (8 * (this.count % 4))) & 0xff\n    this.count += 1\n    if (this.count === this.blockSize) {\n      keccakState.p1600(this.state)\n      this.count = 0\n    }\n  }\n\n  return output\n}\n\nKeccak.prototype.copy = function (dest) {\n  for (let i = 0; i < 50; ++i) dest.state[i] = this.state[i]\n  dest.blockSize = this.blockSize\n  dest.count = this.count\n  dest.squeezing = this.squeezing\n}\n\nmodule.exports = Keccak\n","'use strict'\nvar inherits = require('inherits')\nvar HashBase = require('hash-base')\nvar Buffer = require('safe-buffer').Buffer\n\nvar ARRAY16 = new Array(16)\n\nfunction MD5 () {\n  HashBase.call(this, 64)\n\n  // state\n  this._a = 0x67452301\n  this._b = 0xefcdab89\n  this._c = 0x98badcfe\n  this._d = 0x10325476\n}\n\ninherits(MD5, HashBase)\n\nMD5.prototype._update = function () {\n  var M = ARRAY16\n  for (var i = 0; i < 16; ++i) M[i] = this._block.readInt32LE(i * 4)\n\n  var a = this._a\n  var b = this._b\n  var c = this._c\n  var d = this._d\n\n  a = fnF(a, b, c, d, M[0], 0xd76aa478, 7)\n  d = fnF(d, a, b, c, M[1], 0xe8c7b756, 12)\n  c = fnF(c, d, a, b, M[2], 0x242070db, 17)\n  b = fnF(b, c, d, a, M[3], 0xc1bdceee, 22)\n  a = fnF(a, b, c, d, M[4], 0xf57c0faf, 7)\n  d = fnF(d, a, b, c, M[5], 0x4787c62a, 12)\n  c = fnF(c, d, a, b, M[6], 0xa8304613, 17)\n  b = fnF(b, c, d, a, M[7], 0xfd469501, 22)\n  a = fnF(a, b, c, d, M[8], 0x698098d8, 7)\n  d = fnF(d, a, b, c, M[9], 0x8b44f7af, 12)\n  c = fnF(c, d, a, b, M[10], 0xffff5bb1, 17)\n  b = fnF(b, c, d, a, M[11], 0x895cd7be, 22)\n  a = fnF(a, b, c, d, M[12], 0x6b901122, 7)\n  d = fnF(d, a, b, c, M[13], 0xfd987193, 12)\n  c = fnF(c, d, a, b, M[14], 0xa679438e, 17)\n  b = fnF(b, c, d, a, M[15], 0x49b40821, 22)\n\n  a = fnG(a, b, c, d, M[1], 0xf61e2562, 5)\n  d = fnG(d, a, b, c, M[6], 0xc040b340, 9)\n  c = fnG(c, d, a, b, M[11], 0x265e5a51, 14)\n  b = fnG(b, c, d, a, M[0], 0xe9b6c7aa, 20)\n  a = fnG(a, b, c, d, M[5], 0xd62f105d, 5)\n  d = fnG(d, a, b, c, M[10], 0x02441453, 9)\n  c = fnG(c, d, a, b, M[15], 0xd8a1e681, 14)\n  b = fnG(b, c, d, a, M[4], 0xe7d3fbc8, 20)\n  a = fnG(a, b, c, d, M[9], 0x21e1cde6, 5)\n  d = fnG(d, a, b, c, M[14], 0xc33707d6, 9)\n  c = fnG(c, d, a, b, M[3], 0xf4d50d87, 14)\n  b = fnG(b, c, d, a, M[8], 0x455a14ed, 20)\n  a = fnG(a, b, c, d, M[13], 0xa9e3e905, 5)\n  d = fnG(d, a, b, c, M[2], 0xfcefa3f8, 9)\n  c = fnG(c, d, a, b, M[7], 0x676f02d9, 14)\n  b = fnG(b, c, d, a, M[12], 0x8d2a4c8a, 20)\n\n  a = fnH(a, b, c, d, M[5], 0xfffa3942, 4)\n  d = fnH(d, a, b, c, M[8], 0x8771f681, 11)\n  c = fnH(c, d, a, b, M[11], 0x6d9d6122, 16)\n  b = fnH(b, c, d, a, M[14], 0xfde5380c, 23)\n  a = fnH(a, b, c, d, M[1], 0xa4beea44, 4)\n  d = fnH(d, a, b, c, M[4], 0x4bdecfa9, 11)\n  c = fnH(c, d, a, b, M[7], 0xf6bb4b60, 16)\n  b = fnH(b, c, d, a, M[10], 0xbebfbc70, 23)\n  a = fnH(a, b, c, d, M[13], 0x289b7ec6, 4)\n  d = fnH(d, a, b, c, M[0], 0xeaa127fa, 11)\n  c = fnH(c, d, a, b, M[3], 0xd4ef3085, 16)\n  b = fnH(b, c, d, a, M[6], 0x04881d05, 23)\n  a = fnH(a, b, c, d, M[9], 0xd9d4d039, 4)\n  d = fnH(d, a, b, c, M[12], 0xe6db99e5, 11)\n  c = fnH(c, d, a, b, M[15], 0x1fa27cf8, 16)\n  b = fnH(b, c, d, a, M[2], 0xc4ac5665, 23)\n\n  a = fnI(a, b, c, d, M[0], 0xf4292244, 6)\n  d = fnI(d, a, b, c, M[7], 0x432aff97, 10)\n  c = fnI(c, d, a, b, M[14], 0xab9423a7, 15)\n  b = fnI(b, c, d, a, M[5], 0xfc93a039, 21)\n  a = fnI(a, b, c, d, M[12], 0x655b59c3, 6)\n  d = fnI(d, a, b, c, M[3], 0x8f0ccc92, 10)\n  c = fnI(c, d, a, b, M[10], 0xffeff47d, 15)\n  b = fnI(b, c, d, a, M[1], 0x85845dd1, 21)\n  a = fnI(a, b, c, d, M[8], 0x6fa87e4f, 6)\n  d = fnI(d, a, b, c, M[15], 0xfe2ce6e0, 10)\n  c = fnI(c, d, a, b, M[6], 0xa3014314, 15)\n  b = fnI(b, c, d, a, M[13], 0x4e0811a1, 21)\n  a = fnI(a, b, c, d, M[4], 0xf7537e82, 6)\n  d = fnI(d, a, b, c, M[11], 0xbd3af235, 10)\n  c = fnI(c, d, a, b, M[2], 0x2ad7d2bb, 15)\n  b = fnI(b, c, d, a, M[9], 0xeb86d391, 21)\n\n  this._a = (this._a + a) | 0\n  this._b = (this._b + b) | 0\n  this._c = (this._c + c) | 0\n  this._d = (this._d + d) | 0\n}\n\nMD5.prototype._digest = function () {\n  // create padding and handle blocks\n  this._block[this._blockOffset++] = 0x80\n  if (this._blockOffset > 56) {\n    this._block.fill(0, this._blockOffset, 64)\n    this._update()\n    this._blockOffset = 0\n  }\n\n  this._block.fill(0, this._blockOffset, 56)\n  this._block.writeUInt32LE(this._length[0], 56)\n  this._block.writeUInt32LE(this._length[1], 60)\n  this._update()\n\n  // produce result\n  var buffer = Buffer.allocUnsafe(16)\n  buffer.writeInt32LE(this._a, 0)\n  buffer.writeInt32LE(this._b, 4)\n  buffer.writeInt32LE(this._c, 8)\n  buffer.writeInt32LE(this._d, 12)\n  return buffer\n}\n\nfunction rotl (x, n) {\n  return (x << n) | (x >>> (32 - n))\n}\n\nfunction fnF (a, b, c, d, m, k, s) {\n  return (rotl((a + ((b & c) | ((~b) & d)) + m + k) | 0, s) + b) | 0\n}\n\nfunction fnG (a, b, c, d, m, k, s) {\n  return (rotl((a + ((b & d) | (c & (~d))) + m + k) | 0, s) + b) | 0\n}\n\nfunction fnH (a, b, c, d, m, k, s) {\n  return (rotl((a + (b ^ c ^ d) + m + k) | 0, s) + b) | 0\n}\n\nfunction fnI (a, b, c, d, m, k, s) {\n  return (rotl((a + ((c ^ (b | (~d)))) + m + k) | 0, s) + b) | 0\n}\n\nmodule.exports = MD5\n","'use strict';\n\nvar _typeof = typeof Symbol === \"function\" && typeof Symbol.iterator === \"symbol\" ? function (obj) { return typeof obj; } : function (obj) { return obj && typeof Symbol === \"function\" && obj.constructor === Symbol && obj !== Symbol.prototype ? \"symbol\" : typeof obj; };\n\nvar _require = require('ethereum-cryptography/keccak'),\n    keccak224 = _require.keccak224,\n    keccak384 = _require.keccak384,\n    k256 = _require.keccak256,\n    keccak512 = _require.keccak512;\n\nvar secp256k1 = require('./secp256k1-adapter');\nvar assert = require('assert');\nvar rlp = require('rlp');\nvar BN = require('bn.js');\nvar createHash = require('create-hash');\nvar Buffer = require('safe-buffer').Buffer;\nObject.assign(exports, require('ethjs-util'));\n\n/**\n * the max integer that this VM can handle (a ```BN```)\n * @var {BN} MAX_INTEGER\n */\nexports.MAX_INTEGER = new BN('ffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff', 16);\n\n/**\n * 2^256 (a ```BN```)\n * @var {BN} TWO_POW256\n */\nexports.TWO_POW256 = new BN('10000000000000000000000000000000000000000000000000000000000000000', 16);\n\n/**\n * Keccak-256 hash of null (a ```String```)\n * @var {String} KECCAK256_NULL_S\n */\nexports.KECCAK256_NULL_S = 'c5d2460186f7233c927e7db2dcc703c0e500b653ca82273b7bfad8045d85a470';\nexports.SHA3_NULL_S = exports.KECCAK256_NULL_S;\n\n/**\n * Keccak-256 hash of null (a ```Buffer```)\n * @var {Buffer} KECCAK256_NULL\n */\nexports.KECCAK256_NULL = Buffer.from(exports.KECCAK256_NULL_S, 'hex');\nexports.SHA3_NULL = exports.KECCAK256_NULL;\n\n/**\n * Keccak-256 of an RLP of an empty array (a ```String```)\n * @var {String} KECCAK256_RLP_ARRAY_S\n */\nexports.KECCAK256_RLP_ARRAY_S = '1dcc4de8dec75d7aab85b567b6ccd41ad312451b948a7413f0a142fd40d49347';\nexports.SHA3_RLP_ARRAY_S = exports.KECCAK256_RLP_ARRAY_S;\n\n/**\n * Keccak-256 of an RLP of an empty array (a ```Buffer```)\n * @var {Buffer} KECCAK256_RLP_ARRAY\n */\nexports.KECCAK256_RLP_ARRAY = Buffer.from(exports.KECCAK256_RLP_ARRAY_S, 'hex');\nexports.SHA3_RLP_ARRAY = exports.KECCAK256_RLP_ARRAY;\n\n/**\n * Keccak-256 hash of the RLP of null  (a ```String```)\n * @var {String} KECCAK256_RLP_S\n */\nexports.KECCAK256_RLP_S = '56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421';\nexports.SHA3_RLP_S = exports.KECCAK256_RLP_S;\n\n/**\n * Keccak-256 hash of the RLP of null (a ```Buffer```)\n * @var {Buffer} KECCAK256_RLP\n */\nexports.KECCAK256_RLP = Buffer.from(exports.KECCAK256_RLP_S, 'hex');\nexports.SHA3_RLP = exports.KECCAK256_RLP;\n\n/**\n * [`BN`](https://github.com/indutny/bn.js)\n * @var {Function}\n */\nexports.BN = BN;\n\n/**\n * [`rlp`](https://github.com/ethereumjs/rlp)\n * @var {Function}\n */\nexports.rlp = rlp;\n\n/**\n * [`secp256k1`](https://github.com/cryptocoinjs/secp256k1-node/)\n * @var {Object}\n */\nexports.secp256k1 = secp256k1;\n\n/**\n * Returns a buffer filled with 0s\n * @method zeros\n * @param {Number} bytes  the number of bytes the buffer should be\n * @return {Buffer}\n */\nexports.zeros = function (bytes) {\n  return Buffer.allocUnsafe(bytes).fill(0);\n};\n\n/**\n  * Returns a zero address\n  * @method zeroAddress\n  * @return {String}\n  */\nexports.zeroAddress = function () {\n  var addressLength = 20;\n  var zeroAddress = exports.zeros(addressLength);\n  return exports.bufferToHex(zeroAddress);\n};\n\n/**\n * Left Pads an `Array` or `Buffer` with leading zeros till it has `length` bytes.\n * Or it truncates the beginning if it exceeds.\n * @method lsetLength\n * @param {Buffer|Array} msg the value to pad\n * @param {Number} length the number of bytes the output should be\n * @param {Boolean} [right=false] whether to start padding form the left or right\n * @return {Buffer|Array}\n */\nexports.setLengthLeft = exports.setLength = function (msg, length, right) {\n  var buf = exports.zeros(length);\n  msg = exports.toBuffer(msg);\n  if (right) {\n    if (msg.length < length) {\n      msg.copy(buf);\n      return buf;\n    }\n    return msg.slice(0, length);\n  } else {\n    if (msg.length < length) {\n      msg.copy(buf, length - msg.length);\n      return buf;\n    }\n    return msg.slice(-length);\n  }\n};\n\n/**\n * Right Pads an `Array` or `Buffer` with leading zeros till it has `length` bytes.\n * Or it truncates the beginning if it exceeds.\n * @param {Buffer|Array} msg the value to pad\n * @param {Number} length the number of bytes the output should be\n * @return {Buffer|Array}\n */\nexports.setLengthRight = function (msg, length) {\n  return exports.setLength(msg, length, true);\n};\n\n/**\n * Trims leading zeros from a `Buffer` or an `Array`\n * @param {Buffer|Array|String} a\n * @return {Buffer|Array|String}\n */\nexports.unpad = exports.stripZeros = function (a) {\n  a = exports.stripHexPrefix(a);\n  var first = a[0];\n  while (a.length > 0 && first.toString() === '0') {\n    a = a.slice(1);\n    first = a[0];\n  }\n  return a;\n};\n/**\n * Attempts to turn a value into a `Buffer`. As input it supports `Buffer`, `String`, `Number`, null/undefined, `BN` and other objects with a `toArray()` method.\n * @param {*} v the value\n */\nexports.toBuffer = function (v) {\n  if (!Buffer.isBuffer(v)) {\n    if (Array.isArray(v)) {\n      v = Buffer.from(v);\n    } else if (typeof v === 'string') {\n      if (exports.isHexString(v)) {\n        v = Buffer.from(exports.padToEven(exports.stripHexPrefix(v)), 'hex');\n      } else {\n        v = Buffer.from(v);\n      }\n    } else if (typeof v === 'number') {\n      v = exports.intToBuffer(v);\n    } else if (v === null || v === undefined) {\n      v = Buffer.allocUnsafe(0);\n    } else if (BN.isBN(v)) {\n      v = v.toArrayLike(Buffer);\n    } else if (v.toArray) {\n      // converts a BN to a Buffer\n      v = Buffer.from(v.toArray());\n    } else {\n      throw new Error('invalid type');\n    }\n  }\n  return v;\n};\n\n/**\n * Converts a `Buffer` to a `Number`\n * @param {Buffer} buf\n * @return {Number}\n * @throws If the input number exceeds 53 bits.\n */\nexports.bufferToInt = function (buf) {\n  return new BN(exports.toBuffer(buf)).toNumber();\n};\n\n/**\n * Converts a `Buffer` into a hex `String`\n * @param {Buffer} buf\n * @return {String}\n */\nexports.bufferToHex = function (buf) {\n  buf = exports.toBuffer(buf);\n  return '0x' + buf.toString('hex');\n};\n\n/**\n * Interprets a `Buffer` as a signed integer and returns a `BN`. Assumes 256-bit numbers.\n * @param {Buffer} num\n * @return {BN}\n */\nexports.fromSigned = function (num) {\n  return new BN(num).fromTwos(256);\n};\n\n/**\n * Converts a `BN` to an unsigned integer and returns it as a `Buffer`. Assumes 256-bit numbers.\n * @param {BN} num\n * @return {Buffer}\n */\nexports.toUnsigned = function (num) {\n  return Buffer.from(num.toTwos(256).toArray());\n};\n\n/**\n * Creates Keccak hash of the input\n * @param {Buffer|Array|String|Number} a the input data\n * @param {Number} [bits=256] the Keccak width\n * @return {Buffer}\n */\nexports.keccak = function (a, bits) {\n  a = exports.toBuffer(a);\n  if (!bits) bits = 256;\n\n  switch (bits) {\n    case 224:\n      {\n        return keccak224(a);\n      }\n    case 256:\n      {\n        return k256(a);\n      }\n    case 384:\n      {\n        return keccak384(a);\n      }\n    case 512:\n      {\n        return keccak512(a);\n      }\n    default:\n      {\n        throw new Error('Invald algorithm: keccak' + bits);\n      }\n  }\n};\n\n/**\n * Creates Keccak-256 hash of the input, alias for keccak(a, 256)\n * @param {Buffer|Array|String|Number} a the input data\n * @return {Buffer}\n */\nexports.keccak256 = function (a) {\n  return exports.keccak(a);\n};\n\n/**\n * Creates SHA-3 (Keccak) hash of the input [OBSOLETE]\n * @param {Buffer|Array|String|Number} a the input data\n * @param {Number} [bits=256] the SHA-3 width\n * @return {Buffer}\n */\nexports.sha3 = exports.keccak;\n\n/**\n * Creates SHA256 hash of the input\n * @param {Buffer|Array|String|Number} a the input data\n * @return {Buffer}\n */\nexports.sha256 = function (a) {\n  a = exports.toBuffer(a);\n  return createHash('sha256').update(a).digest();\n};\n\n/**\n * Creates RIPEMD160 hash of the input\n * @param {Buffer|Array|String|Number} a the input data\n * @param {Boolean} padded whether it should be padded to 256 bits or not\n * @return {Buffer}\n */\nexports.ripemd160 = function (a, padded) {\n  a = exports.toBuffer(a);\n  var hash = createHash('rmd160').update(a).digest();\n  if (padded === true) {\n    return exports.setLength(hash, 32);\n  } else {\n    return hash;\n  }\n};\n\n/**\n * Creates SHA-3 hash of the RLP encoded version of the input\n * @param {Buffer|Array|String|Number} a the input data\n * @return {Buffer}\n */\nexports.rlphash = function (a) {\n  return exports.keccak(rlp.encode(a));\n};\n\n/**\n * Checks if the private key satisfies the rules of the curve secp256k1.\n * @param {Buffer} privateKey\n * @return {Boolean}\n */\nexports.isValidPrivate = function (privateKey) {\n  return secp256k1.privateKeyVerify(privateKey);\n};\n\n/**\n * Checks if the public key satisfies the rules of the curve secp256k1\n * and the requirements of Ethereum.\n * @param {Buffer} publicKey The two points of an uncompressed key, unless sanitize is enabled\n * @param {Boolean} [sanitize=false] Accept public keys in other formats\n * @return {Boolean}\n */\nexports.isValidPublic = function (publicKey, sanitize) {\n  if (publicKey.length === 64) {\n    // Convert to SEC1 for secp256k1\n    return secp256k1.publicKeyVerify(Buffer.concat([Buffer.from([4]), publicKey]));\n  }\n\n  if (!sanitize) {\n    return false;\n  }\n\n  return secp256k1.publicKeyVerify(publicKey);\n};\n\n/**\n * Returns the ethereum address of a given public key.\n * Accepts \"Ethereum public keys\" and SEC1 encoded keys.\n * @param {Buffer} pubKey The two points of an uncompressed key, unless sanitize is enabled\n * @param {Boolean} [sanitize=false] Accept public keys in other formats\n * @return {Buffer}\n */\nexports.pubToAddress = exports.publicToAddress = function (pubKey, sanitize) {\n  pubKey = exports.toBuffer(pubKey);\n  if (sanitize && pubKey.length !== 64) {\n    pubKey = secp256k1.publicKeyConvert(pubKey, false).slice(1);\n  }\n  assert(pubKey.length === 64);\n  // Only take the lower 160bits of the hash\n  return exports.keccak(pubKey).slice(-20);\n};\n\n/**\n * Returns the ethereum public key of a given private key\n * @param {Buffer} privateKey A private key must be 256 bits wide\n * @return {Buffer}\n */\nvar privateToPublic = exports.privateToPublic = function (privateKey) {\n  privateKey = exports.toBuffer(privateKey);\n  // skip the type flag and use the X, Y points\n  return secp256k1.publicKeyCreate(privateKey, false).slice(1);\n};\n\n/**\n * Converts a public key to the Ethereum format.\n * @param {Buffer} publicKey\n * @return {Buffer}\n */\nexports.importPublic = function (publicKey) {\n  publicKey = exports.toBuffer(publicKey);\n  if (publicKey.length !== 64) {\n    publicKey = secp256k1.publicKeyConvert(publicKey, false).slice(1);\n  }\n  return publicKey;\n};\n\n/**\n * ECDSA sign\n * @param {Buffer} msgHash\n * @param {Buffer} privateKey\n * @return {Object}\n */\nexports.ecsign = function (msgHash, privateKey) {\n  var sig = secp256k1.sign(msgHash, privateKey);\n\n  var ret = {};\n  ret.r = sig.signature.slice(0, 32);\n  ret.s = sig.signature.slice(32, 64);\n  ret.v = sig.recovery + 27;\n  return ret;\n};\n\n/**\n * Returns the keccak-256 hash of `message`, prefixed with the header used by the `eth_sign` RPC call.\n * The output of this function can be fed into `ecsign` to produce the same signature as the `eth_sign`\n * call for a given `message`, or fed to `ecrecover` along with a signature to recover the public key\n * used to produce the signature.\n * @param message\n * @returns {Buffer} hash\n */\nexports.hashPersonalMessage = function (message) {\n  var prefix = exports.toBuffer('\\x19Ethereum Signed Message:\\n' + message.length.toString());\n  return exports.keccak(Buffer.concat([prefix, message]));\n};\n\n/**\n * ECDSA public key recovery from signature\n * @param {Buffer} msgHash\n * @param {Number} v\n * @param {Buffer} r\n * @param {Buffer} s\n * @return {Buffer} publicKey\n */\nexports.ecrecover = function (msgHash, v, r, s) {\n  var signature = Buffer.concat([exports.setLength(r, 32), exports.setLength(s, 32)], 64);\n  var recovery = v - 27;\n  if (recovery !== 0 && recovery !== 1) {\n    throw new Error('Invalid signature v value');\n  }\n  var senderPubKey = secp256k1.recover(msgHash, signature, recovery);\n  return secp256k1.publicKeyConvert(senderPubKey, false).slice(1);\n};\n\n/**\n * Convert signature parameters into the format of `eth_sign` RPC method\n * @param {Number} v\n * @param {Buffer} r\n * @param {Buffer} s\n * @return {String} sig\n */\nexports.toRpcSig = function (v, r, s) {\n  // NOTE: with potential introduction of chainId this might need to be updated\n  if (v !== 27 && v !== 28) {\n    throw new Error('Invalid recovery id');\n  }\n\n  // geth (and the RPC eth_sign method) uses the 65 byte format used by Bitcoin\n  // FIXME: this might change in the future - https://github.com/ethereum/go-ethereum/issues/2053\n  return exports.bufferToHex(Buffer.concat([exports.setLengthLeft(r, 32), exports.setLengthLeft(s, 32), exports.toBuffer(v - 27)]));\n};\n\n/**\n * Convert signature format of the `eth_sign` RPC method to signature parameters\n * NOTE: all because of a bug in geth: https://github.com/ethereum/go-ethereum/issues/2053\n * @param {String} sig\n * @return {Object}\n */\nexports.fromRpcSig = function (sig) {\n  sig = exports.toBuffer(sig);\n\n  // NOTE: with potential introduction of chainId this might need to be updated\n  if (sig.length !== 65) {\n    throw new Error('Invalid signature length');\n  }\n\n  var v = sig[64];\n  // support both versions of `eth_sign` responses\n  if (v < 27) {\n    v += 27;\n  }\n\n  return {\n    v: v,\n    r: sig.slice(0, 32),\n    s: sig.slice(32, 64)\n  };\n};\n\n/**\n * Returns the ethereum address of a given private key\n * @param {Buffer} privateKey A private key must be 256 bits wide\n * @return {Buffer}\n */\nexports.privateToAddress = function (privateKey) {\n  return exports.publicToAddress(privateToPublic(privateKey));\n};\n\n/**\n * Checks if the address is a valid. Accepts checksummed addresses too\n * @param {String} address\n * @return {Boolean}\n */\nexports.isValidAddress = function (address) {\n  return (/^0x[0-9a-fA-F]{40}$/.test(address)\n  );\n};\n\n/**\n  * Checks if a given address is a zero address\n  * @method isZeroAddress\n  * @param {String} address\n  * @return {Boolean}\n  */\nexports.isZeroAddress = function (address) {\n  var zeroAddress = exports.zeroAddress();\n  return zeroAddress === exports.addHexPrefix(address);\n};\n\n/**\n * Returns a checksummed address\n * @param {String} address\n * @return {String}\n */\nexports.toChecksumAddress = function (address) {\n  address = exports.stripHexPrefix(address).toLowerCase();\n  var hash = exports.keccak(address).toString('hex');\n  var ret = '0x';\n\n  for (var i = 0; i < address.length; i++) {\n    if (parseInt(hash[i], 16) >= 8) {\n      ret += address[i].toUpperCase();\n    } else {\n      ret += address[i];\n    }\n  }\n\n  return ret;\n};\n\n/**\n * Checks if the address is a valid checksummed address\n * @param {Buffer} address\n * @return {Boolean}\n */\nexports.isValidChecksumAddress = function (address) {\n  return exports.isValidAddress(address) && exports.toChecksumAddress(address) === address;\n};\n\n/**\n * Generates an address of a newly created contract\n * @param {Buffer} from the address which is creating this new address\n * @param {Buffer} nonce the nonce of the from account\n * @return {Buffer}\n */\nexports.generateAddress = function (from, nonce) {\n  from = exports.toBuffer(from);\n  nonce = new BN(nonce);\n\n  if (nonce.isZero()) {\n    // in RLP we want to encode null in the case of zero nonce\n    // read the RLP documentation for an answer if you dare\n    nonce = null;\n  } else {\n    nonce = Buffer.from(nonce.toArray());\n  }\n\n  // Only take the lower 160bits of the hash\n  return exports.rlphash([from, nonce]).slice(-20);\n};\n\n/**\n * Returns true if the supplied address belongs to a precompiled account (Byzantium)\n * @param {Buffer|String} address\n * @return {Boolean}\n */\nexports.isPrecompiled = function (address) {\n  var a = exports.unpad(address);\n  return a.length === 1 && a[0] >= 1 && a[0] <= 8;\n};\n\n/**\n * Adds \"0x\" to a given `String` if it does not already start with \"0x\"\n * @param {String} str\n * @return {String}\n */\nexports.addHexPrefix = function (str) {\n  if (typeof str !== 'string') {\n    return str;\n  }\n\n  return exports.isHexPrefixed(str) ? str : '0x' + str;\n};\n\n/**\n * Validate ECDSA signature\n * @method isValidSignature\n * @param {Buffer} v\n * @param {Buffer} r\n * @param {Buffer} s\n * @param {Boolean} [homestead=true]\n * @return {Boolean}\n */\n\nexports.isValidSignature = function (v, r, s, homestead) {\n  var SECP256K1_N_DIV_2 = new BN('7fffffffffffffffffffffffffffffff5d576e7357a4501ddfe92f46681b20a0', 16);\n  var SECP256K1_N = new BN('fffffffffffffffffffffffffffffffebaaedce6af48a03bbfd25e8cd0364141', 16);\n\n  if (r.length !== 32 || s.length !== 32) {\n    return false;\n  }\n\n  if (v !== 27 && v !== 28) {\n    return false;\n  }\n\n  r = new BN(r);\n  s = new BN(s);\n\n  if (r.isZero() || r.gt(SECP256K1_N) || s.isZero() || s.gt(SECP256K1_N)) {\n    return false;\n  }\n\n  if (homestead === false && new BN(s).cmp(SECP256K1_N_DIV_2) === 1) {\n    return false;\n  }\n\n  return true;\n};\n\n/**\n * Converts a `Buffer` or `Array` to JSON\n * @param {Buffer|Array} ba\n * @return {Array|String|null}\n */\nexports.baToJSON = function (ba) {\n  if (Buffer.isBuffer(ba)) {\n    return '0x' + ba.toString('hex');\n  } else if (ba instanceof Array) {\n    var array = [];\n    for (var i = 0; i < ba.length; i++) {\n      array.push(exports.baToJSON(ba[i]));\n    }\n    return array;\n  }\n};\n\n/**\n * Defines properties on a `Object`. It make the assumption that underlying data is binary.\n * @param {Object} self the `Object` to define properties on\n * @param {Array} fields an array fields to define. Fields can contain:\n * * `name` - the name of the properties\n * * `length` - the number of bytes the field can have\n * * `allowLess` - if the field can be less than the length\n * * `allowEmpty`\n * @param {*} data data to be validated against the definitions\n */\nexports.defineProperties = function (self, fields, data) {\n  self.raw = [];\n  self._fields = [];\n\n  // attach the `toJSON`\n  self.toJSON = function (label) {\n    if (label) {\n      var obj = {};\n      self._fields.forEach(function (field) {\n        obj[field] = '0x' + self[field].toString('hex');\n      });\n      return obj;\n    }\n    return exports.baToJSON(this.raw);\n  };\n\n  self.serialize = function serialize() {\n    return rlp.encode(self.raw);\n  };\n\n  fields.forEach(function (field, i) {\n    self._fields.push(field.name);\n    function getter() {\n      return self.raw[i];\n    }\n    function setter(v) {\n      v = exports.toBuffer(v);\n\n      if (v.toString('hex') === '00' && !field.allowZero) {\n        v = Buffer.allocUnsafe(0);\n      }\n\n      if (field.allowLess && field.length) {\n        v = exports.stripZeros(v);\n        assert(field.length >= v.length, 'The field ' + field.name + ' must not have more ' + field.length + ' bytes');\n      } else if (!(field.allowZero && v.length === 0) && field.length) {\n        assert(field.length === v.length, 'The field ' + field.name + ' must have byte length of ' + field.length);\n      }\n\n      self.raw[i] = v;\n    }\n\n    Object.defineProperty(self, field.name, {\n      enumerable: true,\n      configurable: true,\n      get: getter,\n      set: setter\n    });\n\n    if (field.default) {\n      self[field.name] = field.default;\n    }\n\n    // attach alias\n    if (field.alias) {\n      Object.defineProperty(self, field.alias, {\n        enumerable: false,\n        configurable: true,\n        set: setter,\n        get: getter\n      });\n    }\n  });\n\n  // if the constuctor is passed data\n  if (data) {\n    if (typeof data === 'string') {\n      data = Buffer.from(exports.stripHexPrefix(data), 'hex');\n    }\n\n    if (Buffer.isBuffer(data)) {\n      data = rlp.decode(data);\n    }\n\n    if (Array.isArray(data)) {\n      if (data.length > self._fields.length) {\n        throw new Error('wrong number of fields in data');\n      }\n\n      // make sure all the items are buffers\n      data.forEach(function (d, i) {\n        self[self._fields[i]] = exports.toBuffer(d);\n      });\n    } else if ((typeof data === 'undefined' ? 'undefined' : _typeof(data)) === 'object') {\n      var keys = Object.keys(data);\n      fields.forEach(function (field) {\n        if (keys.indexOf(field.name) !== -1) self[field.name] = data[field.name];\n        if (keys.indexOf(field.alias) !== -1) self[field.alias] = data[field.alias];\n      });\n    } else {\n      throw new Error('invalid data');\n    }\n  }\n};","'use strict';\n\nvar secp256k1 = require('ethereum-cryptography/secp256k1');\n\nvar secp256k1v3 = require('./secp256k1-lib/index');\nvar der = require('./secp256k1-lib/der');\n\n/**\n * Verify an ECDSA privateKey\n * @method privateKeyVerify\n * @param {Buffer} privateKey\n * @return {boolean}\n */\nvar privateKeyVerify = function privateKeyVerify(privateKey) {\n  // secp256k1 v4 version throws when privateKey length is not 32\n  if (privateKey.length !== 32) {\n    return false;\n  }\n\n  return secp256k1.privateKeyVerify(Uint8Array.from(privateKey));\n};\n\n/**\n * Export a privateKey in DER format\n * @method privateKeyExport\n * @param {Buffer} privateKey\n * @param {boolean} compressed\n * @return {boolean}\n */\nvar privateKeyExport = function privateKeyExport(privateKey, compressed) {\n  // privateKeyExport method is not part of secp256k1 v4 package\n  // this implementation is based on v3\n  if (privateKey.length !== 32) {\n    throw new RangeError('private key length is invalid');\n  }\n\n  var publicKey = secp256k1v3.privateKeyExport(privateKey, compressed);\n\n  return der.privateKeyExport(privateKey, publicKey, compressed);\n};\n\n/**\n * Import a privateKey in DER format\n * @method privateKeyImport\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\n\nvar privateKeyImport = function privateKeyImport(privateKey) {\n  // privateKeyImport method is not part of secp256k1 v4 package\n  // this implementation is based on v3\n  privateKey = der.privateKeyImport(privateKey);\n  if (privateKey !== null && privateKey.length === 32 && privateKeyVerify(privateKey)) {\n    return privateKey;\n  }\n\n  throw new Error(\"couldn't import from DER format\");\n};\n\n/**\n * Negate a privateKey by subtracting it from the order of the curve's base point\n * @method privateKeyNegate\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nvar privateKeyNegate = function privateKeyNegate(privateKey) {\n  return Buffer.from(secp256k1.privateKeyNegate(Uint8Array.from(privateKey)));\n};\n\n/**\n * Compute the inverse of a privateKey (modulo the order of the curve's base point).\n * @method privateKeyModInverse\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nvar privateKeyModInverse = function privateKeyModInverse(privateKey) {\n  if (privateKey.length !== 32) {\n    throw new Error('private key length is invalid');\n  }\n\n  return Buffer.from(secp256k1v3.privateKeyModInverse(Uint8Array.from(privateKey)));\n};\n\n/**\n * Tweak a privateKey by adding tweak to it.\n * @method privateKeyTweakAdd\n * @param {Buffer} privateKey\n * @param {Buffer} tweak\n * @return {Buffer}\n */\nvar privateKeyTweakAdd = function privateKeyTweakAdd(privateKey, tweak) {\n  return Buffer.from(secp256k1.privateKeyTweakAdd(Uint8Array.from(privateKey), tweak));\n};\n\n/**\n * Tweak a privateKey by multiplying it by a tweak.\n * @method privateKeyTweakMul\n * @param {Buffer} privateKey\n * @param {Buffer} tweak\n * @return {Buffer}\n */\nvar privateKeyTweakMul = function privateKeyTweakMul(privateKey, tweak) {\n  return Buffer.from(secp256k1.privateKeyTweakMul(Uint8Array.from(privateKey), Uint8Array.from(tweak)));\n};\n\n/**\n * Compute the public key for a privateKey.\n * @method publicKeyCreate\n * @param {Buffer} privateKey\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar publicKeyCreate = function publicKeyCreate(privateKey, compressed) {\n  return Buffer.from(secp256k1.publicKeyCreate(Uint8Array.from(privateKey), compressed));\n};\n\n/**\n * Convert a publicKey to compressed or uncompressed form.\n * @method publicKeyConvert\n * @param {Buffer} publicKey\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar publicKeyConvert = function publicKeyConvert(publicKey, compressed) {\n  return Buffer.from(secp256k1.publicKeyConvert(Uint8Array.from(publicKey), compressed));\n};\n\n/**\n * Verify an ECDSA publicKey.\n * @method publicKeyVerify\n * @param {Buffer} publicKey\n * @return {boolean}\n */\nvar publicKeyVerify = function publicKeyVerify(publicKey) {\n  // secp256k1 v4 version throws when publicKey length is not 33 or 65\n  if (publicKey.length !== 33 && publicKey.length !== 65) {\n    return false;\n  }\n\n  return secp256k1.publicKeyVerify(Uint8Array.from(publicKey));\n};\n\n/**\n * Tweak a publicKey by adding tweak times the generator to it.\n * @method publicKeyTweakAdd\n * @param {Buffer} publicKey\n * @param {Buffer} tweak\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar publicKeyTweakAdd = function publicKeyTweakAdd(publicKey, tweak, compressed) {\n  return Buffer.from(secp256k1.publicKeyTweakAdd(Uint8Array.from(publicKey), Uint8Array.from(tweak), compressed));\n};\n\n/**\n * Tweak a publicKey by multiplying it by a tweak value\n * @method publicKeyTweakMul\n * @param {Buffer} publicKey\n * @param {Buffer} tweak\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar publicKeyTweakMul = function publicKeyTweakMul(publicKey, tweak, compressed) {\n  return Buffer.from(secp256k1.publicKeyTweakMul(Uint8Array.from(publicKey), Uint8Array.from(tweak), compressed));\n};\n\n/**\n * Add a given publicKeys together.\n * @method publicKeyCombine\n * @param {Array<Buffer>} publicKeys\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar publicKeyCombine = function publicKeyCombine(publicKeys, compressed) {\n  var keys = [];\n  publicKeys.forEach(function (publicKey) {\n    keys.push(Uint8Array.from(publicKey));\n  });\n\n  return Buffer.from(secp256k1.publicKeyCombine(keys, compressed));\n};\n\n/**\n * Convert a signature to a normalized lower-S form.\n * @method signatureNormalize\n * @param {Buffer} signature\n * @return {Buffer}\n */\nvar signatureNormalize = function signatureNormalize(signature) {\n  return Buffer.from(secp256k1.signatureNormalize(Uint8Array.from(signature)));\n};\n\n/**\n * Serialize an ECDSA signature in DER format.\n * @method signatureExport\n * @param {Buffer} signature\n * @return {Buffer}\n */\nvar signatureExport = function signatureExport(signature) {\n  return Buffer.from(secp256k1.signatureExport(Uint8Array.from(signature)));\n};\n\n/**\n * Parse a DER ECDSA signature (follow by [BIP66](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)).\n * @method signatureImport\n * @param {Buffer} signature\n * @return {Buffer}\n */\nvar signatureImport = function signatureImport(signature) {\n  return Buffer.from(secp256k1.signatureImport(Uint8Array.from(signature)));\n};\n\n/**\n * Parse a DER ECDSA signature (not follow by [BIP66](https://github.com/bitcoin/bips/blob/master/bip-0066.mediawiki)).\n * @method signatureImportLax\n * @param {Buffer} signature\n * @return {Buffer}\n */\nvar signatureImportLax = function signatureImportLax(signature) {\n  // signatureImportLax method is not part of secp256k1 v4 package\n  // this implementation is based on v3\n  // ensure that signature is greater than 0\n  if (signature.length === 0) {\n    throw new RangeError('signature length is invalid');\n  }\n\n  var sigObj = der.signatureImportLax(signature);\n  if (sigObj === null) {\n    throw new Error(\"couldn't parse DER signature\");\n  }\n\n  return secp256k1v3.signatureImport(sigObj);\n};\n\n/**\n * Create an ECDSA signature. Always return low-S signature.\n * @method sign\n * @param {Buffer} message\n * @param {Buffer} privateKey\n * @param {Object} options\n * @return {Buffer}\n */\nvar sign = function sign(message, privateKey, options) {\n  if (options === null) {\n    throw new TypeError('options should be an Object');\n  }\n\n  var signOptions = void 0;\n\n  if (options) {\n    signOptions = {};\n\n    if (options.data === null) {\n      throw new TypeError('options.data should be a Buffer');\n    }\n\n    if (options.data) {\n      // validate option.data length\n      if (options.data.length !== 32) {\n        throw new RangeError('options.data length is invalid');\n      }\n\n      signOptions.data = new Uint8Array(options.data);\n    }\n\n    if (options.noncefn === null) {\n      throw new TypeError('options.noncefn should be a Function');\n    }\n\n    if (options.noncefn) {\n      //  convert option.noncefn function signature\n      signOptions.noncefn = function (message, privateKey, algo, data, attempt) {\n        var bufferAlgo = algo != null ? Buffer.from(algo) : null;\n        var bufferData = data != null ? Buffer.from(data) : null;\n\n        var buffer = Buffer.from('');\n\n        if (options.noncefn) {\n          buffer = options.noncefn(Buffer.from(message), Buffer.from(privateKey), bufferAlgo, bufferData, attempt);\n        }\n\n        return Uint8Array.from(buffer);\n      };\n    }\n  }\n\n  var sig = secp256k1.ecdsaSign(Uint8Array.from(message), Uint8Array.from(privateKey), signOptions);\n\n  return {\n    signature: Buffer.from(sig.signature),\n    recovery: sig.recid\n  };\n};\n\n/**\n * Verify an ECDSA signature.\n * @method verify\n * @param {Buffer} message\n * @param {Buffer} signature\n * @param {Buffer} publicKey\n * @return {boolean}\n */\nvar verify = function verify(message, signature, publicKey) {\n  // note: secp256k1 v4 verify method has a different argument order\n  return secp256k1.ecdsaVerify(Uint8Array.from(signature), Uint8Array.from(message), publicKey);\n};\n\n/**\n * Recover an ECDSA public key from a signature.\n * @method recover\n * @param {Buffer} message\n * @param {Buffer} signature\n * @param {Number} recid\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar recover = function recover(message, signature, recid, compressed) {\n  // note: secp256k1 v4 recover method has a different argument order\n  return Buffer.from(secp256k1.ecdsaRecover(Uint8Array.from(signature), recid, Uint8Array.from(message), compressed));\n};\n\n/**\n * Compute an EC Diffie-Hellman secret and applied sha256 to compressed public key.\n * @method ecdh\n * @param {Buffer} publicKey\n * @param {Buffer} privateKey\n * @return {Buffer}\n */\nvar ecdh = function ecdh(publicKey, privateKey) {\n  // note: secp256k1 v3 doesn't allow optional parameter\n  return Buffer.from(secp256k1.ecdh(Uint8Array.from(publicKey), Uint8Array.from(privateKey), {}));\n};\n\n/**\n * Compute an EC Diffie-Hellman secret and return public key as result\n * @method ecdhUnsafe\n * @param {Buffer} publicKey\n * @param {Buffer} privateKey\n * @param {boolean} compressed\n * @return {Buffer}\n */\nvar ecdhUnsafe = function ecdhUnsafe(publicKey, privateKey, compressed) {\n  // ecdhUnsafe method is not part of secp256k1 v4 package\n  // this implementation is based on v3\n  // ensure valid publicKey length\n  if (publicKey.length !== 33 && publicKey.length !== 65) {\n    throw new RangeError('public key length is invalid');\n  }\n\n  // ensure valid privateKey length\n  if (privateKey.length !== 32) {\n    throw new RangeError('private key length is invalid');\n  }\n\n  return Buffer.from(secp256k1v3.ecdhUnsafe(Uint8Array.from(publicKey), Uint8Array.from(privateKey), compressed));\n};\n\nmodule.exports = {\n  privateKeyVerify: privateKeyVerify,\n  privateKeyExport: privateKeyExport,\n  privateKeyImport: privateKeyImport,\n  privateKeyNegate: privateKeyNegate,\n  privateKeyModInverse: privateKeyModInverse,\n  privateKeyTweakAdd: privateKeyTweakAdd,\n  privateKeyTweakMul: privateKeyTweakMul,\n\n  publicKeyCreate: publicKeyCreate,\n  publicKeyConvert: publicKeyConvert,\n  publicKeyVerify: publicKeyVerify,\n  publicKeyTweakAdd: publicKeyTweakAdd,\n  publicKeyTweakMul: publicKeyTweakMul,\n  publicKeyCombine: publicKeyCombine,\n\n  signatureNormalize: signatureNormalize,\n  signatureExport: signatureExport,\n  signatureImport: signatureImport,\n  signatureImportLax: signatureImportLax,\n\n  sign: sign,\n  verify: verify,\n  recover: recover,\n\n  ecdh: ecdh,\n  ecdhUnsafe: ecdhUnsafe\n};","\"use strict\";\n\n// This file is imported from secp256k1 v3\n// https://github.com/cryptocoinjs/secp256k1-node/blob/master/LICENSE\n\nvar EC_PRIVKEY_EXPORT_DER_COMPRESSED = Buffer.from([\n// begin\n0x30, 0x81, 0xd3, 0x02, 0x01, 0x01, 0x04, 0x20,\n// private key\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n// middle\n0xa0, 0x81, 0x85, 0x30, 0x81, 0x82, 0x02, 0x01, 0x01, 0x30, 0x2c, 0x06, 0x07, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x01, 0x01, 0x02, 0x21, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xfe, 0xff, 0xff, 0xfc, 0x2f, 0x30, 0x06, 0x04, 0x01, 0x00, 0x04, 0x01, 0x07, 0x04, 0x21, 0x02, 0x79, 0xbe, 0x66, 0x7e, 0xf9, 0xdc, 0xbb, 0xac, 0x55, 0xa0, 0x62, 0x95, 0xce, 0x87, 0x0b, 0x07, 0x02, 0x9b, 0xfc, 0xdb, 0x2d, 0xce, 0x28, 0xd9, 0x59, 0xf2, 0x81, 0x5b, 0x16, 0xf8, 0x17, 0x98, 0x02, 0x21, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xfe, 0xba, 0xae, 0xdc, 0xe6, 0xaf, 0x48, 0xa0, 0x3b, 0xbf, 0xd2, 0x5e, 0x8c, 0xd0, 0x36, 0x41, 0x41, 0x02, 0x01, 0x01, 0xa1, 0x24, 0x03, 0x22, 0x00,\n// public key\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]);\n\nvar EC_PRIVKEY_EXPORT_DER_UNCOMPRESSED = Buffer.from([\n// begin\n0x30, 0x82, 0x01, 0x13, 0x02, 0x01, 0x01, 0x04, 0x20,\n// private key\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n// middle\n0xa0, 0x81, 0xa5, 0x30, 0x81, 0xa2, 0x02, 0x01, 0x01, 0x30, 0x2c, 0x06, 0x07, 0x2a, 0x86, 0x48, 0xce, 0x3d, 0x01, 0x01, 0x02, 0x21, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xfe, 0xff, 0xff, 0xfc, 0x2f, 0x30, 0x06, 0x04, 0x01, 0x00, 0x04, 0x01, 0x07, 0x04, 0x41, 0x04, 0x79, 0xbe, 0x66, 0x7e, 0xf9, 0xdc, 0xbb, 0xac, 0x55, 0xa0, 0x62, 0x95, 0xce, 0x87, 0x0b, 0x07, 0x02, 0x9b, 0xfc, 0xdb, 0x2d, 0xce, 0x28, 0xd9, 0x59, 0xf2, 0x81, 0x5b, 0x16, 0xf8, 0x17, 0x98, 0x48, 0x3a, 0xda, 0x77, 0x26, 0xa3, 0xc4, 0x65, 0x5d, 0xa4, 0xfb, 0xfc, 0x0e, 0x11, 0x08, 0xa8, 0xfd, 0x17, 0xb4, 0x48, 0xa6, 0x85, 0x54, 0x19, 0x9c, 0x47, 0xd0, 0x8f, 0xfb, 0x10, 0xd4, 0xb8, 0x02, 0x21, 0x00, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xfe, 0xba, 0xae, 0xdc, 0xe6, 0xaf, 0x48, 0xa0, 0x3b, 0xbf, 0xd2, 0x5e, 0x8c, 0xd0, 0x36, 0x41, 0x41, 0x02, 0x01, 0x01, 0xa1, 0x44, 0x03, 0x42, 0x00,\n// public key\n0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00]);\n\nexports.privateKeyExport = function (privateKey, publicKey, compressed) {\n  var result = Buffer.from(compressed ? EC_PRIVKEY_EXPORT_DER_COMPRESSED : EC_PRIVKEY_EXPORT_DER_UNCOMPRESSED);\n  privateKey.copy(result, compressed ? 8 : 9);\n  publicKey.copy(result, compressed ? 181 : 214);\n  return result;\n};\n\nexports.privateKeyImport = function (privateKey) {\n  var length = privateKey.length;\n\n  // sequence header\n  var index = 0;\n  if (length < index + 1 || privateKey[index] !== 0x30) return null;\n  index += 1;\n\n  // sequence length constructor\n  if (length < index + 1 || !(privateKey[index] & 0x80)) return null;\n\n  var lenb = privateKey[index] & 0x7f;\n  index += 1;\n  if (lenb < 1 || lenb > 2) return null;\n  if (length < index + lenb) return null;\n\n  // sequence length\n  var len = privateKey[index + lenb - 1] | (lenb > 1 ? privateKey[index + lenb - 2] << 8 : 0);\n  index += lenb;\n  if (length < index + len) return null;\n\n  // sequence element 0: version number (=1)\n  if (length < index + 3 || privateKey[index] !== 0x02 || privateKey[index + 1] !== 0x01 || privateKey[index + 2] !== 0x01) {\n    return null;\n  }\n  index += 3;\n\n  // sequence element 1: octet string, up to 32 bytes\n  if (length < index + 2 || privateKey[index] !== 0x04 || privateKey[index + 1] > 0x20 || length < index + 2 + privateKey[index + 1]) {\n    return null;\n  }\n\n  return privateKey.slice(index + 2, index + 2 + privateKey[index + 1]);\n};\n\nexports.signatureImportLax = function (signature) {\n  var r = Buffer.alloc(32, 0);\n  var s = Buffer.alloc(32, 0);\n\n  var length = signature.length;\n  var index = 0;\n\n  // sequence tag byte\n  if (signature[index++] !== 0x30) {\n    return null;\n  }\n\n  // sequence length byte\n  var lenbyte = signature[index++];\n  if (lenbyte & 0x80) {\n    index += lenbyte - 0x80;\n    if (index > length) {\n      return null;\n    }\n  }\n\n  // sequence tag byte for r\n  if (signature[index++] !== 0x02) {\n    return null;\n  }\n\n  // length for r\n  var rlen = signature[index++];\n  if (rlen & 0x80) {\n    lenbyte = rlen - 0x80;\n    if (index + lenbyte > length) {\n      return null;\n    }\n    for (; lenbyte > 0 && signature[index] === 0x00; index += 1, lenbyte -= 1) {}\n    for (rlen = 0; lenbyte > 0; index += 1, lenbyte -= 1) {\n      rlen = (rlen << 8) + signature[index];\n    }\n  }\n  if (rlen > length - index) {\n    return null;\n  }\n  var rindex = index;\n  index += rlen;\n\n  // sequence tag byte for s\n  if (signature[index++] !== 0x02) {\n    return null;\n  }\n\n  // length for s\n  var slen = signature[index++];\n  if (slen & 0x80) {\n    lenbyte = slen - 0x80;\n    if (index + lenbyte > length) {\n      return null;\n    }\n    for (; lenbyte > 0 && signature[index] === 0x00; index += 1, lenbyte -= 1) {}\n    for (slen = 0; lenbyte > 0; index += 1, lenbyte -= 1) {\n      slen = (slen << 8) + signature[index];\n    }\n  }\n  if (slen > length - index) {\n    return null;\n  }\n  var sindex = index;\n  index += slen;\n\n  // ignore leading zeros in r\n  for (; rlen > 0 && signature[rindex] === 0x00; rlen -= 1, rindex += 1) {}\n  // copy r value\n  if (rlen > 32) {\n    return null;\n  }\n  var rvalue = signature.slice(rindex, rindex + rlen);\n  rvalue.copy(r, 32 - rvalue.length);\n\n  // ignore leading zeros in s\n  for (; slen > 0 && signature[sindex] === 0x00; slen -= 1, sindex += 1) {}\n  // copy s value\n  if (slen > 32) {\n    return null;\n  }\n  var svalue = signature.slice(sindex, sindex + slen);\n  svalue.copy(s, 32 - svalue.length);\n\n  return { r: r, s: s };\n};","'use strict';\n\n// This file is imported from secp256k1 v3\n// https://github.com/cryptocoinjs/secp256k1-node/blob/master/LICENSE\n\nvar BN = require('bn.js');\nvar EC = require('elliptic').ec;\n\nvar ec = new EC('secp256k1');\nvar ecparams = ec.curve;\n\nexports.privateKeyExport = function (privateKey, compressed) {\n  var d = new BN(privateKey);\n  if (d.ucmp(ecparams.n) >= 0) {\n    throw new Error('couldn\\'t export to DER format');\n  }\n\n  var point = ec.g.mul(d);\n  return toPublicKey(point.getX(), point.getY(), compressed);\n};\n\nexports.privateKeyModInverse = function (privateKey) {\n  var bn = new BN(privateKey);\n  if (bn.ucmp(ecparams.n) >= 0 || bn.isZero()) {\n    throw new Error('private key range is invalid');\n  }\n\n  return bn.invm(ecparams.n).toArrayLike(Buffer, 'be', 32);\n};\n\nexports.signatureImport = function (sigObj) {\n  var r = new BN(sigObj.r);\n  if (r.ucmp(ecparams.n) >= 0) {\n    r = new BN(0);\n  }\n\n  var s = new BN(sigObj.s);\n  if (s.ucmp(ecparams.n) >= 0) {\n    s = new BN(0);\n  }\n\n  return Buffer.concat([r.toArrayLike(Buffer, 'be', 32), s.toArrayLike(Buffer, 'be', 32)]);\n};\n\nexports.ecdhUnsafe = function (publicKey, privateKey, compressed) {\n  var point = ec.keyFromPublic(publicKey);\n\n  var scalar = new BN(privateKey);\n  if (scalar.ucmp(ecparams.n) >= 0 || scalar.isZero()) {\n    throw new Error('scalar was invalid (zero or overflow)');\n  }\n\n  var shared = point.pub.mul(scalar);\n  return toPublicKey(shared.getX(), shared.getY(), compressed);\n};\n\nvar toPublicKey = function toPublicKey(x, y, compressed) {\n  var publicKey = void 0;\n\n  if (compressed) {\n    publicKey = Buffer.alloc(33);\n    publicKey[0] = y.isOdd() ? 0x03 : 0x02;\n    x.toArrayLike(Buffer, 'be', 32).copy(publicKey, 1);\n  } else {\n    publicKey = Buffer.alloc(65);\n    publicKey[0] = 0x04;\n    x.toArrayLike(Buffer, 'be', 32).copy(publicKey, 1);\n    y.toArrayLike(Buffer, 'be', 32).copy(publicKey, 33);\n  }\n\n  return publicKey;\n};","\"use strict\";\n\nvar rlp = require('rlp');\n\nvar ethUtil = require('ethereumjs-util');\n\nmodule.exports = TrieNode;\n\nfunction TrieNode(type, key, value) {\n  if (Array.isArray(type)) {\n    // parse raw node\n    this.parseNode(type);\n  } else {\n    this.type = type;\n\n    if (type === 'branch') {\n      var values = key;\n      this.raw = Array.apply(null, Array(17));\n\n      if (values) {\n        values.forEach(function (keyVal) {\n          this.set.apply(this, keyVal);\n        });\n      }\n    } else {\n      this.raw = Array(2);\n      this.setValue(value);\n      this.setKey(key);\n    }\n  }\n}\n\nTrieNode.isRawNode = isRawNode;\nTrieNode.addHexPrefix = addHexPrefix;\nTrieNode.removeHexPrefix = removeHexPrefix;\nTrieNode.isTerminator = isTerminator;\nTrieNode.stringToNibbles = stringToNibbles;\nTrieNode.nibblesToBuffer = nibblesToBuffer;\nTrieNode.getNodeType = getNodeType;\nObject.defineProperty(TrieNode.prototype, 'value', {\n  get: function get() {\n    return this.getValue();\n  },\n  set: function set(v) {\n    this.setValue(v);\n  }\n});\nObject.defineProperty(TrieNode.prototype, 'key', {\n  get: function get() {\n    return this.getKey();\n  },\n  set: function set(k) {\n    this.setKey(k);\n  }\n}); // parses a raw node\n\nTrieNode.prototype.parseNode = function (rawNode) {\n  this.raw = rawNode;\n  this.type = getNodeType(rawNode);\n}; // sets the value of the node\n\n\nTrieNode.prototype.setValue = function (key, value) {\n  if (this.type !== 'branch') {\n    this.raw[1] = key;\n  } else {\n    if (arguments.length === 1) {\n      value = key;\n      key = 16;\n    }\n\n    this.raw[key] = value;\n  }\n};\n\nTrieNode.prototype.getValue = function (key) {\n  if (this.type === 'branch') {\n    if (arguments.length === 0) {\n      key = 16;\n    }\n\n    var val = this.raw[key];\n\n    if (val !== null && val !== undefined && val.length !== 0) {\n      return val;\n    }\n  } else {\n    return this.raw[1];\n  }\n};\n\nTrieNode.prototype.setKey = function (key) {\n  if (this.type !== 'branch') {\n    if (Buffer.isBuffer(key)) {\n      key = stringToNibbles(key);\n    } else {\n      key = key.slice(0); // copy the key\n    }\n\n    key = addHexPrefix(key, this.type === 'leaf');\n    this.raw[0] = nibblesToBuffer(key);\n  }\n}; // returns the key as a nibble\n\n\nTrieNode.prototype.getKey = function () {\n  if (this.type !== 'branch') {\n    var key = this.raw[0];\n    key = removeHexPrefix(stringToNibbles(key));\n    return key;\n  }\n};\n\nTrieNode.prototype.serialize = function () {\n  return rlp.encode(this.raw);\n};\n\nTrieNode.prototype.hash = function () {\n  return ethUtil.sha3(this.serialize());\n};\n\nTrieNode.prototype.toString = function () {\n  var out = this.type;\n  out += ': [';\n  this.raw.forEach(function (el) {\n    if (Buffer.isBuffer(el)) {\n      out += el.toString('hex') + ', ';\n    } else if (el) {\n      out += 'object, ';\n    } else {\n      out += 'empty, ';\n    }\n  });\n  out = out.slice(0, -2);\n  out += ']';\n  return out;\n};\n\nTrieNode.prototype.getChildren = function () {\n  var children = [];\n\n  switch (this.type) {\n    case 'leaf':\n      // no children\n      break;\n\n    case 'extention':\n      // one child\n      children.push([this.key, this.getValue()]);\n      break;\n\n    case 'branch':\n      for (var index = 0, end = 16; index < end; index++) {\n        var value = this.getValue(index);\n\n        if (value) {\n          children.push([[index], value]);\n        }\n      }\n\n      break;\n  }\n\n  return children;\n};\n/**\n * @param {Array} dataArr\n * @returns {Buffer} - returns buffer of encoded data\n * hexPrefix\n **/\n\n\nfunction addHexPrefix(key, terminator) {\n  // odd\n  if (key.length % 2) {\n    key.unshift(1);\n  } else {\n    // even\n    key.unshift(0);\n    key.unshift(0);\n  }\n\n  if (terminator) {\n    key[0] += 2;\n  }\n\n  return key;\n}\n\nfunction removeHexPrefix(val) {\n  if (val[0] % 2) {\n    val = val.slice(1);\n  } else {\n    val = val.slice(2);\n  }\n\n  return val;\n}\n/**\n * Determines if a key has Arnold Schwarzenegger in it.\n * @method isTerminator\n * @private\n * @param {Array} key - an hexprefixed array of nibbles\n */\n\n\nfunction isTerminator(key) {\n  return key[0] > 1;\n}\n/**\n * Converts a string OR a buffer to a nibble array.\n * @method stringToNibbles\n * @private\n * @param {Buffer| String} key\n */\n\n\nfunction stringToNibbles(key) {\n  var bkey = new Buffer(key);\n  var nibbles = [];\n\n  for (var i = 0; i < bkey.length; i++) {\n    var q = i * 2;\n    nibbles[q] = bkey[i] >> 4;\n    ++q;\n    nibbles[q] = bkey[i] % 16;\n  }\n\n  return nibbles;\n}\n/**\n * Converts a nibble array into a buffer.\n * @method nibblesToBuffer\n * @private\n * @param arr\n */\n\n\nfunction nibblesToBuffer(arr) {\n  var buf = new Buffer(arr.length / 2);\n\n  for (var i = 0; i < buf.length; i++) {\n    var q = i * 2;\n    buf[i] = (arr[q] << 4) + arr[++q];\n  }\n\n  return buf;\n}\n/**\n * Determines the node type.\n * @private\n * @returns {String} - the node type\n *   - leaf - if the node is a leaf\n *   - branch - if the node is a branch\n *   - extention - if the node is an extention\n *   - unknown - if something else got borked\n */\n\n\nfunction getNodeType(node) {\n  if (node.length === 17) {\n    return 'branch';\n  } else if (node.length === 2) {\n    var key = stringToNibbles(node[0]);\n\n    if (isTerminator(key)) {\n      return 'leaf';\n    }\n\n    return 'extention';\n  }\n}\n\nfunction isRawNode(node) {\n  return Array.isArray(node) && !Buffer.isBuffer(node);\n}","module.exports = assert;\n\nfunction assert(val, msg) {\n  if (!val)\n    throw new Error(msg || 'Assertion failed');\n}\n\nassert.equal = function assertEqual(l, r, msg) {\n  if (l != r)\n    throw new Error(msg || ('Assertion failed: ' + l + ' != ' + r));\n};\n","'use strict';\n\nvar utils = exports;\n\nfunction toArray(msg, enc) {\n  if (Array.isArray(msg))\n    return msg.slice();\n  if (!msg)\n    return [];\n  var res = [];\n  if (typeof msg !== 'string') {\n    for (var i = 0; i < msg.length; i++)\n      res[i] = msg[i] | 0;\n    return res;\n  }\n  if (enc === 'hex') {\n    msg = msg.replace(/[^a-z0-9]+/ig, '');\n    if (msg.length % 2 !== 0)\n      msg = '0' + msg;\n    for (var i = 0; i < msg.length; i += 2)\n      res.push(parseInt(msg[i] + msg[i + 1], 16));\n  } else {\n    for (var i = 0; i < msg.length; i++) {\n      var c = msg.charCodeAt(i);\n      var hi = c >> 8;\n      var lo = c & 0xff;\n      if (hi)\n        res.push(hi, lo);\n      else\n        res.push(lo);\n    }\n  }\n  return res;\n}\nutils.toArray = toArray;\n\nfunction zero2(word) {\n  if (word.length === 1)\n    return '0' + word;\n  else\n    return word;\n}\nutils.zero2 = zero2;\n\nfunction toHex(msg) {\n  var res = '';\n  for (var i = 0; i < msg.length; i++)\n    res += zero2(msg[i].toString(16));\n  return res;\n}\nutils.toHex = toHex;\n\nutils.encode = function encode(arr, enc) {\n  if (enc === 'hex')\n    return toHex(arr);\n  else\n    return arr;\n};\n","'use strict';\n\nvar numberIsNaN = function (value) {\n\treturn value !== value;\n};\n\nmodule.exports = function is(a, b) {\n\tif (a === 0 && b === 0) {\n\t\treturn 1 / a === 1 / b;\n\t}\n\tif (a === b) {\n\t\treturn true;\n\t}\n\tif (numberIsNaN(a) && numberIsNaN(b)) {\n\t\treturn true;\n\t}\n\treturn false;\n};\n\n","'use strict';\n\nvar define = require('define-properties');\nvar callBind = require('call-bind');\n\nvar implementation = require('./implementation');\nvar getPolyfill = require('./polyfill');\nvar shim = require('./shim');\n\nvar polyfill = callBind(getPolyfill(), Object);\n\ndefine(polyfill, {\n\tgetPolyfill: getPolyfill,\n\timplementation: implementation,\n\tshim: shim\n});\n\nmodule.exports = polyfill;\n","'use strict';\n\nvar implementation = require('./implementation');\n\nmodule.exports = function getPolyfill() {\n\treturn typeof Object.is === 'function' ? Object.is : implementation;\n};\n","'use strict';\n\nvar getPolyfill = require('./polyfill');\nvar define = require('define-properties');\n\nmodule.exports = function shimObjectIs() {\n\tvar polyfill = getPolyfill();\n\tdefine(Object, { is: polyfill }, {\n\t\tis: function testObjectIs() {\n\t\t\treturn Object.is !== polyfill;\n\t\t}\n\t});\n\treturn polyfill;\n};\n","'use strict'\n\n// limit of Crypto.getRandomValues()\n// https://developer.mozilla.org/en-US/docs/Web/API/Crypto/getRandomValues\nvar MAX_BYTES = 65536\n\n// Node supports requesting up to this number of bytes\n// https://github.com/nodejs/node/blob/master/lib/internal/crypto/random.js#L48\nvar MAX_UINT32 = 4294967295\n\nfunction oldBrowser () {\n  throw new Error('Secure random number generation is not supported by this browser.\\nUse Chrome, Firefox or Internet Explorer 11')\n}\n\nvar Buffer = require('safe-buffer').Buffer\nvar crypto = global.crypto || global.msCrypto\n\nif (crypto && crypto.getRandomValues) {\n  module.exports = randomBytes\n} else {\n  module.exports = oldBrowser\n}\n\nfunction randomBytes (size, cb) {\n  // phantomjs needs to throw\n  if (size > MAX_UINT32) throw new RangeError('requested too many random bytes')\n\n  var bytes = Buffer.allocUnsafe(size)\n\n  if (size > 0) {  // getRandomValues fails on IE if size == 0\n    if (size > MAX_BYTES) { // this is the max bytes crypto.getRandomValues\n      // can do at once see https://developer.mozilla.org/en-US/docs/Web/API/window.crypto.getRandomValues\n      for (var generated = 0; generated < size; generated += MAX_BYTES) {\n        // buffer.slice automatically checks if the end is past the end of\n        // the buffer so we don't have to here\n        crypto.getRandomValues(bytes.slice(generated, generated + MAX_BYTES))\n      }\n    } else {\n      crypto.getRandomValues(bytes)\n    }\n  }\n\n  if (typeof cb === 'function') {\n    return process.nextTick(function () {\n      cb(null, bytes)\n    })\n  }\n\n  return bytes\n}\n","'use strict';\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n'use strict';\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = require('./_stream_readable');\n\nvar Writable = require('./_stream_writable');\n\nrequire('inherits')(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n'use strict';\n\nmodule.exports = PassThrough;\n\nvar Transform = require('./_stream_transform');\n\nrequire('inherits')(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n'use strict';\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = require('events').EventEmitter;\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = require('util');\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = require('./internal/streams/buffer_list');\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\nrequire('inherits')(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || require('./_stream_duplex');\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = require('string_decoder/').StringDecoder;\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = require('./internal/streams/async_iterator');\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = require('./internal/streams/from');\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n'use strict';\n\nmodule.exports = Transform;\n\nvar _require$codes = require('../errors').codes,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = require('./_stream_duplex');\n\nrequire('inherits')(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}","// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n'use strict';\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: require('util-deprecate')\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = require('./internal/streams/stream');\n/*</replacement>*/\n\n\nvar Buffer = require('buffer').Buffer;\n\nvar OurUint8Array = global.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = require('./internal/streams/destroy');\n\nvar _require = require('./internal/streams/state'),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = require('../errors').codes,\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\nrequire('inherits')(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || require('./_stream_duplex');\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')\n\n  this.autoDestroy = !!options.autoDestroy; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || require('./_stream_duplex'); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};","'use strict';\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = require('./end-of-stream');\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;","'use strict';\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar _require = require('buffer'),\n    Buffer = _require.Buffer;\n\nvar _require2 = require('util'),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n\n      while (p = p.next) {\n        ret += s + p.data;\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n\n      return ret;\n    } // Consumes a specified amount of bytes or characters from the buffered data.\n\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    } // Consumes a specified amount of characters from the buffered data.\n\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Consumes a specified amount of bytes from the buffered data.\n\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Make sure the linked list only shows the minimal necessary information.\n\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread({}, options, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n\n  return BufferList;\n}();","'use strict'; // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};","// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar ERR_STREAM_PREMATURE_CLOSE = require('../../../errors').codes.ERR_STREAM_PREMATURE_CLOSE;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;","module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n","// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n'use strict';\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = require('../../../errors').codes,\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = require('./end-of-stream');\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;","'use strict';\n\nvar ERR_INVALID_OPT_VALUE = require('../../../errors').codes.ERR_INVALID_OPT_VALUE;\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};","module.exports = require('events').EventEmitter;\n","exports = module.exports = require('./lib/_stream_readable.js');\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = require('./lib/_stream_writable.js');\nexports.Duplex = require('./lib/_stream_duplex.js');\nexports.Transform = require('./lib/_stream_transform.js');\nexports.PassThrough = require('./lib/_stream_passthrough.js');\nexports.finished = require('./lib/internal/streams/end-of-stream.js');\nexports.pipeline = require('./lib/internal/streams/pipeline.js');\n","'use strict'\nvar Buffer = require('buffer').Buffer\nvar inherits = require('inherits')\nvar HashBase = require('hash-base')\n\nvar ARRAY16 = new Array(16)\n\nvar zl = [\n  0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15,\n  7, 4, 13, 1, 10, 6, 15, 3, 12, 0, 9, 5, 2, 14, 11, 8,\n  3, 10, 14, 4, 9, 15, 8, 1, 2, 7, 0, 6, 13, 11, 5, 12,\n  1, 9, 11, 10, 0, 8, 12, 4, 13, 3, 7, 15, 14, 5, 6, 2,\n  4, 0, 5, 9, 7, 12, 2, 10, 14, 1, 3, 8, 11, 6, 15, 13\n]\n\nvar zr = [\n  5, 14, 7, 0, 9, 2, 11, 4, 13, 6, 15, 8, 1, 10, 3, 12,\n  6, 11, 3, 7, 0, 13, 5, 10, 14, 15, 8, 12, 4, 9, 1, 2,\n  15, 5, 1, 3, 7, 14, 6, 9, 11, 8, 12, 2, 10, 0, 4, 13,\n  8, 6, 4, 1, 3, 11, 15, 0, 5, 12, 2, 13, 9, 7, 10, 14,\n  12, 15, 10, 4, 1, 5, 8, 7, 6, 2, 13, 14, 0, 3, 9, 11\n]\n\nvar sl = [\n  11, 14, 15, 12, 5, 8, 7, 9, 11, 13, 14, 15, 6, 7, 9, 8,\n  7, 6, 8, 13, 11, 9, 7, 15, 7, 12, 15, 9, 11, 7, 13, 12,\n  11, 13, 6, 7, 14, 9, 13, 15, 14, 8, 13, 6, 5, 12, 7, 5,\n  11, 12, 14, 15, 14, 15, 9, 8, 9, 14, 5, 6, 8, 6, 5, 12,\n  9, 15, 5, 11, 6, 8, 13, 12, 5, 12, 13, 14, 11, 8, 5, 6\n]\n\nvar sr = [\n  8, 9, 9, 11, 13, 15, 15, 5, 7, 7, 8, 11, 14, 14, 12, 6,\n  9, 13, 15, 7, 12, 8, 9, 11, 7, 7, 12, 7, 6, 15, 13, 11,\n  9, 7, 15, 11, 8, 6, 6, 14, 12, 13, 5, 14, 13, 13, 7, 5,\n  15, 5, 8, 11, 14, 14, 6, 14, 6, 9, 12, 9, 12, 5, 15, 8,\n  8, 5, 12, 9, 12, 5, 14, 6, 8, 13, 6, 5, 15, 13, 11, 11\n]\n\nvar hl = [0x00000000, 0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xa953fd4e]\nvar hr = [0x50a28be6, 0x5c4dd124, 0x6d703ef3, 0x7a6d76e9, 0x00000000]\n\nfunction RIPEMD160 () {\n  HashBase.call(this, 64)\n\n  // state\n  this._a = 0x67452301\n  this._b = 0xefcdab89\n  this._c = 0x98badcfe\n  this._d = 0x10325476\n  this._e = 0xc3d2e1f0\n}\n\ninherits(RIPEMD160, HashBase)\n\nRIPEMD160.prototype._update = function () {\n  var words = ARRAY16\n  for (var j = 0; j < 16; ++j) words[j] = this._block.readInt32LE(j * 4)\n\n  var al = this._a | 0\n  var bl = this._b | 0\n  var cl = this._c | 0\n  var dl = this._d | 0\n  var el = this._e | 0\n\n  var ar = this._a | 0\n  var br = this._b | 0\n  var cr = this._c | 0\n  var dr = this._d | 0\n  var er = this._e | 0\n\n  // computation\n  for (var i = 0; i < 80; i += 1) {\n    var tl\n    var tr\n    if (i < 16) {\n      tl = fn1(al, bl, cl, dl, el, words[zl[i]], hl[0], sl[i])\n      tr = fn5(ar, br, cr, dr, er, words[zr[i]], hr[0], sr[i])\n    } else if (i < 32) {\n      tl = fn2(al, bl, cl, dl, el, words[zl[i]], hl[1], sl[i])\n      tr = fn4(ar, br, cr, dr, er, words[zr[i]], hr[1], sr[i])\n    } else if (i < 48) {\n      tl = fn3(al, bl, cl, dl, el, words[zl[i]], hl[2], sl[i])\n      tr = fn3(ar, br, cr, dr, er, words[zr[i]], hr[2], sr[i])\n    } else if (i < 64) {\n      tl = fn4(al, bl, cl, dl, el, words[zl[i]], hl[3], sl[i])\n      tr = fn2(ar, br, cr, dr, er, words[zr[i]], hr[3], sr[i])\n    } else { // if (i<80) {\n      tl = fn5(al, bl, cl, dl, el, words[zl[i]], hl[4], sl[i])\n      tr = fn1(ar, br, cr, dr, er, words[zr[i]], hr[4], sr[i])\n    }\n\n    al = el\n    el = dl\n    dl = rotl(cl, 10)\n    cl = bl\n    bl = tl\n\n    ar = er\n    er = dr\n    dr = rotl(cr, 10)\n    cr = br\n    br = tr\n  }\n\n  // update state\n  var t = (this._b + cl + dr) | 0\n  this._b = (this._c + dl + er) | 0\n  this._c = (this._d + el + ar) | 0\n  this._d = (this._e + al + br) | 0\n  this._e = (this._a + bl + cr) | 0\n  this._a = t\n}\n\nRIPEMD160.prototype._digest = function () {\n  // create padding and handle blocks\n  this._block[this._blockOffset++] = 0x80\n  if (this._blockOffset > 56) {\n    this._block.fill(0, this._blockOffset, 64)\n    this._update()\n    this._blockOffset = 0\n  }\n\n  this._block.fill(0, this._blockOffset, 56)\n  this._block.writeUInt32LE(this._length[0], 56)\n  this._block.writeUInt32LE(this._length[1], 60)\n  this._update()\n\n  // produce result\n  var buffer = Buffer.alloc ? Buffer.alloc(20) : new Buffer(20)\n  buffer.writeInt32LE(this._a, 0)\n  buffer.writeInt32LE(this._b, 4)\n  buffer.writeInt32LE(this._c, 8)\n  buffer.writeInt32LE(this._d, 12)\n  buffer.writeInt32LE(this._e, 16)\n  return buffer\n}\n\nfunction rotl (x, n) {\n  return (x << n) | (x >>> (32 - n))\n}\n\nfunction fn1 (a, b, c, d, e, m, k, s) {\n  return (rotl((a + (b ^ c ^ d) + m + k) | 0, s) + e) | 0\n}\n\nfunction fn2 (a, b, c, d, e, m, k, s) {\n  return (rotl((a + ((b & c) | ((~b) & d)) + m + k) | 0, s) + e) | 0\n}\n\nfunction fn3 (a, b, c, d, e, m, k, s) {\n  return (rotl((a + ((b | (~c)) ^ d) + m + k) | 0, s) + e) | 0\n}\n\nfunction fn4 (a, b, c, d, e, m, k, s) {\n  return (rotl((a + ((b & d) | (c & (~d))) + m + k) | 0, s) + e) | 0\n}\n\nfunction fn5 (a, b, c, d, e, m, k, s) {\n  return (rotl((a + (b ^ (c | (~d))) + m + k) | 0, s) + e) | 0\n}\n\nmodule.exports = RIPEMD160\n","/*! safe-buffer. MIT License. Feross Aboukhadijeh <https://feross.org/opensource> */\n/* eslint-disable node/no-deprecated-api */\nvar buffer = require('buffer')\nvar Buffer = buffer.Buffer\n\n// alternative to using Object.keys for old browsers\nfunction copyProps (src, dst) {\n  for (var key in src) {\n    dst[key] = src[key]\n  }\n}\nif (Buffer.from && Buffer.alloc && Buffer.allocUnsafe && Buffer.allocUnsafeSlow) {\n  module.exports = buffer\n} else {\n  // Copy properties from require('buffer')\n  copyProps(buffer, exports)\n  exports.Buffer = SafeBuffer\n}\n\nfunction SafeBuffer (arg, encodingOrOffset, length) {\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.prototype = Object.create(Buffer.prototype)\n\n// Copy static methods from Buffer\ncopyProps(Buffer, SafeBuffer)\n\nSafeBuffer.from = function (arg, encodingOrOffset, length) {\n  if (typeof arg === 'number') {\n    throw new TypeError('Argument must not be a number')\n  }\n  return Buffer(arg, encodingOrOffset, length)\n}\n\nSafeBuffer.alloc = function (size, fill, encoding) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  var buf = Buffer(size)\n  if (fill !== undefined) {\n    if (typeof encoding === 'string') {\n      buf.fill(fill, encoding)\n    } else {\n      buf.fill(fill)\n    }\n  } else {\n    buf.fill(0)\n  }\n  return buf\n}\n\nSafeBuffer.allocUnsafe = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return Buffer(size)\n}\n\nSafeBuffer.allocUnsafeSlow = function (size) {\n  if (typeof size !== 'number') {\n    throw new TypeError('Argument must be a number')\n  }\n  return buffer.SlowBuffer(size)\n}\n","module.exports = require('./lib')(require('./lib/elliptic'))\n","const EC = require('elliptic').ec\n\nconst ec = new EC('secp256k1')\nconst ecparams = ec.curve\n\n// Hack, we can not use bn.js@5, while elliptic uses bn.js@4\n// See https://github.com/indutny/elliptic/issues/191#issuecomment-569888758\nconst BN = ecparams.n.constructor\n\nfunction loadCompressedPublicKey (first, xbuf) {\n  let x = new BN(xbuf)\n\n  // overflow\n  if (x.cmp(ecparams.p) >= 0) return null\n  x = x.toRed(ecparams.red)\n\n  // compute corresponding Y\n  let y = x.redSqr().redIMul(x).redIAdd(ecparams.b).redSqrt()\n  if ((first === 0x03) !== y.isOdd()) y = y.redNeg()\n\n  return ec.keyPair({ pub: { x: x, y: y } })\n}\n\nfunction loadUncompressedPublicKey (first, xbuf, ybuf) {\n  let x = new BN(xbuf)\n  let y = new BN(ybuf)\n\n  // overflow\n  if (x.cmp(ecparams.p) >= 0 || y.cmp(ecparams.p) >= 0) return null\n\n  x = x.toRed(ecparams.red)\n  y = y.toRed(ecparams.red)\n\n  // is odd flag\n  if ((first === 0x06 || first === 0x07) && y.isOdd() !== (first === 0x07)) return null\n\n  // x*x*x + b = y*y\n  const x3 = x.redSqr().redIMul(x)\n  if (!y.redSqr().redISub(x3.redIAdd(ecparams.b)).isZero()) return null\n\n  return ec.keyPair({ pub: { x: x, y: y } })\n}\n\nfunction loadPublicKey (pubkey) {\n  // length should be validated in interface\n  const first = pubkey[0]\n  switch (first) {\n    case 0x02:\n    case 0x03:\n      if (pubkey.length !== 33) return null\n      return loadCompressedPublicKey(first, pubkey.subarray(1, 33))\n    case 0x04:\n    case 0x06:\n    case 0x07:\n      if (pubkey.length !== 65) return null\n      return loadUncompressedPublicKey(first, pubkey.subarray(1, 33), pubkey.subarray(33, 65))\n    default:\n      return null\n  }\n}\n\nfunction savePublicKey (output, point) {\n  const pubkey = point.encode(null, output.length === 33)\n  // Loop should be faster because we do not need create extra Uint8Array\n  // output.set(new Uint8Array(pubkey))\n  for (let i = 0; i < output.length; ++i) output[i] = pubkey[i]\n}\n\nmodule.exports = {\n  contextRandomize () {\n    return 0\n  },\n\n  privateKeyVerify (seckey) {\n    const bn = new BN(seckey)\n    return bn.cmp(ecparams.n) < 0 && !bn.isZero() ? 0 : 1\n  },\n\n  privateKeyNegate (seckey) {\n    const bn = new BN(seckey)\n    const negate = ecparams.n.sub(bn).umod(ecparams.n).toArrayLike(Uint8Array, 'be', 32)\n    seckey.set(negate)\n    return 0\n  },\n\n  privateKeyTweakAdd (seckey, tweak) {\n    const bn = new BN(tweak)\n    if (bn.cmp(ecparams.n) >= 0) return 1\n\n    bn.iadd(new BN(seckey))\n    if (bn.cmp(ecparams.n) >= 0) bn.isub(ecparams.n)\n    if (bn.isZero()) return 1\n\n    const tweaked = bn.toArrayLike(Uint8Array, 'be', 32)\n    seckey.set(tweaked)\n\n    return 0\n  },\n\n  privateKeyTweakMul (seckey, tweak) {\n    let bn = new BN(tweak)\n    if (bn.cmp(ecparams.n) >= 0 || bn.isZero()) return 1\n\n    bn.imul(new BN(seckey))\n    if (bn.cmp(ecparams.n) >= 0) bn = bn.umod(ecparams.n)\n\n    const tweaked = bn.toArrayLike(Uint8Array, 'be', 32)\n    seckey.set(tweaked)\n\n    return 0\n  },\n\n  publicKeyVerify (pubkey) {\n    const pair = loadPublicKey(pubkey)\n    return pair === null ? 1 : 0\n  },\n\n  publicKeyCreate (output, seckey) {\n    const bn = new BN(seckey)\n    if (bn.cmp(ecparams.n) >= 0 || bn.isZero()) return 1\n\n    const point = ec.keyFromPrivate(seckey).getPublic()\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  publicKeyConvert (output, pubkey) {\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 1\n\n    const point = pair.getPublic()\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  publicKeyNegate (output, pubkey) {\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 1\n\n    const point = pair.getPublic()\n    point.y = point.y.redNeg()\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  publicKeyCombine (output, pubkeys) {\n    const pairs = new Array(pubkeys.length)\n    for (let i = 0; i < pubkeys.length; ++i) {\n      pairs[i] = loadPublicKey(pubkeys[i])\n      if (pairs[i] === null) return 1\n    }\n\n    let point = pairs[0].getPublic()\n    for (let i = 1; i < pairs.length; ++i) point = point.add(pairs[i].pub)\n    if (point.isInfinity()) return 2\n\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  publicKeyTweakAdd (output, pubkey, tweak) {\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 1\n\n    tweak = new BN(tweak)\n    if (tweak.cmp(ecparams.n) >= 0) return 2\n\n    const point = pair.getPublic().add(ecparams.g.mul(tweak))\n    if (point.isInfinity()) return 2\n\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  publicKeyTweakMul (output, pubkey, tweak) {\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 1\n\n    tweak = new BN(tweak)\n    if (tweak.cmp(ecparams.n) >= 0 || tweak.isZero()) return 2\n\n    const point = pair.getPublic().mul(tweak)\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  signatureNormalize (sig) {\n    const r = new BN(sig.subarray(0, 32))\n    const s = new BN(sig.subarray(32, 64))\n    if (r.cmp(ecparams.n) >= 0 || s.cmp(ecparams.n) >= 0) return 1\n\n    if (s.cmp(ec.nh) === 1) {\n      sig.set(ecparams.n.sub(s).toArrayLike(Uint8Array, 'be', 32), 32)\n    }\n\n    return 0\n  },\n\n  // Copied 1-to-1 from https://github.com/bitcoinjs/bip66/blob/master/index.js\n  // Adapted for Uint8Array instead Buffer\n  signatureExport (obj, sig) {\n    const sigR = sig.subarray(0, 32)\n    const sigS = sig.subarray(32, 64)\n    if (new BN(sigR).cmp(ecparams.n) >= 0) return 1\n    if (new BN(sigS).cmp(ecparams.n) >= 0) return 1\n\n    const { output } = obj\n\n    // Prepare R\n    let r = output.subarray(4, 4 + 33)\n    r[0] = 0x00\n    r.set(sigR, 1)\n\n    let lenR = 33\n    let posR = 0\n    for (; lenR > 1 && r[posR] === 0x00 && !(r[posR + 1] & 0x80); --lenR, ++posR);\n\n    r = r.subarray(posR)\n    if (r[0] & 0x80) return 1\n    if (lenR > 1 && (r[0] === 0x00) && !(r[1] & 0x80)) return 1\n\n    // Prepare S\n    let s = output.subarray(6 + 33, 6 + 33 + 33)\n    s[0] = 0x00\n    s.set(sigS, 1)\n\n    let lenS = 33\n    let posS = 0\n    for (; lenS > 1 && s[posS] === 0x00 && !(s[posS + 1] & 0x80); --lenS, ++posS);\n\n    s = s.subarray(posS)\n    if (s[0] & 0x80) return 1\n    if (lenS > 1 && (s[0] === 0x00) && !(s[1] & 0x80)) return 1\n\n    // Set output length for return\n    obj.outputlen = 6 + lenR + lenS\n\n    // Output in specified format\n    // 0x30 [total-length] 0x02 [R-length] [R] 0x02 [S-length] [S]\n    output[0] = 0x30\n    output[1] = obj.outputlen - 2\n    output[2] = 0x02\n    output[3] = r.length\n    output.set(r, 4)\n    output[4 + lenR] = 0x02\n    output[5 + lenR] = s.length\n    output.set(s, 6 + lenR)\n\n    return 0\n  },\n\n  // Copied 1-to-1 from https://github.com/bitcoinjs/bip66/blob/master/index.js\n  // Adapted for Uint8Array instead Buffer\n  signatureImport (output, sig) {\n    if (sig.length < 8) return 1\n    if (sig.length > 72) return 1\n    if (sig[0] !== 0x30) return 1\n    if (sig[1] !== sig.length - 2) return 1\n    if (sig[2] !== 0x02) return 1\n\n    const lenR = sig[3]\n    if (lenR === 0) return 1\n    if (5 + lenR >= sig.length) return 1\n    if (sig[4 + lenR] !== 0x02) return 1\n\n    const lenS = sig[5 + lenR]\n    if (lenS === 0) return 1\n    if ((6 + lenR + lenS) !== sig.length) return 1\n\n    if (sig[4] & 0x80) return 1\n    if (lenR > 1 && (sig[4] === 0x00) && !(sig[5] & 0x80)) return 1\n\n    if (sig[lenR + 6] & 0x80) return 1\n    if (lenS > 1 && (sig[lenR + 6] === 0x00) && !(sig[lenR + 7] & 0x80)) return 1\n\n    let sigR = sig.subarray(4, 4 + lenR)\n    if (sigR.length === 33 && sigR[0] === 0x00) sigR = sigR.subarray(1)\n    if (sigR.length > 32) return 1\n\n    let sigS = sig.subarray(6 + lenR)\n    if (sigS.length === 33 && sigS[0] === 0x00) sigS = sigS.slice(1)\n    if (sigS.length > 32) throw new Error('S length is too long')\n\n    let r = new BN(sigR)\n    if (r.cmp(ecparams.n) >= 0) r = new BN(0)\n\n    let s = new BN(sig.subarray(6 + lenR))\n    if (s.cmp(ecparams.n) >= 0) s = new BN(0)\n\n    output.set(r.toArrayLike(Uint8Array, 'be', 32), 0)\n    output.set(s.toArrayLike(Uint8Array, 'be', 32), 32)\n\n    return 0\n  },\n\n  ecdsaSign (obj, message, seckey, data, noncefn) {\n    if (noncefn) {\n      const _noncefn = noncefn\n      noncefn = (counter) => {\n        const nonce = _noncefn(message, seckey, null, data, counter)\n\n        const isValid = nonce instanceof Uint8Array && nonce.length === 32\n        if (!isValid) throw new Error('This is the way')\n\n        return new BN(nonce)\n      }\n    }\n\n    const d = new BN(seckey)\n    if (d.cmp(ecparams.n) >= 0 || d.isZero()) return 1\n\n    let sig\n    try {\n      sig = ec.sign(message, seckey, { canonical: true, k: noncefn, pers: data })\n    } catch (err) {\n      return 1\n    }\n\n    obj.signature.set(sig.r.toArrayLike(Uint8Array, 'be', 32), 0)\n    obj.signature.set(sig.s.toArrayLike(Uint8Array, 'be', 32), 32)\n    obj.recid = sig.recoveryParam\n\n    return 0\n  },\n\n  ecdsaVerify (sig, msg32, pubkey) {\n    const sigObj = { r: sig.subarray(0, 32), s: sig.subarray(32, 64) }\n\n    const sigr = new BN(sigObj.r)\n    const sigs = new BN(sigObj.s)\n    if (sigr.cmp(ecparams.n) >= 0 || sigs.cmp(ecparams.n) >= 0) return 1\n    if (sigs.cmp(ec.nh) === 1 || sigr.isZero() || sigs.isZero()) return 3\n\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 2\n\n    const point = pair.getPublic()\n    const isValid = ec.verify(msg32, sigObj, point)\n    return isValid ? 0 : 3\n  },\n\n  ecdsaRecover (output, sig, recid, msg32) {\n    const sigObj = { r: sig.slice(0, 32), s: sig.slice(32, 64) }\n\n    const sigr = new BN(sigObj.r)\n    const sigs = new BN(sigObj.s)\n    if (sigr.cmp(ecparams.n) >= 0 || sigs.cmp(ecparams.n) >= 0) return 1\n\n    if (sigr.isZero() || sigs.isZero()) return 2\n\n    // Can throw `throw new Error('Unable to find sencond key candinate');`\n    let point\n    try {\n      point = ec.recoverPubKey(msg32, sigObj, recid)\n    } catch (err) {\n      return 2\n    }\n\n    savePublicKey(output, point)\n\n    return 0\n  },\n\n  ecdh (output, pubkey, seckey, data, hashfn, xbuf, ybuf) {\n    const pair = loadPublicKey(pubkey)\n    if (pair === null) return 1\n\n    const scalar = new BN(seckey)\n    if (scalar.cmp(ecparams.n) >= 0 || scalar.isZero()) return 2\n\n    const point = pair.getPublic().mul(scalar)\n\n    if (hashfn === undefined) {\n      const data = point.encode(null, true)\n      const sha256 = ec.hash().update(data).digest()\n      for (let i = 0; i < 32; ++i) output[i] = sha256[i]\n    } else {\n      if (!xbuf) xbuf = new Uint8Array(32)\n      const x = point.getX().toArray('be', 32)\n      for (let i = 0; i < 32; ++i) xbuf[i] = x[i]\n\n      if (!ybuf) ybuf = new Uint8Array(32)\n      const y = point.getY().toArray('be', 32)\n      for (let i = 0; i < 32; ++i) ybuf[i] = y[i]\n\n      const hash = hashfn(xbuf, ybuf, data)\n\n      const isValid = hash instanceof Uint8Array && hash.length === output.length\n      if (!isValid) return 2\n\n      output.set(hash)\n    }\n\n    return 0\n  }\n}\n","const errors = {\n  IMPOSSIBLE_CASE: 'Impossible case. Please create issue.',\n  TWEAK_ADD:\n    'The tweak was out of range or the resulted private key is invalid',\n  TWEAK_MUL: 'The tweak was out of range or equal to zero',\n  CONTEXT_RANDOMIZE_UNKNOW: 'Unknow error on context randomization',\n  SECKEY_INVALID: 'Private Key is invalid',\n  PUBKEY_PARSE: 'Public Key could not be parsed',\n  PUBKEY_SERIALIZE: 'Public Key serialization error',\n  PUBKEY_COMBINE: 'The sum of the public keys is not valid',\n  SIG_PARSE: 'Signature could not be parsed',\n  SIGN: 'The nonce generation function failed, or the private key was invalid',\n  RECOVER: 'Public key could not be recover',\n  ECDH: 'Scalar was invalid (zero or overflow)'\n}\n\nfunction assert (cond, msg) {\n  if (!cond) throw new Error(msg)\n}\n\nfunction isUint8Array (name, value, length) {\n  assert(value instanceof Uint8Array, `Expected ${name} to be an Uint8Array`)\n\n  if (length !== undefined) {\n    if (Array.isArray(length)) {\n      const numbers = length.join(', ')\n      const msg = `Expected ${name} to be an Uint8Array with length [${numbers}]`\n      assert(length.includes(value.length), msg)\n    } else {\n      const msg = `Expected ${name} to be an Uint8Array with length ${length}`\n      assert(value.length === length, msg)\n    }\n  }\n}\n\nfunction isCompressed (value) {\n  assert(toTypeString(value) === 'Boolean', 'Expected compressed to be a Boolean')\n}\n\nfunction getAssertedOutput (output = (len) => new Uint8Array(len), length) {\n  if (typeof output === 'function') output = output(length)\n  isUint8Array('output', output, length)\n  return output\n}\n\nfunction toTypeString (value) {\n  return Object.prototype.toString.call(value).slice(8, -1)\n}\n\nmodule.exports = (secp256k1) => {\n  return {\n    contextRandomize (seed) {\n      assert(\n        seed === null || seed instanceof Uint8Array,\n        'Expected seed to be an Uint8Array or null'\n      )\n      if (seed !== null) isUint8Array('seed', seed, 32)\n\n      switch (secp256k1.contextRandomize(seed)) {\n        case 1:\n          throw new Error(errors.CONTEXT_RANDOMIZE_UNKNOW)\n      }\n    },\n\n    privateKeyVerify (seckey) {\n      isUint8Array('private key', seckey, 32)\n\n      return secp256k1.privateKeyVerify(seckey) === 0\n    },\n\n    privateKeyNegate (seckey) {\n      isUint8Array('private key', seckey, 32)\n\n      switch (secp256k1.privateKeyNegate(seckey)) {\n        case 0:\n          return seckey\n        case 1:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n      }\n    },\n\n    privateKeyTweakAdd (seckey, tweak) {\n      isUint8Array('private key', seckey, 32)\n      isUint8Array('tweak', tweak, 32)\n\n      switch (secp256k1.privateKeyTweakAdd(seckey, tweak)) {\n        case 0:\n          return seckey\n        case 1:\n          throw new Error(errors.TWEAK_ADD)\n      }\n    },\n\n    privateKeyTweakMul (seckey, tweak) {\n      isUint8Array('private key', seckey, 32)\n      isUint8Array('tweak', tweak, 32)\n\n      switch (secp256k1.privateKeyTweakMul(seckey, tweak)) {\n        case 0:\n          return seckey\n        case 1:\n          throw new Error(errors.TWEAK_MUL)\n      }\n    },\n\n    publicKeyVerify (pubkey) {\n      isUint8Array('public key', pubkey, [33, 65])\n\n      return secp256k1.publicKeyVerify(pubkey) === 0\n    },\n\n    publicKeyCreate (seckey, compressed = true, output) {\n      isUint8Array('private key', seckey, 32)\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyCreate(output, seckey)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.SECKEY_INVALID)\n        case 2:\n          throw new Error(errors.PUBKEY_SERIALIZE)\n      }\n    },\n\n    publicKeyConvert (pubkey, compressed = true, output) {\n      isUint8Array('public key', pubkey, [33, 65])\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyConvert(output, pubkey)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.PUBKEY_SERIALIZE)\n      }\n    },\n\n    publicKeyNegate (pubkey, compressed = true, output) {\n      isUint8Array('public key', pubkey, [33, 65])\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyNegate(output, pubkey)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n        case 3:\n          throw new Error(errors.PUBKEY_SERIALIZE)\n      }\n    },\n\n    publicKeyCombine (pubkeys, compressed = true, output) {\n      assert(Array.isArray(pubkeys), 'Expected public keys to be an Array')\n      assert(pubkeys.length > 0, 'Expected public keys array will have more than zero items')\n      for (const pubkey of pubkeys) {\n        isUint8Array('public key', pubkey, [33, 65])\n      }\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyCombine(output, pubkeys)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.PUBKEY_COMBINE)\n        case 3:\n          throw new Error(errors.PUBKEY_SERIALIZE)\n      }\n    },\n\n    publicKeyTweakAdd (pubkey, tweak, compressed = true, output) {\n      isUint8Array('public key', pubkey, [33, 65])\n      isUint8Array('tweak', tweak, 32)\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyTweakAdd(output, pubkey, tweak)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.TWEAK_ADD)\n      }\n    },\n\n    publicKeyTweakMul (pubkey, tweak, compressed = true, output) {\n      isUint8Array('public key', pubkey, [33, 65])\n      isUint8Array('tweak', tweak, 32)\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.publicKeyTweakMul(output, pubkey, tweak)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.TWEAK_MUL)\n      }\n    },\n\n    signatureNormalize (sig) {\n      isUint8Array('signature', sig, 64)\n\n      switch (secp256k1.signatureNormalize(sig)) {\n        case 0:\n          return sig\n        case 1:\n          throw new Error(errors.SIG_PARSE)\n      }\n    },\n\n    signatureExport (sig, output) {\n      isUint8Array('signature', sig, 64)\n      output = getAssertedOutput(output, 72)\n\n      const obj = { output, outputlen: 72 }\n      switch (secp256k1.signatureExport(obj, sig)) {\n        case 0:\n          return output.slice(0, obj.outputlen)\n        case 1:\n          throw new Error(errors.SIG_PARSE)\n        case 2:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n      }\n    },\n\n    signatureImport (sig, output) {\n      isUint8Array('signature', sig)\n      output = getAssertedOutput(output, 64)\n\n      switch (secp256k1.signatureImport(output, sig)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.SIG_PARSE)\n        case 2:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n      }\n    },\n\n    ecdsaSign (msg32, seckey, options = {}, output) {\n      isUint8Array('message', msg32, 32)\n      isUint8Array('private key', seckey, 32)\n      assert(toTypeString(options) === 'Object', 'Expected options to be an Object')\n      if (options.data !== undefined) isUint8Array('options.data', options.data)\n      if (options.noncefn !== undefined) assert(toTypeString(options.noncefn) === 'Function', 'Expected options.noncefn to be a Function')\n      output = getAssertedOutput(output, 64)\n\n      const obj = { signature: output, recid: null }\n      switch (secp256k1.ecdsaSign(obj, msg32, seckey, options.data, options.noncefn)) {\n        case 0:\n          return obj\n        case 1:\n          throw new Error(errors.SIGN)\n        case 2:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n      }\n    },\n\n    ecdsaVerify (sig, msg32, pubkey) {\n      isUint8Array('signature', sig, 64)\n      isUint8Array('message', msg32, 32)\n      isUint8Array('public key', pubkey, [33, 65])\n\n      switch (secp256k1.ecdsaVerify(sig, msg32, pubkey)) {\n        case 0:\n          return true\n        case 3:\n          return false\n        case 1:\n          throw new Error(errors.SIG_PARSE)\n        case 2:\n          throw new Error(errors.PUBKEY_PARSE)\n      }\n    },\n\n    ecdsaRecover (sig, recid, msg32, compressed = true, output) {\n      isUint8Array('signature', sig, 64)\n      assert(\n        toTypeString(recid) === 'Number' &&\n          recid >= 0 &&\n          recid <= 3,\n        'Expected recovery id to be a Number within interval [0, 3]'\n      )\n      isUint8Array('message', msg32, 32)\n      isCompressed(compressed)\n      output = getAssertedOutput(output, compressed ? 33 : 65)\n\n      switch (secp256k1.ecdsaRecover(output, sig, recid, msg32)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.SIG_PARSE)\n        case 2:\n          throw new Error(errors.RECOVER)\n        case 3:\n          throw new Error(errors.IMPOSSIBLE_CASE)\n      }\n    },\n\n    ecdh (pubkey, seckey, options = {}, output) {\n      isUint8Array('public key', pubkey, [33, 65])\n      isUint8Array('private key', seckey, 32)\n      assert(toTypeString(options) === 'Object', 'Expected options to be an Object')\n      if (options.data !== undefined) isUint8Array('options.data', options.data)\n      if (options.hashfn !== undefined) {\n        assert(toTypeString(options.hashfn) === 'Function', 'Expected options.hashfn to be a Function')\n        if (options.xbuf !== undefined) isUint8Array('options.xbuf', options.xbuf, 32)\n        if (options.ybuf !== undefined) isUint8Array('options.ybuf', options.ybuf, 32)\n        isUint8Array('output', output)\n      } else {\n        output = getAssertedOutput(output, 32)\n      }\n\n      switch (secp256k1.ecdh(output, pubkey, seckey, options.data, options.hashfn, options.xbuf, options.ybuf)) {\n        case 0:\n          return output\n        case 1:\n          throw new Error(errors.PUBKEY_PARSE)\n        case 2:\n          throw new Error(errors.ECDH)\n      }\n    }\n  }\n}\n","var Buffer = require('safe-buffer').Buffer\n\n// prototype class for hash functions\nfunction Hash (blockSize, finalSize) {\n  this._block = Buffer.alloc(blockSize)\n  this._finalSize = finalSize\n  this._blockSize = blockSize\n  this._len = 0\n}\n\nHash.prototype.update = function (data, enc) {\n  if (typeof data === 'string') {\n    enc = enc || 'utf8'\n    data = Buffer.from(data, enc)\n  }\n\n  var block = this._block\n  var blockSize = this._blockSize\n  var length = data.length\n  var accum = this._len\n\n  for (var offset = 0; offset < length;) {\n    var assigned = accum % blockSize\n    var remainder = Math.min(length - offset, blockSize - assigned)\n\n    for (var i = 0; i < remainder; i++) {\n      block[assigned + i] = data[offset + i]\n    }\n\n    accum += remainder\n    offset += remainder\n\n    if ((accum % blockSize) === 0) {\n      this._update(block)\n    }\n  }\n\n  this._len += length\n  return this\n}\n\nHash.prototype.digest = function (enc) {\n  var rem = this._len % this._blockSize\n\n  this._block[rem] = 0x80\n\n  // zero (rem + 1) trailing bits, where (rem + 1) is the smallest\n  // non-negative solution to the equation (length + 1 + (rem + 1)) === finalSize mod blockSize\n  this._block.fill(0, rem + 1)\n\n  if (rem >= this._finalSize) {\n    this._update(this._block)\n    this._block.fill(0)\n  }\n\n  var bits = this._len * 8\n\n  // uint32\n  if (bits <= 0xffffffff) {\n    this._block.writeUInt32BE(bits, this._blockSize - 4)\n\n  // uint64\n  } else {\n    var lowBits = (bits & 0xffffffff) >>> 0\n    var highBits = (bits - lowBits) / 0x100000000\n\n    this._block.writeUInt32BE(highBits, this._blockSize - 8)\n    this._block.writeUInt32BE(lowBits, this._blockSize - 4)\n  }\n\n  this._update(this._block)\n  var hash = this._hash()\n\n  return enc ? hash.toString(enc) : hash\n}\n\nHash.prototype._update = function () {\n  throw new Error('_update must be implemented by subclass')\n}\n\nmodule.exports = Hash\n","var exports = module.exports = function SHA (algorithm) {\n  algorithm = algorithm.toLowerCase()\n\n  var Algorithm = exports[algorithm]\n  if (!Algorithm) throw new Error(algorithm + ' is not supported (we accept pull requests)')\n\n  return new Algorithm()\n}\n\nexports.sha = require('./sha')\nexports.sha1 = require('./sha1')\nexports.sha224 = require('./sha224')\nexports.sha256 = require('./sha256')\nexports.sha384 = require('./sha384')\nexports.sha512 = require('./sha512')\n","/*\n * A JavaScript implementation of the Secure Hash Algorithm, SHA-0, as defined\n * in FIPS PUB 180-1\n * This source code is derived from sha1.js of the same repository.\n * The difference between SHA-0 and SHA-1 is just a bitwise rotate left\n * operation was added.\n */\n\nvar inherits = require('inherits')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar K = [\n  0x5a827999, 0x6ed9eba1, 0x8f1bbcdc | 0, 0xca62c1d6 | 0\n]\n\nvar W = new Array(80)\n\nfunction Sha () {\n  this.init()\n  this._w = W\n\n  Hash.call(this, 64, 56)\n}\n\ninherits(Sha, Hash)\n\nSha.prototype.init = function () {\n  this._a = 0x67452301\n  this._b = 0xefcdab89\n  this._c = 0x98badcfe\n  this._d = 0x10325476\n  this._e = 0xc3d2e1f0\n\n  return this\n}\n\nfunction rotl5 (num) {\n  return (num << 5) | (num >>> 27)\n}\n\nfunction rotl30 (num) {\n  return (num << 30) | (num >>> 2)\n}\n\nfunction ft (s, b, c, d) {\n  if (s === 0) return (b & c) | ((~b) & d)\n  if (s === 2) return (b & c) | (b & d) | (c & d)\n  return b ^ c ^ d\n}\n\nSha.prototype._update = function (M) {\n  var W = this._w\n\n  var a = this._a | 0\n  var b = this._b | 0\n  var c = this._c | 0\n  var d = this._d | 0\n  var e = this._e | 0\n\n  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)\n  for (; i < 80; ++i) W[i] = W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16]\n\n  for (var j = 0; j < 80; ++j) {\n    var s = ~~(j / 20)\n    var t = (rotl5(a) + ft(s, b, c, d) + e + W[j] + K[s]) | 0\n\n    e = d\n    d = c\n    c = rotl30(b)\n    b = a\n    a = t\n  }\n\n  this._a = (a + this._a) | 0\n  this._b = (b + this._b) | 0\n  this._c = (c + this._c) | 0\n  this._d = (d + this._d) | 0\n  this._e = (e + this._e) | 0\n}\n\nSha.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(20)\n\n  H.writeInt32BE(this._a | 0, 0)\n  H.writeInt32BE(this._b | 0, 4)\n  H.writeInt32BE(this._c | 0, 8)\n  H.writeInt32BE(this._d | 0, 12)\n  H.writeInt32BE(this._e | 0, 16)\n\n  return H\n}\n\nmodule.exports = Sha\n","/*\n * A JavaScript implementation of the Secure Hash Algorithm, SHA-1, as defined\n * in FIPS PUB 180-1\n * Version 2.1a Copyright Paul Johnston 2000 - 2002.\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n * Distributed under the BSD License\n * See http://pajhome.org.uk/crypt/md5 for details.\n */\n\nvar inherits = require('inherits')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar K = [\n  0x5a827999, 0x6ed9eba1, 0x8f1bbcdc | 0, 0xca62c1d6 | 0\n]\n\nvar W = new Array(80)\n\nfunction Sha1 () {\n  this.init()\n  this._w = W\n\n  Hash.call(this, 64, 56)\n}\n\ninherits(Sha1, Hash)\n\nSha1.prototype.init = function () {\n  this._a = 0x67452301\n  this._b = 0xefcdab89\n  this._c = 0x98badcfe\n  this._d = 0x10325476\n  this._e = 0xc3d2e1f0\n\n  return this\n}\n\nfunction rotl1 (num) {\n  return (num << 1) | (num >>> 31)\n}\n\nfunction rotl5 (num) {\n  return (num << 5) | (num >>> 27)\n}\n\nfunction rotl30 (num) {\n  return (num << 30) | (num >>> 2)\n}\n\nfunction ft (s, b, c, d) {\n  if (s === 0) return (b & c) | ((~b) & d)\n  if (s === 2) return (b & c) | (b & d) | (c & d)\n  return b ^ c ^ d\n}\n\nSha1.prototype._update = function (M) {\n  var W = this._w\n\n  var a = this._a | 0\n  var b = this._b | 0\n  var c = this._c | 0\n  var d = this._d | 0\n  var e = this._e | 0\n\n  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)\n  for (; i < 80; ++i) W[i] = rotl1(W[i - 3] ^ W[i - 8] ^ W[i - 14] ^ W[i - 16])\n\n  for (var j = 0; j < 80; ++j) {\n    var s = ~~(j / 20)\n    var t = (rotl5(a) + ft(s, b, c, d) + e + W[j] + K[s]) | 0\n\n    e = d\n    d = c\n    c = rotl30(b)\n    b = a\n    a = t\n  }\n\n  this._a = (a + this._a) | 0\n  this._b = (b + this._b) | 0\n  this._c = (c + this._c) | 0\n  this._d = (d + this._d) | 0\n  this._e = (e + this._e) | 0\n}\n\nSha1.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(20)\n\n  H.writeInt32BE(this._a | 0, 0)\n  H.writeInt32BE(this._b | 0, 4)\n  H.writeInt32BE(this._c | 0, 8)\n  H.writeInt32BE(this._d | 0, 12)\n  H.writeInt32BE(this._e | 0, 16)\n\n  return H\n}\n\nmodule.exports = Sha1\n","/**\n * A JavaScript implementation of the Secure Hash Algorithm, SHA-256, as defined\n * in FIPS 180-2\n * Version 2.2-beta Copyright Angel Marin, Paul Johnston 2000 - 2009.\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n *\n */\n\nvar inherits = require('inherits')\nvar Sha256 = require('./sha256')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar W = new Array(64)\n\nfunction Sha224 () {\n  this.init()\n\n  this._w = W // new Array(64)\n\n  Hash.call(this, 64, 56)\n}\n\ninherits(Sha224, Sha256)\n\nSha224.prototype.init = function () {\n  this._a = 0xc1059ed8\n  this._b = 0x367cd507\n  this._c = 0x3070dd17\n  this._d = 0xf70e5939\n  this._e = 0xffc00b31\n  this._f = 0x68581511\n  this._g = 0x64f98fa7\n  this._h = 0xbefa4fa4\n\n  return this\n}\n\nSha224.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(28)\n\n  H.writeInt32BE(this._a, 0)\n  H.writeInt32BE(this._b, 4)\n  H.writeInt32BE(this._c, 8)\n  H.writeInt32BE(this._d, 12)\n  H.writeInt32BE(this._e, 16)\n  H.writeInt32BE(this._f, 20)\n  H.writeInt32BE(this._g, 24)\n\n  return H\n}\n\nmodule.exports = Sha224\n","/**\n * A JavaScript implementation of the Secure Hash Algorithm, SHA-256, as defined\n * in FIPS 180-2\n * Version 2.2-beta Copyright Angel Marin, Paul Johnston 2000 - 2009.\n * Other contributors: Greg Holt, Andrew Kepert, Ydnar, Lostinet\n *\n */\n\nvar inherits = require('inherits')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar K = [\n  0x428A2F98, 0x71374491, 0xB5C0FBCF, 0xE9B5DBA5,\n  0x3956C25B, 0x59F111F1, 0x923F82A4, 0xAB1C5ED5,\n  0xD807AA98, 0x12835B01, 0x243185BE, 0x550C7DC3,\n  0x72BE5D74, 0x80DEB1FE, 0x9BDC06A7, 0xC19BF174,\n  0xE49B69C1, 0xEFBE4786, 0x0FC19DC6, 0x240CA1CC,\n  0x2DE92C6F, 0x4A7484AA, 0x5CB0A9DC, 0x76F988DA,\n  0x983E5152, 0xA831C66D, 0xB00327C8, 0xBF597FC7,\n  0xC6E00BF3, 0xD5A79147, 0x06CA6351, 0x14292967,\n  0x27B70A85, 0x2E1B2138, 0x4D2C6DFC, 0x53380D13,\n  0x650A7354, 0x766A0ABB, 0x81C2C92E, 0x92722C85,\n  0xA2BFE8A1, 0xA81A664B, 0xC24B8B70, 0xC76C51A3,\n  0xD192E819, 0xD6990624, 0xF40E3585, 0x106AA070,\n  0x19A4C116, 0x1E376C08, 0x2748774C, 0x34B0BCB5,\n  0x391C0CB3, 0x4ED8AA4A, 0x5B9CCA4F, 0x682E6FF3,\n  0x748F82EE, 0x78A5636F, 0x84C87814, 0x8CC70208,\n  0x90BEFFFA, 0xA4506CEB, 0xBEF9A3F7, 0xC67178F2\n]\n\nvar W = new Array(64)\n\nfunction Sha256 () {\n  this.init()\n\n  this._w = W // new Array(64)\n\n  Hash.call(this, 64, 56)\n}\n\ninherits(Sha256, Hash)\n\nSha256.prototype.init = function () {\n  this._a = 0x6a09e667\n  this._b = 0xbb67ae85\n  this._c = 0x3c6ef372\n  this._d = 0xa54ff53a\n  this._e = 0x510e527f\n  this._f = 0x9b05688c\n  this._g = 0x1f83d9ab\n  this._h = 0x5be0cd19\n\n  return this\n}\n\nfunction ch (x, y, z) {\n  return z ^ (x & (y ^ z))\n}\n\nfunction maj (x, y, z) {\n  return (x & y) | (z & (x | y))\n}\n\nfunction sigma0 (x) {\n  return (x >>> 2 | x << 30) ^ (x >>> 13 | x << 19) ^ (x >>> 22 | x << 10)\n}\n\nfunction sigma1 (x) {\n  return (x >>> 6 | x << 26) ^ (x >>> 11 | x << 21) ^ (x >>> 25 | x << 7)\n}\n\nfunction gamma0 (x) {\n  return (x >>> 7 | x << 25) ^ (x >>> 18 | x << 14) ^ (x >>> 3)\n}\n\nfunction gamma1 (x) {\n  return (x >>> 17 | x << 15) ^ (x >>> 19 | x << 13) ^ (x >>> 10)\n}\n\nSha256.prototype._update = function (M) {\n  var W = this._w\n\n  var a = this._a | 0\n  var b = this._b | 0\n  var c = this._c | 0\n  var d = this._d | 0\n  var e = this._e | 0\n  var f = this._f | 0\n  var g = this._g | 0\n  var h = this._h | 0\n\n  for (var i = 0; i < 16; ++i) W[i] = M.readInt32BE(i * 4)\n  for (; i < 64; ++i) W[i] = (gamma1(W[i - 2]) + W[i - 7] + gamma0(W[i - 15]) + W[i - 16]) | 0\n\n  for (var j = 0; j < 64; ++j) {\n    var T1 = (h + sigma1(e) + ch(e, f, g) + K[j] + W[j]) | 0\n    var T2 = (sigma0(a) + maj(a, b, c)) | 0\n\n    h = g\n    g = f\n    f = e\n    e = (d + T1) | 0\n    d = c\n    c = b\n    b = a\n    a = (T1 + T2) | 0\n  }\n\n  this._a = (a + this._a) | 0\n  this._b = (b + this._b) | 0\n  this._c = (c + this._c) | 0\n  this._d = (d + this._d) | 0\n  this._e = (e + this._e) | 0\n  this._f = (f + this._f) | 0\n  this._g = (g + this._g) | 0\n  this._h = (h + this._h) | 0\n}\n\nSha256.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(32)\n\n  H.writeInt32BE(this._a, 0)\n  H.writeInt32BE(this._b, 4)\n  H.writeInt32BE(this._c, 8)\n  H.writeInt32BE(this._d, 12)\n  H.writeInt32BE(this._e, 16)\n  H.writeInt32BE(this._f, 20)\n  H.writeInt32BE(this._g, 24)\n  H.writeInt32BE(this._h, 28)\n\n  return H\n}\n\nmodule.exports = Sha256\n","var inherits = require('inherits')\nvar SHA512 = require('./sha512')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar W = new Array(160)\n\nfunction Sha384 () {\n  this.init()\n  this._w = W\n\n  Hash.call(this, 128, 112)\n}\n\ninherits(Sha384, SHA512)\n\nSha384.prototype.init = function () {\n  this._ah = 0xcbbb9d5d\n  this._bh = 0x629a292a\n  this._ch = 0x9159015a\n  this._dh = 0x152fecd8\n  this._eh = 0x67332667\n  this._fh = 0x8eb44a87\n  this._gh = 0xdb0c2e0d\n  this._hh = 0x47b5481d\n\n  this._al = 0xc1059ed8\n  this._bl = 0x367cd507\n  this._cl = 0x3070dd17\n  this._dl = 0xf70e5939\n  this._el = 0xffc00b31\n  this._fl = 0x68581511\n  this._gl = 0x64f98fa7\n  this._hl = 0xbefa4fa4\n\n  return this\n}\n\nSha384.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(48)\n\n  function writeInt64BE (h, l, offset) {\n    H.writeInt32BE(h, offset)\n    H.writeInt32BE(l, offset + 4)\n  }\n\n  writeInt64BE(this._ah, this._al, 0)\n  writeInt64BE(this._bh, this._bl, 8)\n  writeInt64BE(this._ch, this._cl, 16)\n  writeInt64BE(this._dh, this._dl, 24)\n  writeInt64BE(this._eh, this._el, 32)\n  writeInt64BE(this._fh, this._fl, 40)\n\n  return H\n}\n\nmodule.exports = Sha384\n","var inherits = require('inherits')\nvar Hash = require('./hash')\nvar Buffer = require('safe-buffer').Buffer\n\nvar K = [\n  0x428a2f98, 0xd728ae22, 0x71374491, 0x23ef65cd,\n  0xb5c0fbcf, 0xec4d3b2f, 0xe9b5dba5, 0x8189dbbc,\n  0x3956c25b, 0xf348b538, 0x59f111f1, 0xb605d019,\n  0x923f82a4, 0xaf194f9b, 0xab1c5ed5, 0xda6d8118,\n  0xd807aa98, 0xa3030242, 0x12835b01, 0x45706fbe,\n  0x243185be, 0x4ee4b28c, 0x550c7dc3, 0xd5ffb4e2,\n  0x72be5d74, 0xf27b896f, 0x80deb1fe, 0x3b1696b1,\n  0x9bdc06a7, 0x25c71235, 0xc19bf174, 0xcf692694,\n  0xe49b69c1, 0x9ef14ad2, 0xefbe4786, 0x384f25e3,\n  0x0fc19dc6, 0x8b8cd5b5, 0x240ca1cc, 0x77ac9c65,\n  0x2de92c6f, 0x592b0275, 0x4a7484aa, 0x6ea6e483,\n  0x5cb0a9dc, 0xbd41fbd4, 0x76f988da, 0x831153b5,\n  0x983e5152, 0xee66dfab, 0xa831c66d, 0x2db43210,\n  0xb00327c8, 0x98fb213f, 0xbf597fc7, 0xbeef0ee4,\n  0xc6e00bf3, 0x3da88fc2, 0xd5a79147, 0x930aa725,\n  0x06ca6351, 0xe003826f, 0x14292967, 0x0a0e6e70,\n  0x27b70a85, 0x46d22ffc, 0x2e1b2138, 0x5c26c926,\n  0x4d2c6dfc, 0x5ac42aed, 0x53380d13, 0x9d95b3df,\n  0x650a7354, 0x8baf63de, 0x766a0abb, 0x3c77b2a8,\n  0x81c2c92e, 0x47edaee6, 0x92722c85, 0x1482353b,\n  0xa2bfe8a1, 0x4cf10364, 0xa81a664b, 0xbc423001,\n  0xc24b8b70, 0xd0f89791, 0xc76c51a3, 0x0654be30,\n  0xd192e819, 0xd6ef5218, 0xd6990624, 0x5565a910,\n  0xf40e3585, 0x5771202a, 0x106aa070, 0x32bbd1b8,\n  0x19a4c116, 0xb8d2d0c8, 0x1e376c08, 0x5141ab53,\n  0x2748774c, 0xdf8eeb99, 0x34b0bcb5, 0xe19b48a8,\n  0x391c0cb3, 0xc5c95a63, 0x4ed8aa4a, 0xe3418acb,\n  0x5b9cca4f, 0x7763e373, 0x682e6ff3, 0xd6b2b8a3,\n  0x748f82ee, 0x5defb2fc, 0x78a5636f, 0x43172f60,\n  0x84c87814, 0xa1f0ab72, 0x8cc70208, 0x1a6439ec,\n  0x90befffa, 0x23631e28, 0xa4506ceb, 0xde82bde9,\n  0xbef9a3f7, 0xb2c67915, 0xc67178f2, 0xe372532b,\n  0xca273ece, 0xea26619c, 0xd186b8c7, 0x21c0c207,\n  0xeada7dd6, 0xcde0eb1e, 0xf57d4f7f, 0xee6ed178,\n  0x06f067aa, 0x72176fba, 0x0a637dc5, 0xa2c898a6,\n  0x113f9804, 0xbef90dae, 0x1b710b35, 0x131c471b,\n  0x28db77f5, 0x23047d84, 0x32caab7b, 0x40c72493,\n  0x3c9ebe0a, 0x15c9bebc, 0x431d67c4, 0x9c100d4c,\n  0x4cc5d4be, 0xcb3e42b6, 0x597f299c, 0xfc657e2a,\n  0x5fcb6fab, 0x3ad6faec, 0x6c44198c, 0x4a475817\n]\n\nvar W = new Array(160)\n\nfunction Sha512 () {\n  this.init()\n  this._w = W\n\n  Hash.call(this, 128, 112)\n}\n\ninherits(Sha512, Hash)\n\nSha512.prototype.init = function () {\n  this._ah = 0x6a09e667\n  this._bh = 0xbb67ae85\n  this._ch = 0x3c6ef372\n  this._dh = 0xa54ff53a\n  this._eh = 0x510e527f\n  this._fh = 0x9b05688c\n  this._gh = 0x1f83d9ab\n  this._hh = 0x5be0cd19\n\n  this._al = 0xf3bcc908\n  this._bl = 0x84caa73b\n  this._cl = 0xfe94f82b\n  this._dl = 0x5f1d36f1\n  this._el = 0xade682d1\n  this._fl = 0x2b3e6c1f\n  this._gl = 0xfb41bd6b\n  this._hl = 0x137e2179\n\n  return this\n}\n\nfunction Ch (x, y, z) {\n  return z ^ (x & (y ^ z))\n}\n\nfunction maj (x, y, z) {\n  return (x & y) | (z & (x | y))\n}\n\nfunction sigma0 (x, xl) {\n  return (x >>> 28 | xl << 4) ^ (xl >>> 2 | x << 30) ^ (xl >>> 7 | x << 25)\n}\n\nfunction sigma1 (x, xl) {\n  return (x >>> 14 | xl << 18) ^ (x >>> 18 | xl << 14) ^ (xl >>> 9 | x << 23)\n}\n\nfunction Gamma0 (x, xl) {\n  return (x >>> 1 | xl << 31) ^ (x >>> 8 | xl << 24) ^ (x >>> 7)\n}\n\nfunction Gamma0l (x, xl) {\n  return (x >>> 1 | xl << 31) ^ (x >>> 8 | xl << 24) ^ (x >>> 7 | xl << 25)\n}\n\nfunction Gamma1 (x, xl) {\n  return (x >>> 19 | xl << 13) ^ (xl >>> 29 | x << 3) ^ (x >>> 6)\n}\n\nfunction Gamma1l (x, xl) {\n  return (x >>> 19 | xl << 13) ^ (xl >>> 29 | x << 3) ^ (x >>> 6 | xl << 26)\n}\n\nfunction getCarry (a, b) {\n  return (a >>> 0) < (b >>> 0) ? 1 : 0\n}\n\nSha512.prototype._update = function (M) {\n  var W = this._w\n\n  var ah = this._ah | 0\n  var bh = this._bh | 0\n  var ch = this._ch | 0\n  var dh = this._dh | 0\n  var eh = this._eh | 0\n  var fh = this._fh | 0\n  var gh = this._gh | 0\n  var hh = this._hh | 0\n\n  var al = this._al | 0\n  var bl = this._bl | 0\n  var cl = this._cl | 0\n  var dl = this._dl | 0\n  var el = this._el | 0\n  var fl = this._fl | 0\n  var gl = this._gl | 0\n  var hl = this._hl | 0\n\n  for (var i = 0; i < 32; i += 2) {\n    W[i] = M.readInt32BE(i * 4)\n    W[i + 1] = M.readInt32BE(i * 4 + 4)\n  }\n  for (; i < 160; i += 2) {\n    var xh = W[i - 15 * 2]\n    var xl = W[i - 15 * 2 + 1]\n    var gamma0 = Gamma0(xh, xl)\n    var gamma0l = Gamma0l(xl, xh)\n\n    xh = W[i - 2 * 2]\n    xl = W[i - 2 * 2 + 1]\n    var gamma1 = Gamma1(xh, xl)\n    var gamma1l = Gamma1l(xl, xh)\n\n    // W[i] = gamma0 + W[i - 7] + gamma1 + W[i - 16]\n    var Wi7h = W[i - 7 * 2]\n    var Wi7l = W[i - 7 * 2 + 1]\n\n    var Wi16h = W[i - 16 * 2]\n    var Wi16l = W[i - 16 * 2 + 1]\n\n    var Wil = (gamma0l + Wi7l) | 0\n    var Wih = (gamma0 + Wi7h + getCarry(Wil, gamma0l)) | 0\n    Wil = (Wil + gamma1l) | 0\n    Wih = (Wih + gamma1 + getCarry(Wil, gamma1l)) | 0\n    Wil = (Wil + Wi16l) | 0\n    Wih = (Wih + Wi16h + getCarry(Wil, Wi16l)) | 0\n\n    W[i] = Wih\n    W[i + 1] = Wil\n  }\n\n  for (var j = 0; j < 160; j += 2) {\n    Wih = W[j]\n    Wil = W[j + 1]\n\n    var majh = maj(ah, bh, ch)\n    var majl = maj(al, bl, cl)\n\n    var sigma0h = sigma0(ah, al)\n    var sigma0l = sigma0(al, ah)\n    var sigma1h = sigma1(eh, el)\n    var sigma1l = sigma1(el, eh)\n\n    // t1 = h + sigma1 + ch + K[j] + W[j]\n    var Kih = K[j]\n    var Kil = K[j + 1]\n\n    var chh = Ch(eh, fh, gh)\n    var chl = Ch(el, fl, gl)\n\n    var t1l = (hl + sigma1l) | 0\n    var t1h = (hh + sigma1h + getCarry(t1l, hl)) | 0\n    t1l = (t1l + chl) | 0\n    t1h = (t1h + chh + getCarry(t1l, chl)) | 0\n    t1l = (t1l + Kil) | 0\n    t1h = (t1h + Kih + getCarry(t1l, Kil)) | 0\n    t1l = (t1l + Wil) | 0\n    t1h = (t1h + Wih + getCarry(t1l, Wil)) | 0\n\n    // t2 = sigma0 + maj\n    var t2l = (sigma0l + majl) | 0\n    var t2h = (sigma0h + majh + getCarry(t2l, sigma0l)) | 0\n\n    hh = gh\n    hl = gl\n    gh = fh\n    gl = fl\n    fh = eh\n    fl = el\n    el = (dl + t1l) | 0\n    eh = (dh + t1h + getCarry(el, dl)) | 0\n    dh = ch\n    dl = cl\n    ch = bh\n    cl = bl\n    bh = ah\n    bl = al\n    al = (t1l + t2l) | 0\n    ah = (t1h + t2h + getCarry(al, t1l)) | 0\n  }\n\n  this._al = (this._al + al) | 0\n  this._bl = (this._bl + bl) | 0\n  this._cl = (this._cl + cl) | 0\n  this._dl = (this._dl + dl) | 0\n  this._el = (this._el + el) | 0\n  this._fl = (this._fl + fl) | 0\n  this._gl = (this._gl + gl) | 0\n  this._hl = (this._hl + hl) | 0\n\n  this._ah = (this._ah + ah + getCarry(this._al, al)) | 0\n  this._bh = (this._bh + bh + getCarry(this._bl, bl)) | 0\n  this._ch = (this._ch + ch + getCarry(this._cl, cl)) | 0\n  this._dh = (this._dh + dh + getCarry(this._dl, dl)) | 0\n  this._eh = (this._eh + eh + getCarry(this._el, el)) | 0\n  this._fh = (this._fh + fh + getCarry(this._fl, fl)) | 0\n  this._gh = (this._gh + gh + getCarry(this._gl, gl)) | 0\n  this._hh = (this._hh + hh + getCarry(this._hl, hl)) | 0\n}\n\nSha512.prototype._hash = function () {\n  var H = Buffer.allocUnsafe(64)\n\n  function writeInt64BE (h, l, offset) {\n    H.writeInt32BE(h, offset)\n    H.writeInt32BE(l, offset + 4)\n  }\n\n  writeInt64BE(this._ah, this._al, 0)\n  writeInt64BE(this._bh, this._bl, 8)\n  writeInt64BE(this._ch, this._cl, 16)\n  writeInt64BE(this._dh, this._dl, 24)\n  writeInt64BE(this._eh, this._el, 32)\n  writeInt64BE(this._fh, this._fl, 40)\n  writeInt64BE(this._gh, this._gl, 48)\n  writeInt64BE(this._hh, this._hl, 56)\n\n  return H\n}\n\nmodule.exports = Sha512\n",null,null,"// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\nmodule.exports = Stream;\n\nvar EE = require('events').EventEmitter;\nvar inherits = require('inherits');\n\ninherits(Stream, EE);\nStream.Readable = require('readable-stream/lib/_stream_readable.js');\nStream.Writable = require('readable-stream/lib/_stream_writable.js');\nStream.Duplex = require('readable-stream/lib/_stream_duplex.js');\nStream.Transform = require('readable-stream/lib/_stream_transform.js');\nStream.PassThrough = require('readable-stream/lib/_stream_passthrough.js');\nStream.finished = require('readable-stream/lib/internal/streams/end-of-stream.js')\nStream.pipeline = require('readable-stream/lib/internal/streams/pipeline.js')\n\n// Backwards-compat with node 0.4.x\nStream.Stream = Stream;\n\n\n\n// old-style streams.  Note that the pipe method (the only relevant\n// part of this class) is overridden in the Readable class.\n\nfunction Stream() {\n  EE.call(this);\n}\n\nStream.prototype.pipe = function(dest, options) {\n  var source = this;\n\n  function ondata(chunk) {\n    if (dest.writable) {\n      if (false === dest.write(chunk) && source.pause) {\n        source.pause();\n      }\n    }\n  }\n\n  source.on('data', ondata);\n\n  function ondrain() {\n    if (source.readable && source.resume) {\n      source.resume();\n    }\n  }\n\n  dest.on('drain', ondrain);\n\n  // If the 'end' option is not supplied, dest.end() will be called when\n  // source gets the 'end' or 'close' events.  Only dest.end() once.\n  if (!dest._isStdio && (!options || options.end !== false)) {\n    source.on('end', onend);\n    source.on('close', onclose);\n  }\n\n  var didOnEnd = false;\n  function onend() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    dest.end();\n  }\n\n\n  function onclose() {\n    if (didOnEnd) return;\n    didOnEnd = true;\n\n    if (typeof dest.destroy === 'function') dest.destroy();\n  }\n\n  // don't leave dangling pipes when there are errors.\n  function onerror(er) {\n    cleanup();\n    if (EE.listenerCount(this, 'error') === 0) {\n      throw er; // Unhandled stream error in pipe.\n    }\n  }\n\n  source.on('error', onerror);\n  dest.on('error', onerror);\n\n  // remove all the event listeners that were added.\n  function cleanup() {\n    source.removeListener('data', ondata);\n    dest.removeListener('drain', ondrain);\n\n    source.removeListener('end', onend);\n    source.removeListener('close', onclose);\n\n    source.removeListener('error', onerror);\n    dest.removeListener('error', onerror);\n\n    source.removeListener('end', cleanup);\n    source.removeListener('close', cleanup);\n\n    dest.removeListener('close', cleanup);\n  }\n\n  source.on('end', cleanup);\n  source.on('close', cleanup);\n\n  dest.on('close', cleanup);\n\n  dest.emit('pipe', source);\n\n  // Allow for unix-like usage: A.pipe(B).pipe(C)\n  return dest;\n};\n","//\n// strftime\n// github.com/samsonjs/strftime\n// @_sjs\n//\n// Copyright 2010 - 2016 Sami Samhuri <sami@samhuri.net>\n//\n// MIT License\n// http://sjs.mit-license.org\n//\n\n;(function() {\n\n    var Locales = {\n        de_DE: {\n            days: ['Sonntag', 'Montag', 'Dienstag', 'Mittwoch', 'Donnerstag', 'Freitag', 'Samstag'],\n            shortDays: ['So', 'Mo', 'Di', 'Mi', 'Do', 'Fr', 'Sa'],\n            months: ['Januar', 'Februar', 'Mrz', 'April', 'Mai', 'Juni', 'Juli', 'August', 'September', 'Oktober', 'November', 'Dezember'],\n            shortMonths: ['Jan', 'Feb', 'Mr', 'Apr', 'Mai', 'Jun', 'Jul', 'Aug', 'Sep', 'Okt', 'Nov', 'Dez'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d.%m.%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        en_CA: {\n            days: ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday' ],\n            shortDays: ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'],\n            months: ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n            shortMonths: ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n            ordinalSuffixes: [\n                'st', 'nd', 'rd', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'st', 'nd', 'rd', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'st'\n            ],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d/%m/%y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%r',\n                x: '%D'\n            }\n        },\n\n        en_US: {\n            days: ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday' ],\n            shortDays: ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat'],\n            months: ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December'],\n            shortMonths: ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'],\n            ordinalSuffixes: [\n                'st', 'nd', 'rd', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'st', 'nd', 'rd', 'th', 'th', 'th', 'th', 'th', 'th', 'th',\n                'st'\n            ],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%m/%d/%y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%r',\n                x: '%D'\n            }\n        },\n\n        es_MX: {\n            days: ['domingo', 'lunes', 'martes', 'mircoles', 'jueves', 'viernes', 'sbado'],\n            shortDays: ['dom', 'lun', 'mar', 'mi', 'jue', 'vie', 'sb'],\n            months: ['enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio', 'julio', 'agosto', 'septiembre', 'octubre', 'noviembre',' diciembre'],\n            shortMonths: ['ene', 'feb', 'mar', 'abr', 'may', 'jun', 'jul', 'ago', 'sep', 'oct', 'nov', 'dic'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d/%m/%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        fr_FR: {\n            days: ['dimanche', 'lundi', 'mardi', 'mercredi', 'jeudi', 'vendredi', 'samedi'],\n            shortDays: ['dim.', 'lun.', 'mar.', 'mer.', 'jeu.', 'ven.', 'sam.'],\n            months: ['janvier', 'fvrier', 'mars', 'avril', 'mai', 'juin', 'juillet', 'aot', 'septembre', 'octobre', 'novembre', 'dcembre'],\n            shortMonths: ['janv.', 'fvr.', 'mars', 'avril', 'mai', 'juin', 'juil.', 'aot', 'sept.', 'oct.', 'nov.', 'dc.'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d/%m/%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        it_IT: {\n            days: ['domenica', 'luned', 'marted', 'mercoled', 'gioved', 'venerd', 'sabato'],\n            shortDays: ['dom', 'lun', 'mar', 'mer', 'gio', 'ven', 'sab'],\n            months: ['gennaio', 'febbraio', 'marzo', 'aprile', 'maggio', 'giugno', 'luglio', 'agosto', 'settembre', 'ottobre', 'novembre', 'dicembre'],\n            shortMonths: ['pr', 'mag', 'giu', 'lug', 'ago', 'set', 'ott', 'nov', 'dic'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d/%m/%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        nl_NL: {\n            days: ['zondag', 'maandag', 'dinsdag', 'woensdag', 'donderdag', 'vrijdag', 'zaterdag'],\n            shortDays: ['zo', 'ma', 'di', 'wo', 'do', 'vr', 'za'],\n            months: ['januari', 'februari', 'maart', 'april', 'mei', 'juni', 'juli', 'augustus', 'september', 'oktober', 'november', 'december'],\n            shortMonths: ['jan', 'feb', 'mrt', 'apr', 'mei', 'jun', 'jul', 'aug', 'sep', 'okt', 'nov', 'dec'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d-%m-%y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        pt_BR: {\n            days: ['domingo', 'segunda', 'tera', 'quarta', 'quinta', 'sexta', 'sbado'],\n            shortDays: ['Dom', 'Seg', 'Ter', 'Qua', 'Qui', 'Sex', 'Sb'],\n            months: ['janeiro', 'fevereiro', 'maro', 'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro'],\n            shortMonths: ['Jan', 'Fev', 'Mar', 'Abr', 'Mai', 'Jun', 'Jul', 'Ago', 'Set', 'Out', 'Nov', 'Dez'],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d-%m-%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        ru_RU: {\n            days: ['', '', '', '', '', '', ''],\n            shortDays: ['', '', '', '', '', '', ''],\n            months: ['', '', '', '', '', '', '', '', '', '', '', ''],\n            shortMonths: ['', '', '', '', '', '', '', '', '', '', '', ''],\n            AM: 'AM',\n            PM: 'PM',\n            am: 'am',\n            pm: 'pm',\n            formats: {\n                c: '%a %d %b %Y %X',\n                D: '%d.%m.%y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        tr_TR: {\n            days: ['Pazar', 'Pazartesi', 'Sal','aramba', 'Perembe', 'Cuma', 'Cumartesi'],\n            shortDays: ['Paz', 'Pzt', 'Sal', 'r', 'Pr', 'Cum', 'Cts'],\n            months: ['Ocak', 'ubat', 'Mart', 'Nisan', 'Mays', 'Haziran', 'Temmuz', 'Austos', 'Eyll', 'Ekim', 'Kasm', 'Aralk'],\n            shortMonths: ['Oca', 'ub', 'Mar', 'Nis', 'May', 'Haz', 'Tem', 'Au', 'Eyl', 'Eki', 'Kas', 'Ara'],\n            AM: '',\n            PM: 'S',\n            am: '',\n            pm: 'S',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d-%m-%Y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%T',\n                x: '%D'\n            }\n        },\n\n        // By michaeljayt<michaeljayt@gmail.com>\n        // https://github.com/michaeljayt/strftime/commit/bcb4c12743811d51e568175aa7bff3fd2a77cef3\n        zh_CN: {\n            days: ['', '', '', '', '', '', ''],\n            shortDays: ['', '', '', '', '', '', ''],\n            months: ['', '', '', '', '', '', '', '', '', '', '', ''],\n            shortMonths: ['', '', '', '', '', '', '', '', '', '', '', ''],\n            AM: '',\n            PM: '',\n            am: '',\n            pm: '',\n            formats: {\n                c: '%a %d %b %Y %X %Z',\n                D: '%d/%m/%y',\n                F: '%Y-%m-%d',\n                R: '%H:%M',\n                r: '%I:%M:%S %p',\n                T: '%H:%M:%S',\n                v: '%e-%b-%Y',\n                X: '%r',\n                x: '%D'\n            }\n        }\n    };\n\n    var DefaultLocale = Locales['en_US'],\n        defaultStrftime = new Strftime(DefaultLocale, 0, false),\n        isCommonJS = typeof module !== 'undefined',\n        namespace;\n\n    // CommonJS / Node module\n    if (isCommonJS) {\n        namespace = module.exports = defaultStrftime;\n    }\n    // Browsers and other environments\n    else {\n        // Get the global object. Works in ES3, ES5, and ES5 strict mode.\n        namespace = (function() { return this || (1,eval)('this'); }());\n        namespace.strftime = defaultStrftime;\n    }\n\n    // Polyfill Date.now for old browsers.\n    if (typeof Date.now !== 'function') {\n        Date.now = function() {\n          return +new Date();\n        };\n    }\n\n    function Strftime(locale, customTimezoneOffset, useUtcTimezone) {\n        var _locale = locale || DefaultLocale,\n            _customTimezoneOffset = customTimezoneOffset || 0,\n            _useUtcBasedDate = useUtcTimezone || false,\n\n            // we store unix timestamp value here to not create new Date() each iteration (each millisecond)\n            // Date.now() is 2 times faster than new Date()\n            // while millisecond precise is enough here\n            // this could be very helpful when strftime triggered a lot of times one by one\n            _cachedDateTimestamp = 0,\n            _cachedDate;\n\n        function _strftime(format, date) {\n            var timestamp;\n\n            if (!date) {\n                var currentTimestamp = Date.now();\n                if (currentTimestamp > _cachedDateTimestamp) {\n                    _cachedDateTimestamp = currentTimestamp;\n                    _cachedDate = new Date(_cachedDateTimestamp);\n\n                    timestamp = _cachedDateTimestamp;\n\n                    if (_useUtcBasedDate) {\n                        // how to avoid duplication of date instantiation for utc here?\n                        // we tied to getTimezoneOffset of the current date\n                        _cachedDate = new Date(_cachedDateTimestamp + getTimestampToUtcOffsetFor(_cachedDate) + _customTimezoneOffset);\n                    }\n                }\n                else {\n                  timestamp = _cachedDateTimestamp;\n                }\n                date = _cachedDate;\n            }\n            else {\n                timestamp = date.getTime();\n\n                if (_useUtcBasedDate) {\n                    var utcOffset = getTimestampToUtcOffsetFor(date);\n                    date = new Date(timestamp + utcOffset + _customTimezoneOffset);\n                    // If we've crossed a DST boundary with this calculation we need to\n                    // adjust the new date accordingly or it will be off by an hour in UTC.\n                    if (getTimestampToUtcOffsetFor(date) !== utcOffset) {\n                        var newUTCOffset = getTimestampToUtcOffsetFor(date);\n                        date = new Date(timestamp + newUTCOffset + _customTimezoneOffset);\n                    }\n                }\n            }\n\n            return _processFormat(format, date, _locale, timestamp);\n        }\n\n        function _processFormat(format, date, locale, timestamp) {\n            var resultString = '',\n                padding = null,\n                isInScope = false,\n                length = format.length,\n                extendedTZ = false;\n\n            for (var i = 0; i < length; i++) {\n\n                var currentCharCode = format.charCodeAt(i);\n\n                if (isInScope === true) {\n                    // '-'\n                    if (currentCharCode === 45) {\n                        padding = '';\n                        continue;\n                    }\n                    // '_'\n                    else if (currentCharCode === 95) {\n                        padding = ' ';\n                        continue;\n                    }\n                    // '0'\n                    else if (currentCharCode === 48) {\n                        padding = '0';\n                        continue;\n                    }\n                    // ':'\n                    else if (currentCharCode === 58) {\n                      if (extendedTZ) {\n                          warn(\"[WARNING] detected use of unsupported %:: or %::: modifiers to strftime\");\n                      }\n                      extendedTZ = true;\n                      continue;\n                    }\n\n                    switch (currentCharCode) {\n\n                        // Examples for new Date(0) in GMT\n\n                        // '%'\n                        // case '%':\n                        case 37:\n                            resultString += '%';\n                            break;\n\n                        // 'Thursday'\n                        // case 'A':\n                        case 65:\n                            resultString += locale.days[date.getDay()];\n                            break;\n\n                        // 'January'\n                        // case 'B':\n                        case 66:\n                            resultString += locale.months[date.getMonth()];\n                            break;\n\n                        // '19'\n                        // case 'C':\n                        case 67:\n                            resultString += padTill2(Math.floor(date.getFullYear() / 100), padding);\n                            break;\n\n                        // '01/01/70'\n                        // case 'D':\n                        case 68:\n                            resultString += _processFormat(locale.formats.D, date, locale, timestamp);\n                            break;\n\n                        // '1970-01-01'\n                        // case 'F':\n                        case 70:\n                            resultString += _processFormat(locale.formats.F, date, locale, timestamp);\n                            break;\n\n                        // '00'\n                        // case 'H':\n                        case 72:\n                            resultString += padTill2(date.getHours(), padding);\n                            break;\n\n                        // '12'\n                        // case 'I':\n                        case 73:\n                            resultString += padTill2(hours12(date.getHours()), padding);\n                            break;\n\n                        // '000'\n                        // case 'L':\n                        case 76:\n                            resultString += padTill3(Math.floor(timestamp % 1000));\n                            break;\n\n                        // '00'\n                        // case 'M':\n                        case 77:\n                            resultString += padTill2(date.getMinutes(), padding);\n                            break;\n\n                        // 'am'\n                        // case 'P':\n                        case 80:\n                            resultString += date.getHours() < 12 ? locale.am : locale.pm;\n                            break;\n\n                        // '00:00'\n                        // case 'R':\n                        case 82:\n                            resultString += _processFormat(locale.formats.R, date, locale, timestamp);\n                            break;\n\n                        // '00'\n                        // case 'S':\n                        case 83:\n                            resultString += padTill2(date.getSeconds(), padding);\n                            break;\n\n                        // '00:00:00'\n                        // case 'T':\n                        case 84:\n                            resultString += _processFormat(locale.formats.T, date, locale, timestamp);\n                            break;\n\n                        // '00'\n                        // case 'U':\n                        case 85:\n                            resultString += padTill2(weekNumber(date, 'sunday'), padding);\n                            break;\n\n                        // '00'\n                        // case 'W':\n                        case 87:\n                            resultString += padTill2(weekNumber(date, 'monday'), padding);\n                            break;\n\n                        // '16:00:00'\n                        // case 'X':\n                        case 88:\n                            resultString += _processFormat(locale.formats.X, date, locale, timestamp);\n                            break;\n\n                        // '1970'\n                        // case 'Y':\n                        case 89:\n                            resultString += date.getFullYear();\n                            break;\n\n                        // 'GMT'\n                        // case 'Z':\n                        case 90:\n                            if (_useUtcBasedDate && _customTimezoneOffset === 0) {\n                                resultString += \"GMT\";\n                            }\n                            else {\n                                // fixme optimize\n                                var tzString = date.toString().match(/\\(([\\w\\s]+)\\)/);\n                                resultString += tzString && tzString[1] || '';\n                            }\n                            break;\n\n                        // 'Thu'\n                        // case 'a':\n                        case 97:\n                            resultString += locale.shortDays[date.getDay()];\n                            break;\n\n                        // 'Jan'\n                        // case 'b':\n                        case 98:\n                            resultString += locale.shortMonths[date.getMonth()];\n                            break;\n\n                        // ''\n                        // case 'c':\n                        case 99:\n                            resultString += _processFormat(locale.formats.c, date, locale, timestamp);\n                            break;\n\n                        // '01'\n                        // case 'd':\n                        case 100:\n                            resultString += padTill2(date.getDate(), padding);\n                            break;\n\n                        // ' 1'\n                        // case 'e':\n                        case 101:\n                            resultString += padTill2(date.getDate(), padding == null ? ' ' : padding);\n                            break;\n\n                        // 'Jan'\n                        // case 'h':\n                        case 104:\n                            resultString += locale.shortMonths[date.getMonth()];\n                            break;\n\n                        // '000'\n                        // case 'j':\n                        case 106:\n                            var y = new Date(date.getFullYear(), 0, 1);\n                            var day = Math.ceil((date.getTime() - y.getTime()) / (1000 * 60 * 60 * 24));\n                            resultString += padTill3(day);\n                            break;\n\n                        // ' 0'\n                        // case 'k':\n                        case 107:\n                            resultString += padTill2(date.getHours(), padding == null ? ' ' : padding);\n                            break;\n\n                        // '12'\n                        // case 'l':\n                        case 108:\n                            resultString += padTill2(hours12(date.getHours()), padding == null ? ' ' : padding);\n                            break;\n\n                        // '01'\n                        // case 'm':\n                        case 109:\n                            resultString += padTill2(date.getMonth() + 1, padding);\n                            break;\n\n                        // '\\n'\n                        // case 'n':\n                        case 110:\n                            resultString += '\\n';\n                            break;\n\n                        // '1st'\n                        // case 'o':\n                        case 111:\n                            // Try to use an ordinal suffix from the locale, but fall back to using the old\n                            // function for compatibility with old locales that lack them.\n                            var day = date.getDate();\n                            if (locale.ordinalSuffixes) {\n                                resultString += String(day) + (locale.ordinalSuffixes[day - 1] || ordinal(day));\n                            }\n                            else {\n                                resultString += String(day) + ordinal(day);\n                            }\n                            break;\n\n                        // 'AM'\n                        // case 'p':\n                        case 112:\n                            resultString += date.getHours() < 12 ? locale.AM : locale.PM;\n                            break;\n\n                        // '12:00:00 AM'\n                        // case 'r':\n                        case 114:\n                            resultString += _processFormat(locale.formats.r, date, locale, timestamp);\n                            break;\n\n                        // '0'\n                        // case 's':\n                        case 115:\n                            resultString += Math.floor(timestamp / 1000);\n                            break;\n\n                        // '\\t'\n                        // case 't':\n                        case 116:\n                            resultString += '\\t';\n                            break;\n\n                        // '4'\n                        // case 'u':\n                        case 117:\n                            var day = date.getDay();\n                            resultString += day === 0 ? 7 : day;\n                            break; // 1 - 7, Monday is first day of the week\n\n                        // ' 1-Jan-1970'\n                        // case 'v':\n                        case 118:\n                            resultString += _processFormat(locale.formats.v, date, locale, timestamp);\n                            break;\n\n                        // '4'\n                        // case 'w':\n                        case 119:\n                            resultString += date.getDay();\n                            break; // 0 - 6, Sunday is first day of the week\n\n                        // '12/31/69'\n                        // case 'x':\n                        case 120:\n                            resultString += _processFormat(locale.formats.x, date, locale, timestamp);\n                            break;\n\n                        // '70'\n                        // case 'y':\n                        case 121:\n                            resultString += ('' + date.getFullYear()).slice(2);\n                            break;\n\n                        // '+0000'\n                        // case 'z':\n                        case 122:\n                            if (_useUtcBasedDate && _customTimezoneOffset === 0) {\n                                resultString += extendedTZ ? \"+00:00\" : \"+0000\";\n                            }\n                            else {\n                                var off;\n                                if (_customTimezoneOffset !== 0) {\n                                    off = _customTimezoneOffset / (60 * 1000);\n                                }\n                                else {\n                                    off = -date.getTimezoneOffset();\n                                }\n                                var sign = off < 0 ? '-' : '+';\n                                var sep = extendedTZ ? ':' : '';\n                                var hours = Math.floor(Math.abs(off / 60));\n                                var mins = Math.abs(off % 60);\n                                resultString += sign + padTill2(hours) + sep + padTill2(mins);\n                            }\n                            break;\n\n                        default:\n                            if (isInScope) {\n                                resultString += '%';\n                            }\n                            resultString += format[i];\n                            break;\n                    }\n\n                    padding = null;\n                    isInScope = false;\n                    continue;\n                }\n\n                // '%'\n                if (currentCharCode === 37) {\n                    isInScope = true;\n                    continue;\n                }\n\n                resultString += format[i];\n            }\n\n            return resultString;\n        }\n\n        var strftime = _strftime;\n\n        strftime.localize = function(locale) {\n            return new Strftime(locale || _locale, _customTimezoneOffset, _useUtcBasedDate);\n        };\n\n        strftime.localizeByIdentifier = function(localeIdentifier) {\n            var locale = Locales[localeIdentifier];\n            if (!locale) {\n                warn('[WARNING] No locale found with identifier \"' + localeIdentifier + '\".');\n                return strftime;\n            }\n            return strftime.localize(locale);\n        };\n\n        strftime.timezone = function(timezone) {\n            var customTimezoneOffset = _customTimezoneOffset;\n            var useUtcBasedDate = _useUtcBasedDate;\n\n            var timezoneType = typeof timezone;\n            if (timezoneType === 'number' || timezoneType === 'string') {\n                useUtcBasedDate = true;\n\n                // ISO 8601 format timezone string, [-+]HHMM\n                if (timezoneType === 'string') {\n                    var sign = timezone[0] === '-' ? -1 : 1,\n                        hours = parseInt(timezone.slice(1, 3), 10),\n                        minutes = parseInt(timezone.slice(3, 5), 10);\n\n                    customTimezoneOffset = sign * ((60 * hours) + minutes) * 60 * 1000;\n                    // in minutes: 420\n                }\n                else if (timezoneType === 'number') {\n                    customTimezoneOffset = timezone * 60 * 1000;\n                }\n            }\n\n            return new Strftime(_locale, customTimezoneOffset, useUtcBasedDate);\n        };\n\n        strftime.utc = function() {\n            return new Strftime(_locale, _customTimezoneOffset, true);\n        };\n\n        return strftime;\n    }\n\n    function padTill2(numberToPad, paddingChar) {\n        if (paddingChar === '' || numberToPad > 9) {\n            return numberToPad;\n        }\n        if (paddingChar == null) {\n            paddingChar = '0';\n        }\n        return paddingChar + numberToPad;\n    }\n\n    function padTill3(numberToPad) {\n        if (numberToPad > 99) {\n            return numberToPad;\n        }\n        if (numberToPad > 9) {\n            return '0' + numberToPad;\n        }\n        return '00' + numberToPad;\n    }\n\n    function hours12(hour) 